# OpenAI Provider Implementation Comparison

## Overview
This document compares the goose OpenAI provider implementation against the official OpenAI Python SDK to identify gaps and prioritize development efforts.

**Last Updated:** 2025-01-13

---

## Architecture Comparison

### Official OpenAI Python SDK
- **Language:** Python
- **HTTP Client:** httpx (with aiohttp option)
- **Code Generation:** Auto-generated from OpenAPI spec using Stainless
- **Lines of Code:** ~66,000 lines across 767 files
- **Type Safety:** Comprehensive Pydantic models for all types
- **Async Support:** Full async/await support with AsyncOpenAI client
- **Resource Pattern:** Hierarchical resource organization (client.chat.completions.create)

### Goose OpenAI Provider
- **Language:** Rust
- **HTTP Client:** reqwest
- **Implementation:** Hand-coded
- **Lines of Code:** ~1,809 lines (openai.rs: 429, formats/openai.rs: 1,380)
- **Type Safety:** Rust types + serde_json::Value for API responses
- **Async Support:** Full async/await with tokio
- **Pattern:** Provider trait implementation

---

## Feature Comparison Matrix

### âœ… Implemented in Goose

| Feature | Status | Notes |
|---------|--------|-------|
| Chat Completions (streaming) | âœ… | Full support with SSE |
| Chat Completions (non-streaming) | âœ… | Complete |
| Tool/Function Calling | âœ… | Full support with proper error handling |
| Multi-tool requests | âœ… | Handles multiple tool calls in streaming |
| Vision (images) | âœ… | Supports image URLs and base64 |
| Embeddings | âœ… | text-embedding-3-small default |
| Model listing | âœ… | fetch_supported_models() |
| Custom headers | âœ… | OPENAI_CUSTOM_HEADERS support |
| Organization/Project headers | âœ… | OPENAI_ORGANIZATION, OPENAI_PROJECT |
| Custom base URL/host | âœ… | For OpenAI-compatible APIs |
| O-series models (o1, o3) | âœ… | Special handling for reasoning_effort, developer role |
| Retry logic | âœ… | Built-in retry with exponential backoff |
| Request logging | âœ… | RequestLog for debugging |
| Timeout configuration | âœ… | OPENAI_TIMEOUT (default: 600s) |
| Azure OpenAI | âœ… | Separate azure.rs provider |
| Error handling | âœ… | Comprehensive ProviderError types |
| Token usage tracking | âœ… | Input/output/total tokens |

### âŒ Missing from Goose

#### High Priority (Core Functionality)
| Feature | Impact | SDK Support |
|---------|--------|-------------|
| **Structured Outputs (JSON Schema)** | ğŸ”´ High | âœ… Full support with response_format |
| **Responses API** | ğŸ”´ High | âœ… New primary API (client.responses.create) |
| **Audio (Whisper)** | ğŸŸ¡ Medium | âœ… Transcriptions & translations |
| **Text-to-Speech** | ğŸŸ¡ Medium | âœ… client.audio.speech.create |
| **Batch API** | ğŸŸ¡ Medium | âœ… client.batches.* |
| **Image Generation (DALL-E)** | ğŸŸ¡ Medium | âœ… client.images.generate, edit, variations |
| **Video Generation (Sora)** | ğŸŸ¡ Medium | âœ… client.videos.* (new) |

#### Medium Priority (Advanced Features)
| Feature | Impact | SDK Support |
|---------|--------|-------------|
| **Fine-tuning Management** | ğŸŸ¡ Medium | âœ… client.fine_tuning.jobs.* |
| **Assistants API (Beta)** | ğŸŸ¡ Medium | âœ… client.beta.assistants.* |
| **Vector Stores** | ğŸŸ¡ Medium | âœ… client.beta.vector_stores.* |
| **Threads & Messages** | ğŸŸ¡ Medium | âœ… client.beta.threads.* |
| **File Management** | ğŸŸ¡ Medium | âœ… client.files.* |
| **Uploads API** | ğŸŸ¡ Medium | âœ… client.uploads.* for large files |
| **Moderation API** | ğŸŸ¢ Low | âœ… client.moderations.create |
| **Realtime API (WebSocket)** | ğŸŸ¡ Medium | âœ… client.realtime.* |
| **Evals API** | ğŸŸ¢ Low | âœ… client.evals.* |
| **Containers API** | ğŸŸ¢ Low | âœ… client.containers.* |

#### Low Priority (SDK Features)
| Feature | Impact | SDK Support |
|---------|--------|-------------|
| **Pagination helpers** | ğŸŸ¢ Low | âœ… SyncPage/AsyncPage |
| **Webhooks** | ğŸŸ¢ Low | âœ… client.webhooks.* |
| **Raw response access** | ğŸŸ¢ Low | âœ… with_raw_response() |
| **Response parsing helpers** | ğŸŸ¢ Low | âœ… lib._parsing module |
| **CLI tool** | ğŸŸ¢ Low | âœ… openai cli |

### ğŸ”„ Implementation Differences

| Aspect | Goose | OpenAI SDK | Notes |
|--------|-------|------------|-------|
| **Streaming** | Manual SSE parsing | Built-in Stream objects | Both functional |
| **Error handling** | Rust Result types | Python exceptions | Different paradigms |
| **Retries** | with_retry() trait | Built-in retry logic | Both have retry |
| **Type safety** | Rust compile-time | Pydantic runtime | Rust stricter |
| **Config** | Environment vars | Constructor args | Different patterns |
| **Provider abstraction** | Trait system | Not needed | Goose multi-provider |

---

## Key Differences in Chat Completions

### Request Parameters

#### Goose Supports:
- âœ… model, messages, temperature, max_tokens
- âœ… tools (function calling)
- âœ… stream, stream_options
- âœ… O-series: reasoning_effort, max_completion_tokens, developer role
- âœ… Custom: toolshim for models without tool support

#### OpenAI SDK Also Supports:
- âŒ **response_format** (json_object, json_schema, text)
- âŒ **audio** (for multimodal audio input/output)
- âŒ **modalities** (text, audio, vision combinations)
- âŒ **prediction** (for prefilling assistant responses)
- âŒ **metadata** (custom key-value pairs)
- âŒ **store** (for Assistants API)
- âŒ **top_p** (nucleus sampling)
- âŒ **frequency_penalty** / **presence_penalty**
- âŒ **logprobs** (token log probabilities)
- âŒ **top_logprobs**
- âŒ **logit_bias** (token probability modification)
- âŒ **seed** (for deterministic outputs)
- âŒ **service_tier** (default, auto)
- âŒ **user** (end-user identifier)
- âŒ **parallel_tool_calls** (enable/disable)
- âŒ **tool_choice** (auto, required, none, or specific tool)

### Response Handling

#### Goose Supports:
- âœ… Text content
- âœ… Tool calls (with proper streaming)
- âœ… Usage data (tokens)
- âœ… Error content in tool calls
- âœ… Multiple tool calls in one response

#### OpenAI SDK Also Supports:
- âŒ **Audio output** (speech responses)
- âŒ **Refusal** (content policy refusals)
- âŒ **Finish reasons** (stop, length, tool_calls, content_filter, function_call)
- âŒ **Log probabilities** (per token)
- âŒ **System fingerprint** (for reproducibility)

---

## API Coverage by Endpoint

| Endpoint | Goose | OpenAI SDK | Priority |
|----------|-------|------------|----------|
| /chat/completions | âœ… Full | âœ… Full | Core |
| /embeddings | âœ… Basic | âœ… Full | High |
| /audio/transcriptions | âŒ | âœ… | High |
| /audio/translations | âŒ | âœ… | High |
| /audio/speech | âŒ | âœ… | High |
| /images/generations | âŒ | âœ… | Medium |
| /images/edits | âŒ | âœ… | Medium |
| /images/variations | âŒ | âœ… | Medium |
| /videos/* | âŒ | âœ… | Medium |
| /models | âœ… List | âœ… List/Get/Delete | Low |
| /moderations | âŒ | âœ… | Low |
| /fine_tuning/jobs | âŒ | âœ… | Medium |
| /files | âŒ | âœ… | Medium |
| /uploads/* | âŒ | âœ… | Low |
| /batches | âŒ | âœ… | Medium |
| /beta/assistants | âŒ | âœ… | Medium |
| /beta/threads | âŒ | âœ… | Medium |
| /beta/vector_stores | âŒ | âœ… | Medium |
| /realtime/* | âŒ | âœ… | Low |
| /responses/* | âŒ | âœ… | High |
| /evals/* | âŒ | âœ… | Low |
| /containers/* | âŒ | âœ… | Low |

---

## Recommendations: What to Focus On

### ğŸ¯ Immediate Priorities (P0)

1. **Structured Outputs / JSON Schema**
   - **Why:** Critical for reliable tool outputs and structured data extraction
   - **Impact:** Enables schema validation, better reliability
   - **Effort:** Medium - add response_format parameter support
   - **Code:** Add to `create_request()` in formats/openai.rs

2. **Responses API**
   - **Why:** New primary API from OpenAI, replacing chat completions
   - **Impact:** Future-proofing, better developer experience
   - **Effort:** High - new API surface
   - **Code:** New module or extend existing provider

3. **Audio (Whisper) Transcription**
   - **Why:** Core functionality for multimodal applications
   - **Impact:** Enables voice input processing
   - **Effort:** Medium - file upload + API call
   - **Code:** New audio module in provider

4. **Missing Chat Completion Parameters**
   - **Priority:** top_p, frequency_penalty, presence_penalty, seed
   - **Why:** Common parameters for output control
   - **Impact:** Better control over generation
   - **Effort:** Low - just add to payload
   - **Code:** Extend `create_request()` in formats/openai.rs

### ğŸ”„ Short Term (P1)

5. **Image Generation (DALL-E)**
   - **Why:** Popular feature for creative applications
   - **Impact:** Enables image generation workflows
   - **Effort:** Medium - new API endpoint
   - **Code:** New images module

6. **Batch API**
   - **Why:** Cost-effective processing of large workloads
   - **Impact:** Enables efficient bulk processing
   - **Effort:** Medium - async batch handling
   - **Code:** New batches module

7. **Enhanced Embeddings**
   - **Current:** Basic support with text-embedding-3-small
   - **Add:** Model selection, dimensions parameter, encoding_format
   - **Effort:** Low
   - **Code:** Extend embedding.rs

### ğŸ“¦ Medium Term (P2)

8. **Text-to-Speech**
   - **Why:** Completes audio capabilities
   - **Impact:** Voice output
   - **Effort:** Low - simple API
   - **Code:** Extend audio module

9. **File Management**
   - **Why:** Required for fine-tuning and assistants
   - **Impact:** Enables advanced features
   - **Effort:** Medium
   - **Code:** New files module

10. **Moderation API**
    - **Why:** Content safety
    - **Impact:** Required for production apps
    - **Effort:** Low
    - **Code:** New moderations module

### ğŸ”® Long Term (P3)

11. **Assistants API (Beta)**
    - **Why:** Stateful conversations with memory
    - **Impact:** Advanced use cases
    - **Effort:** High - complex state management
    - **Code:** New beta/assistants module

12. **Fine-tuning Management**
    - **Why:** Model customization
    - **Impact:** Advanced use cases
    - **Effort:** Medium
    - **Code:** New fine_tuning module

13. **Vector Stores**
    - **Why:** RAG and semantic search
    - **Impact:** Knowledge base applications
    - **Effort:** High
    - **Code:** New vector_stores module

---

## Code Organization Recommendations

### Current Structure
```
crates/goose/src/providers/
â”œâ”€â”€ openai.rs          (429 lines)  - Provider implementation
â”œâ”€â”€ formats/
â”‚   â””â”€â”€ openai.rs      (1,380 lines) - Request/response formatting
â”œâ”€â”€ embedding.rs       (24 lines)   - Trait definition
â”œâ”€â”€ api_client.rs      (457 lines)  - HTTP client
â””â”€â”€ base.rs            (675 lines)  - Provider trait
```

### Recommended Structure for Growth
```
crates/goose/src/providers/openai/
â”œâ”€â”€ mod.rs                    - Re-exports
â”œâ”€â”€ provider.rs               - Main OpenAiProvider impl
â”œâ”€â”€ client.rs                 - HTTP client wrapper
â”œâ”€â”€ completions/
â”‚   â”œâ”€â”€ mod.rs
â”‚   â”œâ”€â”€ chat.rs              - Chat completions
â”‚   â”œâ”€â”€ streaming.rs         - Streaming logic
â”‚   â””â”€â”€ responses.rs         - New Responses API
â”œâ”€â”€ embeddings.rs            - Embeddings API
â”œâ”€â”€ audio/
â”‚   â”œâ”€â”€ mod.rs
â”‚   â”œâ”€â”€ transcriptions.rs   - Whisper
â”‚   â”œâ”€â”€ translations.rs     - Translations
â”‚   â””â”€â”€ speech.rs           - TTS
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ mod.rs
â”‚   â”œâ”€â”€ generations.rs
â”‚   â”œâ”€â”€ edits.rs
â”‚   â””â”€â”€ variations.rs
â”œâ”€â”€ batches.rs              - Batch API
â”œâ”€â”€ files.rs                - File management
â”œâ”€â”€ moderations.rs          - Moderation API
â”œâ”€â”€ models.rs               - Model management
â”œâ”€â”€ formats/
â”‚   â”œâ”€â”€ mod.rs
â”‚   â”œâ”€â”€ requests.rs         - Request builders
â”‚   â”œâ”€â”€ responses.rs        - Response parsers
â”‚   â””â”€â”€ streaming.rs        - SSE parsing
â””â”€â”€ types/
    â”œâ”€â”€ mod.rs
    â”œâ”€â”€ completions.rs
    â”œâ”€â”€ audio.rs
    â”œâ”€â”€ images.rs
    â””â”€â”€ ...
```

---

## Specific Implementation Gaps

### 1. Structured Outputs (JSON Schema)

**Current:** No response_format support
**Needed:**
```rust
// Add to ModelConfig or request payload
pub struct ResponseFormat {
    pub type_: ResponseFormatType,
    pub json_schema: Option<JsonSchema>,
}

pub enum ResponseFormatType {
    Text,
    JsonObject,
    JsonSchema,
}
```

**Usage in SDK:**
```python
response = client.chat.completions.create(
    model="gpt-4o",
    messages=[{"role": "user", "content": "Extract: John is 30"}],
    response_format={
        "type": "json_schema",
        "json_schema": {
            "name": "person",
            "strict": True,
            "schema": {
                "type": "object",
                "properties": {
                    "name": {"type": "string"},
                    "age": {"type": "integer"}
                },
                "required": ["name", "age"]
            }
        }
    }
)
```

### 2. Missing Parameters

Add to `create_request()`:
```rust
// Currently missing:
pub struct ModelConfig {
    // ... existing fields ...
    pub top_p: Option<f32>,
    pub frequency_penalty: Option<f32>,
    pub presence_penalty: Option<f32>,
    pub seed: Option<i32>,
    pub logit_bias: Option<HashMap<String, f32>>,
    pub logprobs: Option<bool>,
    pub top_logprobs: Option<i32>,
    pub service_tier: Option<String>,
    pub user: Option<String>,
}
```

### 3. Tool Choice Control

**Current:** Tools are either provided or not
**Needed:**
```rust
pub enum ToolChoice {
    Auto,           // Let model decide
    Required,       // Must call a tool
    None,           // Don't call tools
    Specific(String), // Call specific tool
}
```

---

## Testing Gaps

### Current Testing
- âœ… Basic request/response parsing
- âœ… Tool call parsing
- âœ… Streaming multi-tool
- âœ… O-series model handling
- âœ… Error handling

### Missing Tests
- âŒ Structured outputs validation
- âŒ Audio parameter handling
- âŒ All chat completion parameters
- âŒ Moderation API
- âŒ Batch API
- âŒ Image generation
- âŒ File upload
- âŒ Retry behavior verification
- âŒ Rate limit handling
- âŒ Timeout behavior

---

## Performance Considerations

### Goose Advantages
- ğŸš€ Rust performance (memory safety, zero-cost abstractions)
- ğŸš€ Compiled binary (faster startup)
- ğŸš€ No GIL issues (true parallelism)
- ğŸš€ Lower memory footprint

### SDK Advantages
- ğŸ“¦ Auto-generated (always up-to-date with API)
- ğŸ“¦ Comprehensive type hints
- ğŸ“¦ More helper utilities
- ğŸ“¦ Larger ecosystem integration

---

## Migration Path for Users

If implementing parity, consider:

1. **Backward Compatibility:** Keep existing API stable
2. **Gradual Addition:** Add new features as optional
3. **Feature Flags:** Use Cargo features for optional endpoints
4. **Documentation:** Clear examples for each new feature
5. **Testing:** Comprehensive integration tests against OpenAI API

---

## Summary Statistics

| Metric | Goose | OpenAI SDK |
|--------|-------|------------|
| **Total Files** | 2 main | 767 |
| **Lines of Code** | ~1,809 | ~66,153 |
| **API Endpoints** | 2 | ~20+ |
| **Chat Params** | ~8 | ~30+ |
| **Response Types** | 3 | 15+ |
| **Test Coverage** | ~10 tests | ~100+ tests |
| **Feature Completeness** | ~30% | 100% |

---

## Conclusion

**Current State:** Goose has excellent coverage of core chat completion functionality with streaming, tool calling, and O-series model support. The implementation is solid and performant.

**Main Gaps:** Missing structured outputs (critical), Responses API (new primary API), audio APIs (whisper/TTS), and many advanced parameters.

**Recommended Focus:**
1. âš¡ **P0:** Structured outputs (JSON Schema) - critical for reliability
2. âš¡ **P0:** Responses API - future-proofing
3. âš¡ **P0:** Missing chat parameters (top_p, penalties, seed) - common needs
4. ğŸ”„ **P1:** Audio transcription (Whisper) - multimodal applications
5. ğŸ”„ **P1:** Image generation (DALL-E) - creative applications
6. ğŸ”„ **P1:** Batch API - cost optimization

The goose implementation is well-architected for a provider abstraction layer. Adding full OpenAI parity would significantly expand the codebase but provide comprehensive API coverage. Consider prioritizing based on actual user needs rather than 100% API parity.
