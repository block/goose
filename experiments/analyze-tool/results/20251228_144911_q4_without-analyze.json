Loading recipe: Explore Test - Without Analyze
Description: Test codebase exploration without the analyze tool (baseline)
Parameters used to load this recipe:
   target_directory: /Users/baxen/Development/goose
   question: How does a message flow from CLI input to LLM response?

starting session | provider: databricks model: goose-claude-4-5-opus
    session id: 20251228_61
    working directory: /Users/baxen/Development/goose
{
  "messages": [
    {
      "id": null,
      "role": "user",
      "created": 1766962602,
      "content": [
        {
          "type": "text",
          "text": "You are exploring a codebase to answer a question. Use whatever tools you have available\nto understand the code structure and answer accurately.\n\nTarget directory: /Users/baxen/Development/goose\n\nQuestion: How does a message flow from CLI input to LLM response?\n\nProvide a clear, structured answer. When you're done, summarize what tools you used\nand how many times you called each one.\n"
        }
      ],
      "metadata": {
        "userVisible": true,
        "agentVisible": true
      }
    },
    {
      "id": "msg_013sWXAp15azrC6WtMPc2hrX",
      "role": "assistant",
      "created": 1766962605,
      "content": [
        {
          "type": "toolRequest",
          "id": "toolu_01UjbLDo58JusEGyHdgXJsh3",
          "toolCall": {
            "status": "success",
            "value": {
              "name": "developer__text_editor",
              "arguments": {
                "command": "view",
                "path": "/Users/baxen/Development/goose"
              }
            }
          }
        }
      ],
      "metadata": {
        "userVisible": true,
        "agentVisible": true
      }
    },
    {
      "id": "msg_500a3684-1f59-422a-923b-a3f5dadfb7c8",
      "role": "user",
      "created": 1766962605,
      "content": [
        {
          "type": "toolResponse",
          "id": "toolu_01UjbLDo58JusEGyHdgXJsh3",
          "toolResult": {
            "status": "success",
            "value": {
              "content": [
                {
                  "type": "text",
                  "text": "'/Users/baxen/Development/goose' is a directory. Contents:\n\nDirectories:\n  .devcontainer/\n  .git/\n  .github/\n  .hermit/\n  .husky/\n  .intersect/\n  .worktrees/\n  bin/\n  clippy-baselines/\n  crates/\n  documentation/\n  examples/\n  experiments/\n  recipe-scanner/\n  scripts/\n  target/\n  ui/\n\nFiles:\n  .dockerignore\n  .gitattributes\n  .gitignore\n  .goosehints\n  ACCEPTABLE_USAGE.md\n  AGENTS.md\n  BUILDING_DOCKER.md\n  BUILDING_LINUX.md\n  CONTRIBUTING.md\n  CONTRIBUTING_RECIPES.md\n  Cargo.lock\n  Cargo.toml\n  Cross.toml\n  Dockerfile\n  GOVERNANCE.md\n  HOWTOAI.md\n  Justfile\n  LICENSE\n  MAINTAINERS.md\n  README.md\n  RELEASE.md\n  SECURITY.md\n  download_cli.ps1\n  download_cli.sh\n  flake.lock\n  flake.nix\n  goose-self-test.yaml\n  recipe.yaml\n  run_cross_local.md\n  rust-toolchain.toml\n  search.log\n  test_acp_client.py\n  title.log\n\n... and 1 more items (showing first 50 items)\n"
                }
              ],
              "isError": false
            }
          }
        }
      ],
      "metadata": {
        "userVisible": true,
        "agentVisible": true
      }
    },
    {
      "id": "msg_013dwRpCnAqSbDwXPMvruiVZ",
      "role": "assistant",
      "created": 1766962610,
      "content": [
        {
          "type": "toolRequest",
          "id": "toolu_01RnBDfkoMR4YsC8y2Wmz7oH",
          "toolCall": {
            "status": "success",
            "value": {
              "name": "developer__text_editor",
              "arguments": {
                "command": "view",
                "path": "/Users/baxen/Development/goose/crates/goose-cli/src"
              }
            }
          }
        },
        {
          "type": "toolRequest",
          "id": "toolu_01HFKTFHkrcgxBShMRSb2Vyp",
          "toolCall": {
            "status": "success",
            "value": {
              "name": "developer__text_editor",
              "arguments": {
                "command": "view",
                "path": "/Users/baxen/Development/goose/crates/goose/src"
              }
            }
          }
        }
      ],
      "metadata": {
        "userVisible": true,
        "agentVisible": true
      }
    },
    {
      "id": "msg_dde83dc8-2a93-4ba2-bdde-ebd44dff6247",
      "role": "user",
      "created": 1766962610,
      "content": [
        {
          "type": "toolResponse",
          "id": "toolu_01RnBDfkoMR4YsC8y2Wmz7oH",
          "toolResult": {
            "status": "success",
            "value": {
              "content": [
                {
                  "type": "text",
                  "text": "'/Users/baxen/Development/goose/crates/goose-cli/src' is a directory. Contents:\n\nDirectories:\n  commands/\n  recipes/\n  scenario_tests/\n  session/\n\nFiles:\n  cli.rs\n  lib.rs\n  logging.rs\n  main.rs\n  project_tracker.rs\n  signal.rs\n"
                }
              ],
              "isError": false
            }
          }
        }
      ],
      "metadata": {
        "userVisible": true,
        "agentVisible": true
      }
    },
    {
      "id": "msg_905348ce-20b1-4129-a45c-2f8912fef1d9",
      "role": "user",
      "created": 1766962610,
      "content": [
        {
          "type": "toolResponse",
          "id": "toolu_01HFKTFHkrcgxBShMRSb2Vyp",
          "toolResult": {
            "status": "success",
            "value": {
              "content": [
                {
                  "type": "text",
                  "text": "'/Users/baxen/Development/goose/crates/goose/src' is a directory. Contents:\n\nDirectories:\n  agents/\n  config/\n  context_mgmt/\n  conversation/\n  execution/\n  goose_apps/\n  hints/\n  oauth/\n  permission/\n  prompts/\n  providers/\n  recipe/\n  security/\n  session/\n  tracing/\n\nFiles:\n  action_required_manager.rs\n  lib.rs\n  logging.rs\n  mcp_utils.rs\n  model.rs\n  posthog.rs\n  prompt_template.rs\n  recipe_deeplink.rs\n  scheduler.rs\n  scheduler_trait.rs\n  session_context.rs\n  slash_commands.rs\n  subprocess.rs\n  token_counter.rs\n  tool_inspection.rs\n  tool_monitor.rs\n  utils.rs\n"
                }
              ],
              "isError": false
            }
          }
        }
      ],
      "metadata": {
        "userVisible": true,
        "agentVisible": true
      }
    },
    {
      "id": "msg_01MHDuSnhRun5bpNKdgUzDY1",
      "role": "assistant",
      "created": 1766962614,
      "content": [
        {
          "type": "toolRequest",
          "id": "toolu_01SC86DjjNSS86DGKKjdfUbW",
          "toolCall": {
            "status": "success",
            "value": {
              "name": "developer__text_editor",
              "arguments": {
                "command": "view",
                "path": "/Users/baxen/Development/goose/crates/goose-cli/src/main.rs"
              }
            }
          }
        },
        {
          "type": "toolRequest",
          "id": "toolu_01Bg7pJCMvsaV32cbGoAooiu",
          "toolCall": {
            "status": "success",
            "value": {
              "name": "developer__text_editor",
              "arguments": {
                "command": "view",
                "path": "/Users/baxen/Development/goose/crates/goose-cli/src/cli.rs"
              }
            }
          }
        },
        {
          "type": "toolRequest",
          "id": "toolu_01U6qotsW281FRMNfG3Q5LAR",
          "toolCall": {
            "status": "success",
            "value": {
              "name": "developer__text_editor",
              "arguments": {
                "command": "view",
                "path": "/Users/baxen/Development/goose/crates/goose-cli/src/session"
              }
            }
          }
        }
      ],
      "metadata": {
        "userVisible": true,
        "agentVisible": true
      }
    },
    {
      "id": "msg_498652ad-aa2d-44d3-98a0-16e161e5a9f9",
      "role": "user",
      "created": 1766962614,
      "content": [
        {
          "type": "toolResponse",
          "id": "toolu_01SC86DjjNSS86DGKKjdfUbW",
          "toolResult": {
            "status": "success",
            "value": {
              "content": [
                {
                  "type": "resource",
                  "resource": {
                    "uri": "file:///Users/baxen/Development/goose/crates/goose-cli/src/main.rs",
                    "mimeType": "text",
                    "text": "use anyhow::Result;\nuse goose_cli::cli::cli;\n\n#[tokio::main]\nasync fn main() -> Result<()> {\n    if let Err(e) = goose_cli::logging::setup_logging(None, None) {\n        eprintln!(\"Warning: Failed to initialize logging: {}\", e);\n    }\n\n    let result = cli().await;\n\n    // Only wait for telemetry flush if OTLP is configured\n    let should_wait = goose::config::Config::global()\n        .get_param::<String>(\"otel_exporter_otlp_endpoint\")\n        .is_ok();\n\n    if should_wait {\n        // Use a shorter, dynamic wait with max timeout\n        let max_wait = tokio::time::Duration::from_millis(500);\n        let start = tokio::time::Instant::now();\n\n        // Give telemetry a chance to flush, but don't wait too long\n        while start.elapsed() < max_wait {\n            tokio::time::sleep(tokio::time::Duration::from_millis(50)).await;\n\n            // In future, we could check if there are pending spans/metrics here\n            // For now, we just do a quick wait to allow batch exports to complete\n            if start.elapsed() >= tokio::time::Duration::from_millis(200) {\n                break; // Most exports should complete within 200ms\n            }\n        }\n\n        goose::tracing::shutdown_otlp();\n    }\n\n    result\n}\n"
                  },
                  "annotations": {
                    "audience": [
                      "assistant"
                    ]
                  }
                },
                {
                  "type": "text",
                  "text": "### /Users/baxen/Development/goose/crates/goose-cli/src/main.rs\n```rust\n1: use anyhow::Result;\n2: use goose_cli::cli::cli;\n3: \n4: #[tokio::main]\n5: async fn main() -> Result<()> {\n6:     if let Err(e) = goose_cli::logging::setup_logging(None, None) {\n7:         eprintln!(\"Warning: Failed to initialize logging: {}\", e);\n8:     }\n9: \n10:     let result = cli().await;\n11: \n12:     // Only wait for telemetry flush if OTLP is configured\n13:     let should_wait = goose::config::Config::global()\n14:         .get_param::<String>(\"otel_exporter_otlp_endpoint\")\n15:         .is_ok();\n16: \n17:     if should_wait {\n18:         // Use a shorter, dynamic wait with max timeout\n19:         let max_wait = tokio::time::Duration::from_millis(500);\n20:         let start = tokio::time::Instant::now();\n21: \n22:         // Give telemetry a chance to flush, but don't wait too long\n23:         while start.elapsed() < max_wait {\n24:             tokio::time::sleep(tokio::time::Duration::from_millis(50)).await;\n25: \n26:             // In future, we could check if there are pending spans/metrics here\n27:             // For now, we just do a quick wait to allow batch exports to complete\n28:             if start.elapsed() >= tokio::time::Duration::from_millis(200) {\n29:                 break; // Most exports should complete within 200ms\n30:             }\n31:         }\n32: \n33:         goose::tracing::shutdown_otlp();\n34:     }\n35: \n36:     result\n37: }\n```\n",
                  "annotations": {
                    "audience": [
                      "user"
                    ],
                    "priority": 0.0
                  }
                }
              ],
              "isError": false
            }
          }
        }
      ],
      "metadata": {
        "userVisible": true,
        "agentVisible": true
      }
    },
    {
      "id": "msg_ac0dac05-33ae-401e-8730-844a3382cd29",
      "role": "user",
      "created": 1766962614,
      "content": [
        {
          "type": "toolResponse",
          "id": "toolu_01Bg7pJCMvsaV32cbGoAooiu",
          "toolResult": {
            "status": "success",
            "value": {
              "content": [
                {
                  "type": "resource",
                  "resource": {
                    "uri": "file:///Users/baxen/Development/goose/crates/goose-cli/src/cli.rs",
                    "mimeType": "text",
                    "text": "use anyhow::Result;\nuse clap::{Args, Parser, Subcommand};\n\nuse goose::config::{Config, ExtensionConfig};\nuse goose_mcp::mcp_server_runner::{serve, McpCommand};\nuse goose_mcp::{\n    AutoVisualiserRouter, ComputerControllerServer, DevelopServer, DeveloperServer, MemoryServer,\n    TutorialServer,\n};\n\nuse crate::commands::acp::run_acp_agent;\nuse crate::commands::bench::agent_generator;\nuse crate::commands::configure::handle_configure;\nuse crate::commands::info::handle_info;\nuse crate::commands::project::{handle_project_default, handle_projects_interactive};\nuse crate::commands::recipe::{handle_deeplink, handle_list, handle_open, handle_validate};\nuse crate::commands::term::{\n    handle_term_info, handle_term_init, handle_term_log, handle_term_run, Shell,\n};\n\nuse crate::commands::schedule::{\n    handle_schedule_add, handle_schedule_cron_help, handle_schedule_list, handle_schedule_remove,\n    handle_schedule_run_now, handle_schedule_services_status, handle_schedule_services_stop,\n    handle_schedule_sessions,\n};\nuse crate::commands::session::{handle_session_list, handle_session_remove};\nuse crate::recipes::extract_from_cli::extract_recipe_info_from_cli;\nuse crate::recipes::recipe::{explain_recipe, render_recipe_as_yaml};\nuse crate::session::{build_session, SessionBuilderConfig, SessionSettings};\nuse goose::session::session_manager::SessionType;\nuse goose::session::SessionManager;\nuse goose_bench::bench_config::BenchRunConfig;\nuse goose_bench::runners::bench_runner::BenchRunner;\nuse goose_bench::runners::eval_runner::EvalRunner;\nuse goose_bench::runners::metric_aggregator::MetricAggregator;\nuse goose_bench::runners::model_runner::ModelRunner;\nuse std::io::Read;\nuse std::path::PathBuf;\nuse tracing::warn;\n\n#[derive(Parser)]\n#[command(author, version, display_name = \"\", about, long_about = None)]\nstruct Cli {\n    #[command(subcommand)]\n    command: Option<Command>,\n}\n\n#[derive(Args, Debug, Clone)]\n#[group(required = false, multiple = false)]\npub struct Identifier {\n    #[arg(\n        short = 'n',\n        long,\n        value_name = \"NAME\",\n        help = \"Name for the chat session (e.g., 'project-x')\",\n        long_help = \"Specify a name for your chat session. When used with --resume, will resume this specific session if it exists.\"\n    )]\n    pub name: Option<String>,\n\n    #[arg(\n        long = \"session-id\",\n        alias = \"id\",\n        value_name = \"SESSION_ID\",\n        help = \"Session ID (e.g., '20250921_143022')\",\n        long_help = \"Specify a session ID directly. When used with --resume, will resume this specific session if it exists.\"\n    )]\n    pub session_id: Option<String>,\n\n    #[arg(\n        long,\n        value_name = \"PATH\",\n        help = \"Legacy: Path for the chat session\",\n        long_help = \"Legacy parameter for backward compatibility. Extracts session ID from the file path (e.g., '/path/to/20250325_200615.\njsonl' -> '20250325_200615').\"\n    )]\n    pub path: Option<PathBuf>,\n}\n\nasync fn get_or_create_session_id(\n    identifier: Option<Identifier>,\n    resume: bool,\n    no_session: bool,\n) -> Result<Option<String>> {\n    if no_session {\n        return Ok(None);\n    }\n\n    let Some(id) = identifier else {\n        return if resume {\n            let sessions = SessionManager::list_sessions().await?;\n            let session_id = sessions\n                .first()\n                .map(|s| s.id.clone())\n                .ok_or_else(|| anyhow::anyhow!(\"No session found to resume\"))?;\n            Ok(Some(session_id))\n        } else {\n            let session = SessionManager::create_session(\n                std::env::current_dir()?,\n                \"CLI Session\".to_string(),\n                SessionType::User,\n            )\n            .await?;\n            Ok(Some(session.id))\n        };\n    };\n\n    if let Some(session_id) = id.session_id {\n        Ok(Some(session_id))\n    } else if let Some(name) = id.name {\n        if resume {\n            let sessions = SessionManager::list_sessions().await?;\n            let session_id = sessions\n                .into_iter()\n                .find(|s| s.name == name || s.id == name)\n                .map(|s| s.id)\n                .ok_or_else(|| anyhow::anyhow!(\"No session found with name '{}'\", name))?;\n            Ok(Some(session_id))\n        } else {\n            let session = SessionManager::create_session(\n                std::env::current_dir()?,\n                name.clone(),\n                SessionType::User,\n            )\n            .await?;\n\n            SessionManager::update_session(&session.id)\n                .user_provided_name(name)\n                .apply()\n                .await?;\n\n            Ok(Some(session.id))\n        }\n    } else if let Some(path) = id.path {\n        let session_id = path\n            .file_stem()\n            .and_then(|s| s.to_str())\n            .map(|s| s.to_string())\n            .ok_or_else(|| anyhow::anyhow!(\"Could not extract session ID from path: {:?}\", path))?;\n        Ok(Some(session_id))\n    } else {\n        let session = SessionManager::create_session(\n            std::env::current_dir()?,\n            \"CLI Session\".to_string(),\n            SessionType::User,\n        )\n        .await?;\n        Ok(Some(session.id))\n    }\n}\n\nasync fn lookup_session_id(identifier: Identifier) -> Result<String> {\n    if let Some(session_id) = identifier.session_id {\n        Ok(session_id)\n    } else if let Some(name) = identifier.name {\n        let sessions = SessionManager::list_sessions().await?;\n        sessions\n            .into_iter()\n            .find(|s| s.name == name || s.id == name)\n            .map(|s| s.id)\n            .ok_or_else(|| anyhow::anyhow!(\"No session found with name '{}'\", name))\n    } else if let Some(path) = identifier.path {\n        path.file_stem()\n            .and_then(|s| s.to_str())\n            .map(|s| s.to_string())\n            .ok_or_else(|| anyhow::anyhow!(\"Could not extract session ID from path: {:?}\", path))\n    } else {\n        Err(anyhow::anyhow!(\"No identifier provided\"))\n    }\n}\n\nfn parse_key_val(s: &str) -> Result<(String, String), String> {\n    match s.split_once('=') {\n        Some((key, value)) => Ok((key.to_string(), value.to_string())),\n        None => Err(format!(\"invalid KEY=VALUE: {}\", s)),\n    }\n}\n\n#[derive(Subcommand)]\nenum SessionCommand {\n    #[command(about = \"List all available sessions\")]\n    List {\n        #[arg(\n            short,\n            long,\n            help = \"Output format (text, json)\",\n            default_value = \"text\"\n        )]\n        format: String,\n\n        #[arg(\n            long = \"ascending\",\n            help = \"Sort by date in ascending order (oldest first)\",\n            long_help = \"Sort sessions by date in ascending order (oldest first). Default is descending order (newest first).\"\n        )]\n        ascending: bool,\n\n        #[arg(\n            short = 'w',\n            short_alias = 'p',\n            long = \"working_dir\",\n            help = \"Filter sessions by working directory\"\n        )]\n        working_dir: Option<PathBuf>,\n\n        #[arg(short = 'l', long = \"limit\", help = \"Limit the number of results\")]\n        limit: Option<usize>,\n    },\n    #[command(about = \"Remove sessions. Runs interactively if no ID, name, or regex is provided.\")]\n    Remove {\n        #[command(flatten)]\n        identifier: Option<Identifier>,\n        #[arg(\n            short = 'r',\n            long,\n            help = \"Regex for removing matched sessions (optional)\"\n        )]\n        regex: Option<String>,\n    },\n    #[command(about = \"Export a session\")]\n    Export {\n        #[command(flatten)]\n        identifier: Option<Identifier>,\n\n        #[arg(\n            short,\n            long,\n            help = \"Output file path (default: stdout)\",\n            long_help = \"Path to save the exported Markdown. If not provided, output will be sent to stdout\"\n        )]\n        output: Option<PathBuf>,\n\n        #[arg(\n            long = \"format\",\n            value_name = \"FORMAT\",\n            help = \"Output format (markdown, json, yaml)\",\n            default_value = \"markdown\"\n        )]\n        format: String,\n    },\n    #[command(name = \"diagnostics\")]\n    Diagnostics {\n        /// Session identifier for generating diagnostics\n        #[command(flatten)]\n        identifier: Option<Identifier>,\n\n        /// Output path for the diagnostics zip file (optional, defaults to current directory)\n        #[arg(short = 'o', long)]\n        output: Option<PathBuf>,\n    },\n}\n\n#[derive(Subcommand, Debug)]\nenum SchedulerCommand {\n    #[command(about = \"Add a new scheduled job\")]\n    Add {\n        #[arg(\n            long = \"schedule-id\",\n            alias = \"id\",\n            help = \"Unique ID for the recurring scheduled job\"\n        )]\n        schedule_id: String,\n        #[arg(\n            long,\n            help = \"Cron expression for the schedule\",\n            long_help = \"Cron expression for when to run the job. Examples:\\n  '0 * * * *'     - Every hour at minute 0\\n  '0 */2 * * *'   - Every 2 hours\\n  '@hourly'       - Every hour (shorthand)\\n  '0 9 * * *'     - Every day at 9:00 AM\\n  '0 9 * * 1'     - Every Monday at 9:00 AM\\n  '0 0 1 * *'     - First day of every month at midnight\"\n        )]\n        cron: String,\n        #[arg(\n            long,\n            help = \"Recipe source (path to file, or base64 encoded recipe string)\"\n        )]\n        recipe_source: String,\n    },\n    #[command(about = \"List all scheduled jobs\")]\n    List {},\n    #[command(about = \"Remove a scheduled job by ID\")]\n    Remove {\n        #[arg(\n            long = \"schedule-id\",\n            alias = \"id\",\n            help = \"ID of the scheduled job to remove (removes the recurring schedule)\"\n        )]\n        schedule_id: String,\n    },\n    /// List sessions created by a specific schedule\n    #[command(about = \"List sessions created by a specific schedule\")]\n    Sessions {\n        /// ID of the schedule\n        #[arg(long = \"schedule-id\", alias = \"id\", help = \"ID of the schedule\")]\n        schedule_id: String,\n        #[arg(short = 'l', long, help = \"Maximum number of sessions to return\")]\n        limit: Option<usize>,\n    },\n    #[command(about = \"Run a scheduled job immediately\")]\n    RunNow {\n        /// ID of the schedule to run\n        #[arg(long = \"schedule-id\", alias = \"id\", help = \"ID of the schedule to run\")]\n        schedule_id: String,\n    },\n    /// Check status of scheduler services (deprecated - no external services needed)\n    #[command(about = \"[Deprecated] Check status of scheduler services\")]\n    ServicesStatus {},\n    /// Stop scheduler services (deprecated - no external services needed)\n    #[command(about = \"[Deprecated] Stop scheduler services\")]\n    ServicesStop {},\n    /// Show cron expression examples and help\n    #[command(about = \"Show cron expression examples and help\")]\n    CronHelp {},\n}\n\n#[derive(Subcommand)]\npub enum BenchCommand {\n    #[command(name = \"init-config\", about = \"Create a new starter-config\")]\n    InitConfig {\n        #[arg(short, long, help = \"filename with extension for generated config\")]\n        name: String,\n    },\n\n    #[command(about = \"Run all benchmarks from a config\")]\n    Run {\n        #[arg(\n            short,\n            long,\n            help = \"A config file generated by the config-init command\"\n        )]\n        config: PathBuf,\n    },\n\n    #[command(about = \"List all available selectors\")]\n    Selectors {\n        #[arg(\n            short,\n            long,\n            help = \"A config file generated by the config-init command\"\n        )]\n        config: Option<PathBuf>,\n    },\n\n    #[command(name = \"eval-model\", about = \"Run an eval of model\")]\n    EvalModel {\n        #[arg(short, long, help = \"A serialized config file for the model only.\")]\n        config: String,\n    },\n\n    #[command(name = \"exec-eval\", about = \"run a single eval\")]\n    ExecEval {\n        #[arg(short, long, help = \"A serialized config file for the eval only.\")]\n        config: String,\n    },\n\n    #[command(\n        name = \"generate-leaderboard\",\n        about = \"Generate a leaderboard CSV from benchmark results\"\n    )]\n    GenerateLeaderboard {\n        #[arg(\n            short,\n            long,\n            help = \"Path to the benchmark directory containing model evaluation results\"\n        )]\n        benchmark_dir: PathBuf,\n    },\n}\n\n#[derive(Subcommand)]\nenum RecipeCommand {\n    /// Validate a recipe file\n    #[command(about = \"Validate a recipe\")]\n    Validate {\n        /// Recipe name to get recipe file to validate\n        #[arg(help = \"recipe name to get recipe file or full path to the recipe file to validate\")]\n        recipe_name: String,\n    },\n\n    /// Generate a deeplink for a recipe file\n    #[command(about = \"Generate a deeplink for a recipe\")]\n    Deeplink {\n        /// Recipe name to get recipe file to generate deeplink\n        #[arg(\n            help = \"recipe name to get recipe file or full path to the recipe file to generate deeplink\"\n        )]\n        recipe_name: String,\n        /// Recipe parameters in key=value format (can be specified multiple times)\n        #[arg(\n            short = 'p',\n            long = \"param\",\n            value_name = \"KEY=VALUE\",\n            help = \"Recipe parameter in key=value format (can be specified multiple times)\"\n        )]\n        params: Vec<String>,\n    },\n\n    /// Open a recipe in Goose Desktop\n    #[command(about = \"Open a recipe in Goose Desktop\")]\n    Open {\n        /// Recipe name to get recipe file to open\n        #[arg(help = \"recipe name or full path to the recipe file\")]\n        recipe_name: String,\n        /// Recipe parameters in key=value format (can be specified multiple times)\n        #[arg(\n            short = 'p',\n            long = \"param\",\n            value_name = \"KEY=VALUE\",\n            help = \"Recipe parameter in key=value format (can be specified multiple times)\"\n        )]\n        params: Vec<String>,\n    },\n\n    /// List available recipes\n    #[command(about = \"List available recipes\")]\n    List {\n        /// Output format (text, json)\n        #[arg(\n            long = \"format\",\n            value_name = \"FORMAT\",\n            help = \"Output format (text, json)\",\n            default_value = \"text\"\n        )]\n        format: String,\n\n        /// Show verbose information including recipe descriptions\n        #[arg(\n            short,\n            long,\n            help = \"Show verbose information including recipe descriptions\"\n        )]\n        verbose: bool,\n    },\n}\n\n#[derive(Subcommand)]\nenum Command {\n    /// Configure goose settings\n    #[command(about = \"Configure goose settings\")]\n    Configure {},\n\n    /// Display goose configuration information\n    #[command(about = \"Display goose information\")]\n    Info {\n        /// Show verbose information including current configuration\n        #[arg(short, long, help = \"Show verbose information including config.yaml\")]\n        verbose: bool,\n    },\n\n    /// Manage system prompts and behaviors\n    #[command(about = \"Run one of the mcp servers bundled with goose\")]\n    Mcp {\n        #[arg(value_parser = clap::value_parser!(McpCommand))]\n        server: McpCommand,\n    },\n\n    /// Run goose as an ACP (Agent Client Protocol) agent\n    #[command(about = \"Run goose as an ACP agent server on stdio\")]\n    Acp {},\n\n    /// Start or resume interactive chat sessions\n    #[command(\n        about = \"Start or resume interactive chat sessions\",\n        visible_alias = \"s\"\n    )]\n    Session {\n        #[command(subcommand)]\n        command: Option<SessionCommand>,\n        /// Identifier for the chat session\n        #[command(flatten)]\n        identifier: Option<Identifier>,\n\n        /// Resume a previous session\n        #[arg(\n            short,\n            long,\n            help = \"Resume a previous session (last used or specified by --name/--session-id)\",\n            long_help = \"Continue from a previous session. If --name or --session-id is provided, resumes that specific session. Otherwise resumes the most recently used session.\"\n        )]\n        resume: bool,\n\n        /// Show message history when resuming\n        #[arg(\n            long,\n            help = \"Show previous messages when resuming a session\",\n            requires = \"resume\"\n        )]\n        history: bool,\n\n        /// Enable debug output mode\n        #[arg(\n            long,\n            help = \"Enable debug output mode with full content and no truncation\",\n            long_help = \"When enabled, shows complete tool responses without truncation and full paths.\"\n        )]\n        debug: bool,\n\n        /// Maximum number of consecutive identical tool calls allowed\n        #[arg(\n            long = \"max-tool-repetitions\",\n            value_name = \"NUMBER\",\n            help = \"Maximum number of consecutive identical tool calls allowed\",\n            long_help = \"Set a limit on how many times the same tool can be called consecutively with identical parameters. Helps prevent infinite loops.\"\n        )]\n        max_tool_repetitions: Option<u32>,\n\n        /// Maximum number of turns (iterations) allowed in a single response\n        #[arg(\n            long = \"max-turns\",\n            value_name = \"NUMBER\",\n            help = \"Maximum number of turns allowed without user input (default: 1000)\",\n            long_help = \"Set a limit on how many turns (iterations) the agent can take without asking for user input to continue.\"\n        )]\n        max_turns: Option<u32>,\n\n        /// Add stdio extensions with environment variables and commands\n        #[arg(\n            long = \"with-extension\",\n            value_name = \"COMMAND\",\n            help = \"Add stdio extensions (can be specified multiple times)\",\n            long_help = \"Add stdio extensions from full commands with environment variables. Can be specified multiple times. Format: 'ENV1=val1 ENV2=val2 command args...'\",\n            action = clap::ArgAction::Append\n        )]\n        extensions: Vec<String>,\n\n        /// Add remote extensions with a URL\n        #[arg(\n            long = \"with-remote-extension\",\n            value_name = \"URL\",\n            help = \"Add remote extensions (can be specified multiple times)\",\n            long_help = \"Add remote extensions from a URL. Can be specified multiple times. Format: 'url...'\",\n            action = clap::ArgAction::Append\n        )]\n        remote_extensions: Vec<String>,\n\n        /// Add streamable HTTP extensions with a URL\n        #[arg(\n            long = \"with-streamable-http-extension\",\n            value_name = \"URL\",\n            help = \"Add streamable HTTP extensions (can be specified multiple times)\",\n            long_help = \"Add streamable HTTP extensions from a URL. Can be specified multiple times. Format: 'url...'\",\n            action = clap::ArgAction::Append\n        )]\n        streamable_http_extensions: Vec<String>,\n\n        /// Add builtin extensions by name\n        #[arg(\n            long = \"with-builtin\",\n            value_name = \"NAME\",\n            help = \"Add builtin extensions by name (e.g., 'developer' or multiple: 'developer,github')\",\n            long_help = \"Add one or more builtin extensions that are bundled with goose by specifying their names, comma-separated\",\n            value_delimiter = ','\n        )]\n        builtins: Vec<String>,\n    },\n\n    /// Open the last project directory\n    #[command(about = \"Open the last project directory\", visible_alias = \"p\")]\n    Project {},\n\n    /// List recent project directories\n    #[command(about = \"List recent project directories\", visible_alias = \"ps\")]\n    Projects,\n\n    /// Execute commands from an instruction file\n    #[command(about = \"Execute commands from an instruction file or stdin\")]\n    Run {\n        /// Path to instruction file containing commands\n        #[arg(\n            short,\n            long,\n            value_name = \"FILE\",\n            help = \"Path to instruction file containing commands. Use - for stdin.\",\n            conflicts_with = \"input_text\",\n            conflicts_with = \"recipe\"\n        )]\n        instructions: Option<String>,\n\n        /// Input text containing commands\n        #[arg(\n            short = 't',\n            long = \"text\",\n            value_name = \"TEXT\",\n            help = \"Input text to provide to goose directly\",\n            long_help = \"Input text containing commands for goose. Use this in lieu of the instructions argument.\",\n            conflicts_with = \"instructions\",\n            conflicts_with = \"recipe\"\n        )]\n        input_text: Option<String>,\n\n        /// Additional system prompt to customize agent behavior\n        #[arg(\n            long = \"system\",\n            value_name = \"TEXT\",\n            help = \"Additional system prompt to customize agent behavior\",\n            long_help = \"Provide additional system instructions to customize the agent's behavior\",\n            conflicts_with = \"recipe\"\n        )]\n        system: Option<String>,\n\n        /// Recipe name or full path to the recipe file\n        #[arg(\n            short = None,\n            long = \"recipe\",\n            value_name = \"RECIPE_NAME or FULL_PATH_TO_RECIPE_FILE\",\n            help = \"Recipe name to get recipe file or the full path of the recipe file (use --explain to see recipe details)\",\n            long_help = \"Recipe name to get recipe file or the full path of the recipe file that defines a custom agent configuration. Use --explain to see the recipe's title, description, and parameters.\",\n            conflicts_with = \"instructions\",\n            conflicts_with = \"input_text\"\n        )]\n        recipe: Option<String>,\n\n        #[arg(\n            long,\n            value_name = \"KEY=VALUE\",\n            help = \"Dynamic parameters (e.g., --params username=alice --params channel_name=goose-channel)\",\n            long_help = \"Key-value parameters to pass to the recipe file. Can be specified multiple times.\",\n            action = clap::ArgAction::Append,\n            value_parser = parse_key_val,\n        )]\n        params: Vec<(String, String)>,\n\n        /// Continue in interactive mode after processing input\n        #[arg(\n            short = 's',\n            long = \"interactive\",\n            help = \"Continue in interactive mode after processing initial input\"\n        )]\n        interactive: bool,\n\n        /// Run without storing a session file\n        #[arg(\n            long = \"no-session\",\n            help = \"Run without storing a session file\",\n            long_help = \"Execute commands without creating or using a session file. Useful for automated runs.\",\n            conflicts_with_all = [\"resume\", \"name\", \"path\"]\n        )]\n        no_session: bool,\n\n        /// Show the recipe title, description, and parameters\n        #[arg(\n            long = \"explain\",\n            help = \"Show the recipe title, description, and parameters\"\n        )]\n        explain: bool,\n\n        /// Print the rendered recipe instead of running it\n        #[arg(\n            long = \"render-recipe\",\n            help = \"Print the rendered recipe instead of running it.\"\n        )]\n        render_recipe: bool,\n\n        /// Maximum number of consecutive identical tool calls allowed\n        #[arg(\n            long = \"max-tool-repetitions\",\n            value_name = \"NUMBER\",\n            help = \"Maximum number of consecutive identical tool calls allowed\",\n            long_help = \"Set a limit on how many times the same tool can be called consecutively with identical parameters. Helps prevent infinite loops.\"\n        )]\n        max_tool_repetitions: Option<u32>,\n\n        /// Maximum number of turns (iterations) allowed in a single response\n        #[arg(\n            long = \"max-turns\",\n            value_name = \"NUMBER\",\n            help = \"Maximum number of turns allowed without user input (default: 1000)\",\n            long_help = \"Set a limit on how many turns (iterations) the agent can take without asking for user input to continue.\"\n        )]\n        max_turns: Option<u32>,\n\n        /// Identifier for this run session\n        #[command(flatten)]\n        identifier: Option<Identifier>,\n\n        /// Resume a previous run\n        #[arg(\n            short,\n            long,\n            action = clap::ArgAction::SetTrue,\n            help = \"Resume from a previous run\",\n            long_help = \"Continue from a previous run, maintaining the execution state and context.\"\n        )]\n        resume: bool,\n\n        /// Enable debug output mode\n        #[arg(\n            long,\n            help = \"Enable debug output mode with full content and no truncation\",\n            long_help = \"When enabled, shows complete tool responses without truncation and full paths.\"\n        )]\n        debug: bool,\n\n        /// Add stdio extensions with environment variables and commands\n        #[arg(\n            long = \"with-extension\",\n            value_name = \"COMMAND\",\n            help = \"Add stdio extensions (can be specified multiple times)\",\n            long_help = \"Add stdio extensions from full commands with environment variables. Can be specified multiple times. Format: 'ENV1=val1 ENV2=val2 command args...'\",\n            action = clap::ArgAction::Append\n        )]\n        extensions: Vec<String>,\n\n        /// Add remote extensions\n        #[arg(\n            long = \"with-remote-extension\",\n            value_name = \"URL\",\n            help = \"Add remote extensions (can be specified multiple times)\",\n            long_help = \"Add remote extensions. Can be specified multiple times. Format: 'url...'\",\n            action = clap::ArgAction::Append\n        )]\n        remote_extensions: Vec<String>,\n\n        /// Add streamable HTTP extensions\n        #[arg(\n            long = \"with-streamable-http-extension\",\n            value_name = \"URL\",\n            help = \"Add streamable HTTP extensions (can be specified multiple times)\",\n            long_help = \"Add streamable HTTP extensions. Can be specified multiple times. Format: 'url...'\",\n            action = clap::ArgAction::Append\n        )]\n        streamable_http_extensions: Vec<String>,\n\n        /// Add builtin extensions by name\n        #[arg(\n            long = \"with-builtin\",\n            value_name = \"NAME\",\n            help = \"Add builtin extensions by name (e.g., 'developer' or multiple: 'developer,github')\",\n            long_help = \"Add one or more builtin extensions that are bundled with goose by specifying their names, comma-separated\",\n            value_delimiter = ','\n        )]\n        builtins: Vec<String>,\n\n        /// Quiet mode - suppress non-response output\n        #[arg(\n            short = 'q',\n            long = \"quiet\",\n            help = \"Quiet mode. Suppress non-response output, printing only the model response to stdout\"\n        )]\n        quiet: bool,\n\n        /// Scheduled job ID (used internally for scheduled executions)\n        #[arg(\n            long = \"scheduled-job-id\",\n            value_name = \"ID\",\n            help = \"ID of the scheduled job that triggered this execution (internal use)\",\n            long_help = \"Internal parameter used when this run command is executed by a scheduled job. This associates the session with the schedule for tracking purposes.\",\n            hide = true\n        )]\n        scheduled_job_id: Option<String>,\n\n        /// Additional sub-recipe file paths\n        #[arg(\n            long = \"sub-recipe\",\n            value_name = \"RECIPE\",\n            help = \"Sub-recipe name or file path (can be specified multiple times)\",\n            long_help = \"Specify sub-recipes to include alongside the main recipe. Can be:\\n  - Recipe names from GitHub (if GOOSE_RECIPE_GITHUB_REPO is configured)\\n  - Local file paths to YAML files\\nCan be specified multiple times to include multiple sub-recipes.\",\n            action = clap::ArgAction::Append\n        )]\n        additional_sub_recipes: Vec<String>,\n\n        /// Output format (text, json, stream-json)\n        #[arg(\n            long = \"output-format\",\n            value_name = \"FORMAT\",\n            help = \"Output format (text, json, stream-json)\",\n            default_value = \"text\",\n            value_parser = clap::builder::PossibleValuesParser::new([\"text\", \"json\", \"stream-json\"])\n        )]\n        output_format: String,\n\n        /// Provider to use for this run (overrides environment variable)\n        #[arg(\n            long = \"provider\",\n            value_name = \"PROVIDER\",\n            help = \"Specify the LLM provider to use (e.g., 'openai', 'anthropic')\",\n            long_help = \"Override the GOOSE_PROVIDER environment variable for this run. Available providers include openai, anthropic, ollama, databricks, gemini-cli, claude-code, and others.\"\n        )]\n        provider: Option<String>,\n\n        /// Model to use for this run (overrides environment variable)\n        #[arg(\n            long = \"model\",\n            value_name = \"MODEL\",\n            help = \"Specify the model to use (e.g., 'gpt-4o', 'claude-sonnet-4-20250514')\",\n            long_help = \"Override the GOOSE_MODEL environment variable for this run. The model must be supported by the specified provider.\"\n        )]\n        model: Option<String>,\n    },\n\n    /// Recipe utilities for validation and deeplinking\n    #[command(about = \"Recipe utilities for validation and deeplinking\")]\n    Recipe {\n        #[command(subcommand)]\n        command: RecipeCommand,\n    },\n\n    /// Manage scheduled jobs\n    #[command(about = \"Manage scheduled jobs\", visible_alias = \"sched\")]\n    Schedule {\n        #[command(subcommand)]\n        command: SchedulerCommand,\n    },\n\n    /// Update the goose CLI version\n    #[command(about = \"Update the goose CLI version\")]\n    Update {\n        /// Update to canary version\n        #[arg(\n            short,\n            long,\n            help = \"Update to canary version\",\n            long_help = \"Update to the latest canary version of the goose CLI, otherwise updates to the latest stable version.\"\n        )]\n        canary: bool,\n\n        /// Enforce to re-configure goose during update\n        #[arg(short, long, help = \"Enforce to re-configure goose during update\")]\n        reconfigure: bool,\n    },\n\n    /// Evaluate system configuration across a range of practical tasks\n    #[command(about = \"Evaluate system configuration across a range of practical tasks\")]\n    Bench {\n        #[command(subcommand)]\n        cmd: BenchCommand,\n    },\n\n    /// Start a web server with a chat interface\n    #[command(about = \"Experimental: Start a web server with a chat interface\")]\n    Web {\n        /// Port to run the web server on\n        #[arg(\n            short,\n            long,\n            default_value = \"3000\",\n            help = \"Port to run the web server on\"\n        )]\n        port: u16,\n\n        /// Host to bind the web server to\n        #[arg(\n            long,\n            default_value = \"127.0.0.1\",\n            help = \"Host to bind the web server to\"\n        )]\n        host: String,\n\n        /// Open browser automatically\n        #[arg(long, help = \"Open browser automatically when server starts\")]\n        open: bool,\n\n        /// Authentication token for both Basic Auth (password) and Bearer token\n        #[arg(long, help = \"Authentication token to secure the web interface\")]\n        auth_token: Option<String>,\n    },\n\n    /// Terminal-integrated session (one session per terminal)\n    #[command(\n        about = \"Terminal-integrated goose session\",\n        long_about = \"Runs a goose session tied to your terminal window.\\n\\\n                      Each terminal maintains its own persistent session that resumes automatically.\\n\\n\\\n                      Setup:\\n  \\\n                        eval \\\"$(goose term init zsh)\\\"  # Add to ~/.zshrc\\n\\n\\\n                      Usage:\\n  \\\n                        goose term run \\\"list files in this directory\\\"\\n  \\\n                        @goose \\\"create a python script\\\"  # using alias\\n  \\\n                        @g \\\"quick question\\\"  # short alias\"\n    )]\n    Term {\n        #[command(subcommand)]\n        command: TermCommand,\n    },\n}\n\n#[derive(Subcommand)]\nenum TermCommand {\n    /// Print shell initialization script\n    #[command(\n        about = \"Print shell initialization script\",\n        long_about = \"Prints shell configuration to set up terminal-integrated sessions.\\n\\\n                      Each terminal gets a persistent goose session that automatically resumes.\\n\\n\\\n                      Setup:\\n  \\\n                        echo 'eval \\\"$(goose term init zsh)\\\"' >> ~/.zshrc\\n  \\\n                        source ~/.zshrc\\n\\n\\\n                      With --default (anything typed that isn't a command goes to goose):\\n  \\\n                        echo 'eval \\\"$(goose term init zsh --default)\\\"' >> ~/.zshrc\"\n    )]\n    Init {\n        /// Shell type (bash, zsh, fish, powershell)\n        #[arg(value_enum)]\n        shell: Shell,\n\n        #[arg(short, long, help = \"Name for the terminal session\")]\n        name: Option<String>,\n\n        /// Make goose the default handler for unknown commands\n        #[arg(\n            long = \"default\",\n            help = \"Make goose the default handler for unknown commands\",\n            long_help = \"When enabled, anything you type that isn't a valid command will be sent to goose. Only supported for zsh and bash.\"\n        )]\n        default: bool,\n    },\n\n    /// Log a shell command (called by shell hook)\n    #[command(about = \"Log a shell command to the session\", hide = true)]\n    Log {\n        /// The command that was executed\n        command: String,\n    },\n\n    /// Run a prompt in the terminal session\n    #[command(\n        about = \"Run a prompt in the terminal session\",\n        long_about = \"Run a prompt in the terminal-integrated session.\\n\\n\\\n                      Examples:\\n  \\\n                        goose term run list files in this directory\\n  \\\n                        @goose list files  # using alias\\n  \\\n                        @g why did that fail  # short alias\"\n    )]\n    Run {\n        /// The prompt to send to goose (multiple words allowed without quotes)\n        #[arg(required = true, num_args = 1..)]\n        prompt: Vec<String>,\n    },\n\n    /// Print session info for prompt integration\n    #[command(\n        about = \"Print session info for prompt integration\",\n        long_about = \"Prints compact session info (token usage, model) for shell prompt integration.\\n\\\n                      Example output: ●○○○○ sonnet\"\n    )]\n    Info,\n}\n\n#[derive(clap::ValueEnum, Clone, Debug)]\nenum CliProviderVariant {\n    OpenAi,\n    Databricks,\n    Ollama,\n}\n\n#[derive(Debug)]\npub struct InputConfig {\n    pub contents: Option<String>,\n    pub extensions_override: Option<Vec<ExtensionConfig>>,\n    pub additional_system_prompt: Option<String>,\n}\n\n#[derive(Debug)]\npub struct RecipeInfo {\n    pub session_settings: Option<SessionSettings>,\n    pub sub_recipes: Option<Vec<goose::recipe::SubRecipe>>,\n    pub final_output_response: Option<goose::recipe::Response>,\n    pub retry_config: Option<goose::agents::types::RetryConfig>,\n}\n\npub async fn cli() -> anyhow::Result<()> {\n    let cli = Cli::parse();\n\n    if let Err(e) = crate::project_tracker::update_project_tracker(None, None) {\n        warn!(\"Warning: Failed to update project tracker: {}\", e);\n    }\n\n    let command_name = match &cli.command {\n        Some(Command::Configure {}) => \"configure\",\n        Some(Command::Info { .. }) => \"info\",\n        Some(Command::Mcp { .. }) => \"mcp\",\n        Some(Command::Acp {}) => \"acp\",\n        Some(Command::Session { .. }) => \"session\",\n        Some(Command::Project {}) => \"project\",\n        Some(Command::Projects) => \"projects\",\n        Some(Command::Run { .. }) => \"run\",\n        Some(Command::Schedule { .. }) => \"schedule\",\n        Some(Command::Update { .. }) => \"update\",\n        Some(Command::Bench { .. }) => \"bench\",\n        Some(Command::Recipe { .. }) => \"recipe\",\n        Some(Command::Web { .. }) => \"web\",\n        Some(Command::Term { .. }) => \"term\",\n        None => \"default_session\",\n    };\n\n    tracing::info!(\n        counter.goose.cli_commands = 1,\n        command = command_name,\n        \"CLI command executed\"\n    );\n\n    match cli.command {\n        Some(Command::Configure {}) => handle_configure().await?,\n        Some(Command::Info { verbose }) => handle_info(verbose)?,\n        Some(Command::Mcp { server }) => {\n            let name = server.name();\n            crate::logging::setup_logging(Some(&format!(\"mcp-{name}\")), None)?;\n            match server {\n                McpCommand::AutoVisualiser => serve(AutoVisualiserRouter::new()).await?,\n                McpCommand::ComputerController => serve(ComputerControllerServer::new()).await?,\n                McpCommand::Develop => serve(DevelopServer::new()).await?,\n                McpCommand::Developer => serve(DeveloperServer::new()).await?,\n                McpCommand::Memory => serve(MemoryServer::new()).await?,\n                McpCommand::Tutorial => serve(TutorialServer::new()).await?,\n            }\n        }\n        Some(Command::Acp {}) => {\n            run_acp_agent().await?;\n        }\n        Some(Command::Session {\n            command,\n            identifier,\n            resume,\n            history,\n            debug,\n            max_tool_repetitions,\n            max_turns,\n            extensions,\n            remote_extensions,\n            streamable_http_extensions,\n            builtins,\n        }) => {\n            return match command {\n                Some(SessionCommand::List {\n                    format,\n                    ascending,\n                    working_dir,\n                    limit,\n                }) => Ok(handle_session_list(format, ascending, working_dir, limit).await?),\n                Some(SessionCommand::Remove { identifier, regex }) => {\n                    let (session_id, name) = if let Some(id) = identifier {\n                        (id.session_id, id.name)\n                    } else {\n                        (None, None)\n                    };\n                    Ok(handle_session_remove(session_id, name, regex).await?)\n                }\n                Some(SessionCommand::Export {\n                    identifier,\n                    output,\n                    format,\n                }) => {\n                    let session_identifier = if let Some(id) = identifier {\n                        lookup_session_id(id).await?\n                    } else {\n                        // If no identifier is provided, prompt for interactive selection\n                        match crate::commands::session::prompt_interactive_session_selection().await\n                        {\n                            Ok(id) => id,\n                            Err(e) => {\n                                eprintln!(\"Error: {}\", e);\n                                return Ok(());\n                            }\n                        }\n                    };\n\n                    crate::commands::session::handle_session_export(\n                        session_identifier,\n                        output,\n                        format,\n                    )\n                    .await?;\n                    Ok(())\n                }\n                Some(SessionCommand::Diagnostics { identifier, output }) => {\n                    let session_id = if let Some(id) = identifier {\n                        lookup_session_id(id).await?\n                    } else {\n                        match crate::commands::session::prompt_interactive_session_selection().await\n                        {\n                            Ok(id) => id,\n                            Err(e) => {\n                                eprintln!(\"Error: {}\", e);\n                                return Ok(());\n                            }\n                        }\n                    };\n                    crate::commands::session::handle_diagnostics(&session_id, output).await?;\n                    Ok(())\n                }\n                None => {\n                    let session_start = std::time::Instant::now();\n                    let session_type = if resume { \"resumed\" } else { \"new\" };\n\n                    tracing::info!(\n                        counter.goose.session_starts = 1,\n                        session_type,\n                        interactive = true,\n                        \"Session started\"\n                    );\n\n                    if let Some(Identifier {\n                        session_id: Some(_),\n                        ..\n                    }) = &identifier\n                    {\n                        if !resume {\n                            eprintln!(\"Error: --session-id can only be used with --resume flag\");\n                            std::process::exit(1);\n                        }\n                    }\n\n                    let session_id = get_or_create_session_id(identifier, resume, false).await?;\n\n                    // Run session command by default\n                    let mut session: crate::CliSession = build_session(SessionBuilderConfig {\n                        session_id,\n                        resume,\n                        no_session: false,\n                        extensions,\n                        remote_extensions,\n                        streamable_http_extensions,\n                        builtins,\n                        extensions_override: None,\n                        additional_system_prompt: None,\n                        settings: None,\n                        provider: None,\n                        model: None,\n                        debug,\n                        max_tool_repetitions,\n                        max_turns,\n                        scheduled_job_id: None,\n                        interactive: true,\n                        quiet: false,\n                        sub_recipes: None,\n                        final_output_response: None,\n                        retry_config: None,\n                        output_format: \"text\".to_string(),\n                    })\n                    .await;\n\n                    // Render previous messages if resuming a session and history flag is set\n                    if resume && history {\n                        session.render_message_history();\n                    }\n\n                    let result = session.interactive(None).await;\n\n                    let session_duration = session_start.elapsed();\n                    let exit_type = if result.is_ok() { \"normal\" } else { \"error\" };\n\n                    let (total_tokens, message_count) = session\n                        .get_session()\n                        .await\n                        .map(|m| (m.total_tokens.unwrap_or(0), m.message_count))\n                        .unwrap_or((0, 0));\n\n                    tracing::info!(\n                        counter.goose.session_completions = 1,\n                        session_type,\n                        exit_type,\n                        duration_ms = session_duration.as_millis() as u64,\n                        total_tokens,\n                        message_count,\n                        \"Session completed\"\n                    );\n\n                    tracing::info!(\n                        counter.goose.session_duration_ms = session_duration.as_millis() as u64,\n                        session_type,\n                        \"Session duration\"\n                    );\n\n                    if total_tokens > 0 {\n                        tracing::info!(\n                            counter.goose.session_tokens = total_tokens,\n                            session_type,\n                            \"Session tokens\"\n                        );\n                    }\n\n                    Ok(())\n                }\n            };\n        }\n        Some(Command::Project {}) => {\n            // Default behavior: offer to resume the last project\n            handle_project_default()?;\n            return Ok(());\n        }\n        Some(Command::Projects) => {\n            // Interactive project selection\n            handle_projects_interactive()?;\n            return Ok(());\n        }\n\n        Some(Command::Run {\n            instructions,\n            input_text,\n            recipe,\n            system,\n            interactive,\n            identifier,\n            resume,\n            no_session,\n            debug,\n            max_tool_repetitions,\n            max_turns,\n            extensions,\n            remote_extensions,\n            streamable_http_extensions,\n            builtins,\n            params,\n            explain,\n            render_recipe,\n            scheduled_job_id,\n            quiet,\n            additional_sub_recipes,\n            output_format,\n            provider,\n            model,\n        }) => {\n            let (input_config, recipe_info) = match (instructions, input_text, recipe) {\n                (Some(file), _, _) if file == \"-\" => {\n                    let mut input = String::new();\n                    std::io::stdin()\n                        .read_to_string(&mut input)\n                        .expect(\"Failed to read from stdin\");\n\n                    let input_config = InputConfig {\n                        contents: Some(input),\n                        extensions_override: None,\n                        additional_system_prompt: system,\n                    };\n                    (input_config, None)\n                }\n                (Some(file), _, _) => {\n                    let contents = std::fs::read_to_string(&file).unwrap_or_else(|err| {\n                        eprintln!(\n                            \"Instruction file not found — did you mean to use goose run --text?\\n{}\",\n                            err\n                        );\n                        std::process::exit(1);\n                    });\n                    let input_config = InputConfig {\n                        contents: Some(contents),\n                        extensions_override: None,\n                        additional_system_prompt: None,\n                    };\n                    (input_config, None)\n                }\n                (_, Some(text), _) => {\n                    let input_config = InputConfig {\n                        contents: Some(text),\n                        extensions_override: None,\n                        additional_system_prompt: system,\n                    };\n                    (input_config, None)\n                }\n                (_, _, Some(recipe_name)) => {\n                    let recipe_display_name = std::path::Path::new(&recipe_name)\n                        .file_name()\n                        .and_then(|name| name.to_str())\n                        .unwrap_or(&recipe_name);\n\n                    let recipe_version =\n                        crate::recipes::search_recipe::load_recipe_file(&recipe_name)\n                            .ok()\n                            .and_then(|rf| {\n                                goose::recipe::template_recipe::parse_recipe_content(\n                                    &rf.content,\n                                    Some(rf.parent_dir.display().to_string()),\n                                )\n                                .ok()\n                                .map(|(r, _)| r.version)\n                            })\n                            .unwrap_or_else(|| \"unknown\".to_string());\n\n                    if explain {\n                        explain_recipe(&recipe_name, params)?;\n                        return Ok(());\n                    }\n                    if render_recipe {\n                        if let Err(err) = render_recipe_as_yaml(&recipe_name, params) {\n                            eprintln!(\"{}: {}\", console::style(\"Error\").red().bold(), err);\n                            std::process::exit(1);\n                        }\n                        return Ok(());\n                    }\n\n                    tracing::info!(\n                        counter.goose.recipe_runs = 1,\n                        recipe_name = %recipe_display_name,\n                        recipe_version = %recipe_version,\n                        session_type = \"recipe\",\n                        interface = \"cli\",\n                        \"Recipe execution started\"\n                    );\n\n                    let (input_config, recipe_info) = extract_recipe_info_from_cli(\n                        recipe_name,\n                        params,\n                        additional_sub_recipes,\n                        quiet,\n                    )?;\n                    (input_config, Some(recipe_info))\n                }\n                (None, None, None) => {\n                    eprintln!(\"Error: Must provide either --instructions (-i), --text (-t), or --recipe. Use -i - for stdin.\");\n                    std::process::exit(1);\n                }\n            };\n\n            if let Some(Identifier {\n                session_id: Some(_),\n                ..\n            }) = &identifier\n            {\n                if !resume {\n                    eprintln!(\"Error: --session-id can only be used with --resume flag\");\n                    std::process::exit(1);\n                }\n            }\n\n            let session_id = get_or_create_session_id(identifier, resume, no_session).await?;\n\n            let mut session = build_session(SessionBuilderConfig {\n                session_id,\n                resume,\n                no_session,\n                extensions,\n                remote_extensions,\n                streamable_http_extensions,\n                builtins,\n                extensions_override: input_config.extensions_override,\n                additional_system_prompt: input_config.additional_system_prompt,\n                settings: recipe_info\n                    .as_ref()\n                    .and_then(|r| r.session_settings.clone()),\n                provider,\n                model,\n                debug,\n                max_tool_repetitions,\n                max_turns,\n                scheduled_job_id,\n                interactive, // Use the interactive flag from the Run command\n                quiet,\n                sub_recipes: recipe_info.as_ref().and_then(|r| r.sub_recipes.clone()),\n                final_output_response: recipe_info\n                    .as_ref()\n                    .and_then(|r| r.final_output_response.clone()),\n                retry_config: recipe_info.as_ref().and_then(|r| r.retry_config.clone()),\n                output_format,\n            })\n            .await;\n\n            if interactive {\n                session.interactive(input_config.contents).await?;\n            } else if let Some(contents) = input_config.contents {\n                let session_start = std::time::Instant::now();\n                let session_type = if recipe_info.is_some() {\n                    \"recipe\"\n                } else {\n                    \"run\"\n                };\n\n                tracing::info!(\n                    counter.goose.session_starts = 1,\n                    session_type,\n                    interactive = false,\n                    \"Headless session started\"\n                );\n\n                let result = session.headless(contents).await;\n\n                let session_duration = session_start.elapsed();\n                let exit_type = if result.is_ok() { \"normal\" } else { \"error\" };\n\n                let (total_tokens, message_count) = session\n                    .get_session()\n                    .await\n                    .map(|m| (m.total_tokens.unwrap_or(0), m.message_count))\n                    .unwrap_or((0, 0));\n\n                tracing::info!(\n                    counter.goose.session_completions = 1,\n                    session_type,\n                    exit_type,\n                    duration_ms = session_duration.as_millis() as u64,\n                    total_tokens,\n                    message_count,\n                    interactive = false,\n                    \"Headless session completed\"\n                );\n\n                tracing::info!(\n                    counter.goose.session_duration_ms = session_duration.as_millis() as u64,\n                    session_type,\n                    \"Headless session duration\"\n                );\n\n                if total_tokens > 0 {\n                    tracing::info!(\n                        counter.goose.session_tokens = total_tokens,\n                        session_type,\n                        \"Headless session tokens\"\n                    );\n                }\n\n                result?;\n            } else {\n                return Err(anyhow::anyhow!(\n                    \"no text provided for prompt in headless mode\"\n                ));\n            }\n\n            return Ok(());\n        }\n        Some(Command::Schedule { command }) => {\n            match command {\n                SchedulerCommand::Add {\n                    schedule_id,\n                    cron,\n                    recipe_source,\n                } => {\n                    handle_schedule_add(schedule_id, cron, recipe_source).await?;\n                }\n                SchedulerCommand::List {} => {\n                    handle_schedule_list().await?;\n                }\n                SchedulerCommand::Remove { schedule_id } => {\n                    handle_schedule_remove(schedule_id).await?;\n                }\n                SchedulerCommand::Sessions { schedule_id, limit } => {\n                    // New arm\n                    handle_schedule_sessions(schedule_id, limit).await?;\n                }\n                SchedulerCommand::RunNow { schedule_id } => {\n                    // New arm\n                    handle_schedule_run_now(schedule_id).await?;\n                }\n                SchedulerCommand::ServicesStatus {} => {\n                    handle_schedule_services_status().await?;\n                }\n                SchedulerCommand::ServicesStop {} => {\n                    handle_schedule_services_stop().await?;\n                }\n                SchedulerCommand::CronHelp {} => {\n                    handle_schedule_cron_help().await?;\n                }\n            }\n            return Ok(());\n        }\n        Some(Command::Update {\n            canary,\n            reconfigure,\n        }) => {\n            crate::commands::update::update(canary, reconfigure)?;\n            return Ok(());\n        }\n        Some(Command::Bench { cmd }) => {\n            match cmd {\n                BenchCommand::Selectors { config } => BenchRunner::list_selectors(config)?,\n                BenchCommand::InitConfig { name } => {\n                    let mut config = BenchRunConfig::default();\n                    let cwd = std::env::current_dir()?;\n                    config.output_dir = Some(cwd);\n                    config.save(name);\n                }\n                BenchCommand::Run { config } => BenchRunner::new(config)?.run()?,\n                BenchCommand::EvalModel { config } => ModelRunner::from(config)?.run()?,\n                BenchCommand::ExecEval { config } => {\n                    EvalRunner::from(config)?.run(agent_generator).await?\n                }\n                BenchCommand::GenerateLeaderboard { benchmark_dir } => {\n                    MetricAggregator::generate_csv_from_benchmark_dir(&benchmark_dir)?\n                }\n            }\n            return Ok(());\n        }\n        Some(Command::Recipe { command }) => {\n            match command {\n                RecipeCommand::Validate { recipe_name } => {\n                    handle_validate(&recipe_name)?;\n                }\n                RecipeCommand::Deeplink {\n                    recipe_name,\n                    params,\n                } => {\n                    handle_deeplink(&recipe_name, &params)?;\n                }\n                RecipeCommand::Open {\n                    recipe_name,\n                    params,\n                } => {\n                    handle_open(&recipe_name, &params)?;\n                }\n                RecipeCommand::List { format, verbose } => {\n                    handle_list(&format, verbose)?;\n                }\n            }\n            return Ok(());\n        }\n        Some(Command::Web {\n            port,\n            host,\n            open,\n            auth_token,\n        }) => {\n            crate::commands::web::handle_web(port, host, open, auth_token).await?;\n            return Ok(());\n        }\n        Some(Command::Term { command }) => {\n            match command {\n                TermCommand::Init {\n                    shell,\n                    name,\n                    default,\n                } => {\n                    handle_term_init(shell, name, default).await?;\n                }\n                TermCommand::Log { command } => {\n                    handle_term_log(command).await?;\n                }\n                TermCommand::Run { prompt } => {\n                    handle_term_run(prompt).await?;\n                }\n                TermCommand::Info => {\n                    handle_term_info().await?;\n                }\n            }\n            return Ok(());\n        }\n        None => {\n            return if !Config::global().exists() {\n                handle_configure().await?;\n                Ok(())\n            } else {\n                // Run session command by default\n                let session_id = get_or_create_session_id(None, false, false).await?;\n\n                let mut session = build_session(SessionBuilderConfig {\n                    session_id,\n                    resume: false,\n                    no_session: false,\n                    extensions: Vec::new(),\n                    remote_extensions: Vec::new(),\n                    streamable_http_extensions: Vec::new(),\n                    builtins: Vec::new(),\n                    extensions_override: None,\n                    additional_system_prompt: None,\n                    settings: None::<SessionSettings>,\n                    provider: None,\n                    model: None,\n                    debug: false,\n                    max_tool_repetitions: None,\n                    max_turns: None,\n                    scheduled_job_id: None,\n                    interactive: true,\n                    quiet: false,\n                    sub_recipes: None,\n                    final_output_response: None,\n                    retry_config: None,\n                    output_format: \"text\".to_string(),\n                })\n                .await;\n                session.interactive(None).await?;\n                Ok(())\n            };\n        }\n    }\n    Ok(())\n}\n"
                  },
                  "annotations": {
                    "audience": [
                      "assistant"
                    ]
                  }
                },
                {
                  "type": "text",
                  "text": "### /Users/baxen/Development/goose/crates/goose-cli/src/cli.rs\n```rust\n1: use anyhow::Result;\n2: use clap::{Args, Parser, Subcommand};\n3: \n4: use goose::config::{Config, ExtensionConfig};\n5: use goose_mcp::mcp_server_runner::{serve, McpCommand};\n6: use goose_mcp::{\n7:     AutoVisualiserRouter, ComputerControllerServer, DevelopServer, DeveloperServer, MemoryServer,\n8:     TutorialServer,\n9: };\n10: \n11: use crate::commands::acp::run_acp_agent;\n12: use crate::commands::bench::agent_generator;\n13: use crate::commands::configure::handle_configure;\n14: use crate::commands::info::handle_info;\n15: use crate::commands::project::{handle_project_default, handle_projects_interactive};\n16: use crate::commands::recipe::{handle_deeplink, handle_list, handle_open, handle_validate};\n17: use crate::commands::term::{\n18:     handle_term_info, handle_term_init, handle_term_log, handle_term_run, Shell,\n19: };\n20: \n21: use crate::commands::schedule::{\n22:     handle_schedule_add, handle_schedule_cron_help, handle_schedule_list, handle_schedule_remove,\n23:     handle_schedule_run_now, handle_schedule_services_status, handle_schedule_services_stop,\n24:     handle_schedule_sessions,\n25: };\n26: use crate::commands::session::{handle_session_list, handle_session_remove};\n27: use crate::recipes::extract_from_cli::extract_recipe_info_from_cli;\n28: use crate::recipes::recipe::{explain_recipe, render_recipe_as_yaml};\n29: use crate::session::{build_session, SessionBuilderConfig, SessionSettings};\n30: use goose::session::session_manager::SessionType;\n31: use goose::session::SessionManager;\n32: use goose_bench::bench_config::BenchRunConfig;\n33: use goose_bench::runners::bench_runner::BenchRunner;\n34: use goose_bench::runners::eval_runner::EvalRunner;\n35: use goose_bench::runners::metric_aggregator::MetricAggregator;\n36: use goose_bench::runners::model_runner::ModelRunner;\n37: use std::io::Read;\n38: use std::path::PathBuf;\n39: use tracing::warn;\n40: \n41: #[derive(Parser)]\n42: #[command(author, version, display_name = \"\", about, long_about = None)]\n43: struct Cli {\n44:     #[command(subcommand)]\n45:     command: Option<Command>,\n46: }\n47: \n48: #[derive(Args, Debug, Clone)]\n49: #[group(required = false, multiple = false)]\n50: pub struct Identifier {\n51:     #[arg(\n52:         short = 'n',\n53:         long,\n54:         value_name = \"NAME\",\n55:         help = \"Name for the chat session (e.g., 'project-x')\",\n56:         long_help = \"Specify a name for your chat session. When used with --resume, will resume this specific session if it exists.\"\n57:     )]\n58:     pub name: Option<String>,\n59: \n60:     #[arg(\n61:         long = \"session-id\",\n62:         alias = \"id\",\n63:         value_name = \"SESSION_ID\",\n64:         help = \"Session ID (e.g., '20250921_143022')\",\n65:         long_help = \"Specify a session ID directly. When used with --resume, will resume this specific session if it exists.\"\n66:     )]\n67:     pub session_id: Option<String>,\n68: \n69:     #[arg(\n70:         long,\n71:         value_name = \"PATH\",\n72:         help = \"Legacy: Path for the chat session\",\n73:         long_help = \"Legacy parameter for backward compatibility. Extracts session ID from the file path (e.g., '/path/to/20250325_200615.\n74: jsonl' -> '20250325_200615').\"\n75:     )]\n76:     pub path: Option<PathBuf>,\n77: }\n78: \n79: async fn get_or_create_session_id(\n80:     identifier: Option<Identifier>,\n81:     resume: bool,\n82:     no_session: bool,\n83: ) -> Result<Option<String>> {\n84:     if no_session {\n85:         return Ok(None);\n86:     }\n87: \n88:     let Some(id) = identifier else {\n89:         return if resume {\n90:             let sessions = SessionManager::list_sessions().await?;\n91:             let session_id = sessions\n92:                 .first()\n93:                 .map(|s| s.id.clone())\n94:                 .ok_or_else(|| anyhow::anyhow!(\"No session found to resume\"))?;\n95:             Ok(Some(session_id))\n96:         } else {\n97:             let session = SessionManager::create_session(\n98:                 std::env::current_dir()?,\n99:                 \"CLI Session\".to_string(),\n100:                 SessionType::User,\n101:             )\n102:             .await?;\n103:             Ok(Some(session.id))\n104:         };\n105:     };\n106: \n107:     if let Some(session_id) = id.session_id {\n108:         Ok(Some(session_id))\n109:     } else if let Some(name) = id.name {\n110:         if resume {\n111:             let sessions = SessionManager::list_sessions().await?;\n112:             let session_id = sessions\n113:                 .into_iter()\n114:                 .find(|s| s.name == name || s.id == name)\n115:                 .map(|s| s.id)\n116:                 .ok_or_else(|| anyhow::anyhow!(\"No session found with name '{}'\", name))?;\n117:             Ok(Some(session_id))\n118:         } else {\n119:             let session = SessionManager::create_session(\n120:                 std::env::current_dir()?,\n121:                 name.clone(),\n122:                 SessionType::User,\n123:             )\n124:             .await?;\n125: \n126:             SessionManager::update_session(&session.id)\n127:                 .user_provided_name(name)\n128:                 .apply()\n129:                 .await?;\n130: \n131:             Ok(Some(session.id))\n132:         }\n133:     } else if let Some(path) = id.path {\n134:         let session_id = path\n135:             .file_stem()\n136:             .and_then(|s| s.to_str())\n137:             .map(|s| s.to_string())\n138:             .ok_or_else(|| anyhow::anyhow!(\"Could not extract session ID from path: {:?}\", path))?;\n139:         Ok(Some(session_id))\n140:     } else {\n141:         let session = SessionManager::create_session(\n142:             std::env::current_dir()?,\n143:             \"CLI Session\".to_string(),\n144:             SessionType::User,\n145:         )\n146:         .await?;\n147:         Ok(Some(session.id))\n148:     }\n149: }\n150: \n151: async fn lookup_session_id(identifier: Identifier) -> Result<String> {\n152:     if let Some(session_id) = identifier.session_id {\n153:         Ok(session_id)\n154:     } else if let Some(name) = identifier.name {\n155:         let sessions = SessionManager::list_sessions().await?;\n156:         sessions\n157:             .into_iter()\n158:             .find(|s| s.name == name || s.id == name)\n159:             .map(|s| s.id)\n160:             .ok_or_else(|| anyhow::anyhow!(\"No session found with name '{}'\", name))\n161:     } else if let Some(path) = identifier.path {\n162:         path.file_stem()\n163:             .and_then(|s| s.to_str())\n164:             .map(|s| s.to_string())\n165:             .ok_or_else(|| anyhow::anyhow!(\"Could not extract session ID from path: {:?}\", path))\n166:     } else {\n167:         Err(anyhow::anyhow!(\"No identifier provided\"))\n168:     }\n169: }\n170: \n171: fn parse_key_val(s: &str) -> Result<(String, String), String> {\n172:     match s.split_once('=') {\n173:         Some((key, value)) => Ok((key.to_string(), value.to_string())),\n174:         None => Err(format!(\"invalid KEY=VALUE: {}\", s)),\n175:     }\n176: }\n177: \n178: #[derive(Subcommand)]\n179: enum SessionCommand {\n180:     #[command(about = \"List all available sessions\")]\n181:     List {\n182:         #[arg(\n183:             short,\n184:             long,\n185:             help = \"Output format (text, json)\",\n186:             default_value = \"text\"\n187:         )]\n188:         format: String,\n189: \n190:         #[arg(\n191:             long = \"ascending\",\n192:             help = \"Sort by date in ascending order (oldest first)\",\n193:             long_help = \"Sort sessions by date in ascending order (oldest first). Default is descending order (newest first).\"\n194:         )]\n195:         ascending: bool,\n196: \n197:         #[arg(\n198:             short = 'w',\n199:             short_alias = 'p',\n200:             long = \"working_dir\",\n201:             help = \"Filter sessions by working directory\"\n202:         )]\n203:         working_dir: Option<PathBuf>,\n204: \n205:         #[arg(short = 'l', long = \"limit\", help = \"Limit the number of results\")]\n206:         limit: Option<usize>,\n207:     },\n208:     #[command(about = \"Remove sessions. Runs interactively if no ID, name, or regex is provided.\")]\n209:     Remove {\n210:         #[command(flatten)]\n211:         identifier: Option<Identifier>,\n212:         #[arg(\n213:             short = 'r',\n214:             long,\n215:             help = \"Regex for removing matched sessions (optional)\"\n216:         )]\n217:         regex: Option<String>,\n218:     },\n219:     #[command(about = \"Export a session\")]\n220:     Export {\n221:         #[command(flatten)]\n222:         identifier: Option<Identifier>,\n223: \n224:         #[arg(\n225:             short,\n226:             long,\n227:             help = \"Output file path (default: stdout)\",\n228:             long_help = \"Path to save the exported Markdown. If not provided, output will be sent to stdout\"\n229:         )]\n230:         output: Option<PathBuf>,\n231: \n232:         #[arg(\n233:             long = \"format\",\n234:             value_name = \"FORMAT\",\n235:             help = \"Output format (markdown, json, yaml)\",\n236:             default_value = \"markdown\"\n237:         )]\n238:         format: String,\n239:     },\n240:     #[command(name = \"diagnostics\")]\n241:     Diagnostics {\n242:         /// Session identifier for generating diagnostics\n243:         #[command(flatten)]\n244:         identifier: Option<Identifier>,\n245: \n246:         /// Output path for the diagnostics zip file (optional, defaults to current directory)\n247:         #[arg(short = 'o', long)]\n248:         output: Option<PathBuf>,\n249:     },\n250: }\n251: \n252: #[derive(Subcommand, Debug)]\n253: enum SchedulerCommand {\n254:     #[command(about = \"Add a new scheduled job\")]\n255:     Add {\n256:         #[arg(\n257:             long = \"schedule-id\",\n258:             alias = \"id\",\n259:             help = \"Unique ID for the recurring scheduled job\"\n260:         )]\n261:         schedule_id: String,\n262:         #[arg(\n263:             long,\n264:             help = \"Cron expression for the schedule\",\n265:             long_help = \"Cron expression for when to run the job. Examples:\\n  '0 * * * *'     - Every hour at minute 0\\n  '0 */2 * * *'   - Every 2 hours\\n  '@hourly'       - Every hour (shorthand)\\n  '0 9 * * *'     - Every day at 9:00 AM\\n  '0 9 * * 1'     - Every Monday at 9:00 AM\\n  '0 0 1 * *'     - First day of every month at midnight\"\n266:         )]\n267:         cron: String,\n268:         #[arg(\n269:             long,\n270:             help = \"Recipe source (path to file, or base64 encoded recipe string)\"\n271:         )]\n272:         recipe_source: String,\n273:     },\n274:     #[command(about = \"List all scheduled jobs\")]\n275:     List {},\n276:     #[command(about = \"Remove a scheduled job by ID\")]\n277:     Remove {\n278:         #[arg(\n279:             long = \"schedule-id\",\n280:             alias = \"id\",\n281:             help = \"ID of the scheduled job to remove (removes the recurring schedule)\"\n282:         )]\n283:         schedule_id: String,\n284:     },\n285:     /// List sessions created by a specific schedule\n286:     #[command(about = \"List sessions created by a specific schedule\")]\n287:     Sessions {\n288:         /// ID of the schedule\n289:         #[arg(long = \"schedule-id\", alias = \"id\", help = \"ID of the schedule\")]\n290:         schedule_id: String,\n291:         #[arg(short = 'l', long, help = \"Maximum number of sessions to return\")]\n292:         limit: Option<usize>,\n293:     },\n294:     #[command(about = \"Run a scheduled job immediately\")]\n295:     RunNow {\n296:         /// ID of the schedule to run\n297:         #[arg(long = \"schedule-id\", alias = \"id\", help = \"ID of the schedule to run\")]\n298:         schedule_id: String,\n299:     },\n300:     /// Check status of scheduler services (deprecated - no external services needed)\n301:     #[command(about = \"[Deprecated] Check status of scheduler services\")]\n302:     ServicesStatus {},\n303:     /// Stop scheduler services (deprecated - no external services needed)\n304:     #[command(about = \"[Deprecated] Stop scheduler services\")]\n305:     ServicesStop {},\n306:     /// Show cron expression examples and help\n307:     #[command(about = \"Show cron expression examples and help\")]\n308:     CronHelp {},\n309: }\n310: \n311: #[derive(Subcommand)]\n312: pub enum BenchCommand {\n313:     #[command(name = \"init-config\", about = \"Create a new starter-config\")]\n314:     InitConfig {\n315:         #[arg(short, long, help = \"filename with extension for generated config\")]\n316:         name: String,\n317:     },\n318: \n319:     #[command(about = \"Run all benchmarks from a config\")]\n320:     Run {\n321:         #[arg(\n322:             short,\n323:             long,\n324:             help = \"A config file generated by the config-init command\"\n325:         )]\n326:         config: PathBuf,\n327:     },\n328: \n329:     #[command(about = \"List all available selectors\")]\n330:     Selectors {\n331:         #[arg(\n332:             short,\n333:             long,\n334:             help = \"A config file generated by the config-init command\"\n335:         )]\n336:         config: Option<PathBuf>,\n337:     },\n338: \n339:     #[command(name = \"eval-model\", about = \"Run an eval of model\")]\n340:     EvalModel {\n341:         #[arg(short, long, help = \"A serialized config file for the model only.\")]\n342:         config: String,\n343:     },\n344: \n345:     #[command(name = \"exec-eval\", about = \"run a single eval\")]\n346:     ExecEval {\n347:         #[arg(short, long, help = \"A serialized config file for the eval only.\")]\n348:         config: String,\n349:     },\n350: \n351:     #[command(\n352:         name = \"generate-leaderboard\",\n353:         about = \"Generate a leaderboard CSV from benchmark results\"\n354:     )]\n355:     GenerateLeaderboard {\n356:         #[arg(\n357:             short,\n358:             long,\n359:             help = \"Path to the benchmark directory containing model evaluation results\"\n360:         )]\n361:         benchmark_dir: PathBuf,\n362:     },\n363: }\n364: \n365: #[derive(Subcommand)]\n366: enum RecipeCommand {\n367:     /// Validate a recipe file\n368:     #[command(about = \"Validate a recipe\")]\n369:     Validate {\n370:         /// Recipe name to get recipe file to validate\n371:         #[arg(help = \"recipe name to get recipe file or full path to the recipe file to validate\")]\n372:         recipe_name: String,\n373:     },\n374: \n375:     /// Generate a deeplink for a recipe file\n376:     #[command(about = \"Generate a deeplink for a recipe\")]\n377:     Deeplink {\n378:         /// Recipe name to get recipe file to generate deeplink\n379:         #[arg(\n380:             help = \"recipe name to get recipe file or full path to the recipe file to generate deeplink\"\n381:         )]\n382:         recipe_name: String,\n383:         /// Recipe parameters in key=value format (can be specified multiple times)\n384:         #[arg(\n385:             short = 'p',\n386:             long = \"param\",\n387:             value_name = \"KEY=VALUE\",\n388:             help = \"Recipe parameter in key=value format (can be specified multiple times)\"\n389:         )]\n390:         params: Vec<String>,\n391:     },\n392: \n393:     /// Open a recipe in Goose Desktop\n394:     #[command(about = \"Open a recipe in Goose Desktop\")]\n395:     Open {\n396:         /// Recipe name to get recipe file to open\n397:         #[arg(help = \"recipe name or full path to the recipe file\")]\n398:         recipe_name: String,\n399:         /// Recipe parameters in key=value format (can be specified multiple times)\n400:         #[arg(\n401:             short = 'p',\n402:             long = \"param\",\n403:             value_name = \"KEY=VALUE\",\n404:             help = \"Recipe parameter in key=value format (can be specified multiple times)\"\n405:         )]\n406:         params: Vec<String>,\n407:     },\n408: \n409:     /// List available recipes\n410:     #[command(about = \"List available recipes\")]\n411:     List {\n412:         /// Output format (text, json)\n413:         #[arg(\n414:             long = \"format\",\n415:             value_name = \"FORMAT\",\n416:             help = \"Output format (text, json)\",\n417:             default_value = \"text\"\n418:         )]\n419:         format: String,\n420: \n421:         /// Show verbose information including recipe descriptions\n422:         #[arg(\n423:             short,\n424:             long,\n425:             help = \"Show verbose information including recipe descriptions\"\n426:         )]\n427:         verbose: bool,\n428:     },\n429: }\n430: \n431: #[derive(Subcommand)]\n432: enum Command {\n433:     /// Configure goose settings\n434:     #[command(about = \"Configure goose settings\")]\n435:     Configure {},\n436: \n437:     /// Display goose configuration information\n438:     #[command(about = \"Display goose information\")]\n439:     Info {\n440:         /// Show verbose information including current configuration\n441:         #[arg(short, long, help = \"Show verbose information including config.yaml\")]\n442:         verbose: bool,\n443:     },\n444: \n445:     /// Manage system prompts and behaviors\n446:     #[command(about = \"Run one of the mcp servers bundled with goose\")]\n447:     Mcp {\n448:         #[arg(value_parser = clap::value_parser!(McpCommand))]\n449:         server: McpCommand,\n450:     },\n451: \n452:     /// Run goose as an ACP (Agent Client Protocol) agent\n453:     #[command(about = \"Run goose as an ACP agent server on stdio\")]\n454:     Acp {},\n455: \n456:     /// Start or resume interactive chat sessions\n457:     #[command(\n458:         about = \"Start or resume interactive chat sessions\",\n459:         visible_alias = \"s\"\n460:     )]\n461:     Session {\n462:         #[command(subcommand)]\n463:         command: Option<SessionCommand>,\n464:         /// Identifier for the chat session\n465:         #[command(flatten)]\n466:         identifier: Option<Identifier>,\n467: \n468:         /// Resume a previous session\n469:         #[arg(\n470:             short,\n471:             long,\n472:             help = \"Resume a previous session (last used or specified by --name/--session-id)\",\n473:             long_help = \"Continue from a previous session. If --name or --session-id is provided, resumes that specific session. Otherwise resumes the most recently used session.\"\n474:         )]\n475:         resume: bool,\n476: \n477:         /// Show message history when resuming\n478:         #[arg(\n479:             long,\n480:             help = \"Show previous messages when resuming a session\",\n481:             requires = \"resume\"\n482:         )]\n483:         history: bool,\n484: \n485:         /// Enable debug output mode\n486:         #[arg(\n487:             long,\n488:             help = \"Enable debug output mode with full content and no truncation\",\n489:             long_help = \"When enabled, shows complete tool responses without truncation and full paths.\"\n490:         )]\n491:         debug: bool,\n492: \n493:         /// Maximum number of consecutive identical tool calls allowed\n494:         #[arg(\n495:             long = \"max-tool-repetitions\",\n496:             value_name = \"NUMBER\",\n497:             help = \"Maximum number of consecutive identical tool calls allowed\",\n498:             long_help = \"Set a limit on how many times the same tool can be called consecutively with identical parameters. Helps prevent infinite loops.\"\n499:         )]\n500:         max_tool_repetitions: Option<u32>,\n501: \n502:         /// Maximum number of turns (iterations) allowed in a single response\n503:         #[arg(\n504:             long = \"max-turns\",\n505:             value_name = \"NUMBER\",\n506:             help = \"Maximum number of turns allowed without user input (default: 1000)\",\n507:             long_help = \"Set a limit on how many turns (iterations) the agent can take without asking for user input to continue.\"\n508:         )]\n509:         max_turns: Option<u32>,\n510: \n511:         /// Add stdio extensions with environment variables and commands\n512:         #[arg(\n513:             long = \"with-extension\",\n514:             value_name = \"COMMAND\",\n515:             help = \"Add stdio extensions (can be specified multiple times)\",\n516:             long_help = \"Add stdio extensions from full commands with environment variables. Can be specified multiple times. Format: 'ENV1=val1 ENV2=val2 command args...'\",\n517:             action = clap::ArgAction::Append\n518:         )]\n519:         extensions: Vec<String>,\n520: \n521:         /// Add remote extensions with a URL\n522:         #[arg(\n523:             long = \"with-remote-extension\",\n524:             value_name = \"URL\",\n525:             help = \"Add remote extensions (can be specified multiple times)\",\n526:             long_help = \"Add remote extensions from a URL. Can be specified multiple times. Format: 'url...'\",\n527:             action = clap::ArgAction::Append\n528:         )]\n529:         remote_extensions: Vec<String>,\n530: \n531:         /// Add streamable HTTP extensions with a URL\n532:         #[arg(\n533:             long = \"with-streamable-http-extension\",\n534:             value_name = \"URL\",\n535:             help = \"Add streamable HTTP extensions (can be specified multiple times)\",\n536:             long_help = \"Add streamable HTTP extensions from a URL. Can be specified multiple times. Format: 'url...'\",\n537:             action = clap::ArgAction::Append\n538:         )]\n539:         streamable_http_extensions: Vec<String>,\n540: \n541:         /// Add builtin extensions by name\n542:         #[arg(\n543:             long = \"with-builtin\",\n544:             value_name = \"NAME\",\n545:             help = \"Add builtin extensions by name (e.g., 'developer' or multiple: 'developer,github')\",\n546:             long_help = \"Add one or more builtin extensions that are bundled with goose by specifying their names, comma-separated\",\n547:             value_delimiter = ','\n548:         )]\n549:         builtins: Vec<String>,\n550:     },\n551: \n552:     /// Open the last project directory\n553:     #[command(about = \"Open the last project directory\", visible_alias = \"p\")]\n554:     Project {},\n555: \n556:     /// List recent project directories\n557:     #[command(about = \"List recent project directories\", visible_alias = \"ps\")]\n558:     Projects,\n559: \n560:     /// Execute commands from an instruction file\n561:     #[command(about = \"Execute commands from an instruction file or stdin\")]\n562:     Run {\n563:         /// Path to instruction file containing commands\n564:         #[arg(\n565:             short,\n566:             long,\n567:             value_name = \"FILE\",\n568:             help = \"Path to instruction file containing commands. Use - for stdin.\",\n569:             conflicts_with = \"input_text\",\n570:             conflicts_with = \"recipe\"\n571:         )]\n572:         instructions: Option<String>,\n573: \n574:         /// Input text containing commands\n575:         #[arg(\n576:             short = 't',\n577:             long = \"text\",\n578:             value_name = \"TEXT\",\n579:             help = \"Input text to provide to goose directly\",\n580:             long_help = \"Input text containing commands for goose. Use this in lieu of the instructions argument.\",\n581:             conflicts_with = \"instructions\",\n582:             conflicts_with = \"recipe\"\n583:         )]\n584:         input_text: Option<String>,\n585: \n586:         /// Additional system prompt to customize agent behavior\n587:         #[arg(\n588:             long = \"system\",\n589:             value_name = \"TEXT\",\n590:             help = \"Additional system prompt to customize agent behavior\",\n591:             long_help = \"Provide additional system instructions to customize the agent's behavior\",\n592:             conflicts_with = \"recipe\"\n593:         )]\n594:         system: Option<String>,\n595: \n596:         /// Recipe name or full path to the recipe file\n597:         #[arg(\n598:             short = None,\n599:             long = \"recipe\",\n600:             value_name = \"RECIPE_NAME or FULL_PATH_TO_RECIPE_FILE\",\n601:             help = \"Recipe name to get recipe file or the full path of the recipe file (use --explain to see recipe details)\",\n602:             long_help = \"Recipe name to get recipe file or the full path of the recipe file that defines a custom agent configuration. Use --explain to see the recipe's title, description, and parameters.\",\n603:             conflicts_with = \"instructions\",\n604:             conflicts_with = \"input_text\"\n605:         )]\n606:         recipe: Option<String>,\n607: \n608:         #[arg(\n609:             long,\n610:             value_name = \"KEY=VALUE\",\n611:             help = \"Dynamic parameters (e.g., --params username=alice --params channel_name=goose-channel)\",\n612:             long_help = \"Key-value parameters to pass to the recipe file. Can be specified multiple times.\",\n613:             action = clap::ArgAction::Append,\n614:             value_parser = parse_key_val,\n615:         )]\n616:         params: Vec<(String, String)>,\n617: \n618:         /// Continue in interactive mode after processing input\n619:         #[arg(\n620:             short = 's',\n621:             long = \"interactive\",\n622:             help = \"Continue in interactive mode after processing initial input\"\n623:         )]\n624:         interactive: bool,\n625: \n626:         /// Run without storing a session file\n627:         #[arg(\n628:             long = \"no-session\",\n629:             help = \"Run without storing a session file\",\n630:             long_help = \"Execute commands without creating or using a session file. Useful for automated runs.\",\n631:             conflicts_with_all = [\"resume\", \"name\", \"path\"]\n632:         )]\n633:         no_session: bool,\n634: \n635:         /// Show the recipe title, description, and parameters\n636:         #[arg(\n637:             long = \"explain\",\n638:             help = \"Show the recipe title, description, and parameters\"\n639:         )]\n640:         explain: bool,\n641: \n642:         /// Print the rendered recipe instead of running it\n643:         #[arg(\n644:             long = \"render-recipe\",\n645:             help = \"Print the rendered recipe instead of running it.\"\n646:         )]\n647:         render_recipe: bool,\n648: \n649:         /// Maximum number of consecutive identical tool calls allowed\n650:         #[arg(\n651:             long = \"max-tool-repetitions\",\n652:             value_name = \"NUMBER\",\n653:             help = \"Maximum number of consecutive identical tool calls allowed\",\n654:             long_help = \"Set a limit on how many times the same tool can be called consecutively with identical parameters. Helps prevent infinite loops.\"\n655:         )]\n656:         max_tool_repetitions: Option<u32>,\n657: \n658:         /// Maximum number of turns (iterations) allowed in a single response\n659:         #[arg(\n660:             long = \"max-turns\",\n661:             value_name = \"NUMBER\",\n662:             help = \"Maximum number of turns allowed without user input (default: 1000)\",\n663:             long_help = \"Set a limit on how many turns (iterations) the agent can take without asking for user input to continue.\"\n664:         )]\n665:         max_turns: Option<u32>,\n666: \n667:         /// Identifier for this run session\n668:         #[command(flatten)]\n669:         identifier: Option<Identifier>,\n670: \n671:         /// Resume a previous run\n672:         #[arg(\n673:             short,\n674:             long,\n675:             action = clap::ArgAction::SetTrue,\n676:             help = \"Resume from a previous run\",\n677:             long_help = \"Continue from a previous run, maintaining the execution state and context.\"\n678:         )]\n679:         resume: bool,\n680: \n681:         /// Enable debug output mode\n682:         #[arg(\n683:             long,\n684:             help = \"Enable debug output mode with full content and no truncation\",\n685:             long_help = \"When enabled, shows complete tool responses without truncation and full paths.\"\n686:         )]\n687:         debug: bool,\n688: \n689:         /// Add stdio extensions with environment variables and commands\n690:         #[arg(\n691:             long = \"with-extension\",\n692:             value_name = \"COMMAND\",\n693:             help = \"Add stdio extensions (can be specified multiple times)\",\n694:             long_help = \"Add stdio extensions from full commands with environment variables. Can be specified multiple times. Format: 'ENV1=val1 ENV2=val2 command args...'\",\n695:             action = clap::ArgAction::Append\n696:         )]\n697:         extensions: Vec<String>,\n698: \n699:         /// Add remote extensions\n700:         #[arg(\n701:             long = \"with-remote-extension\",\n702:             value_name = \"URL\",\n703:             help = \"Add remote extensions (can be specified multiple times)\",\n704:             long_help = \"Add remote extensions. Can be specified multiple times. Format: 'url...'\",\n705:             action = clap::ArgAction::Append\n706:         )]\n707:         remote_extensions: Vec<String>,\n708: \n709:         /// Add streamable HTTP extensions\n710:         #[arg(\n711:             long = \"with-streamable-http-extension\",\n712:             value_name = \"URL\",\n713:             help = \"Add streamable HTTP extensions (can be specified multiple times)\",\n714:             long_help = \"Add streamable HTTP extensions. Can be specified multiple times. Format: 'url...'\",\n715:             action = clap::ArgAction::Append\n716:         )]\n717:         streamable_http_extensions: Vec<String>,\n718: \n719:         /// Add builtin extensions by name\n720:         #[arg(\n721:             long = \"with-builtin\",\n722:             value_name = \"NAME\",\n723:             help = \"Add builtin extensions by name (e.g., 'developer' or multiple: 'developer,github')\",\n724:             long_help = \"Add one or more builtin extensions that are bundled with goose by specifying their names, comma-separated\",\n725:             value_delimiter = ','\n726:         )]\n727:         builtins: Vec<String>,\n728: \n729:         /// Quiet mode - suppress non-response output\n730:         #[arg(\n731:             short = 'q',\n732:             long = \"quiet\",\n733:             help = \"Quiet mode. Suppress non-response output, printing only the model response to stdout\"\n734:         )]\n735:         quiet: bool,\n736: \n737:         /// Scheduled job ID (used internally for scheduled executions)\n738:         #[arg(\n739:             long = \"scheduled-job-id\",\n740:             value_name = \"ID\",\n741:             help = \"ID of the scheduled job that triggered this execution (internal use)\",\n742:             long_help = \"Internal parameter used when this run command is executed by a scheduled job. This associates the session with the schedule for tracking purposes.\",\n743:             hide = true\n744:         )]\n745:         scheduled_job_id: Option<String>,\n746: \n747:         /// Additional sub-recipe file paths\n748:         #[arg(\n749:             long = \"sub-recipe\",\n750:             value_name = \"RECIPE\",\n751:             help = \"Sub-recipe name or file path (can be specified multiple times)\",\n752:             long_help = \"Specify sub-recipes to include alongside the main recipe. Can be:\\n  - Recipe names from GitHub (if GOOSE_RECIPE_GITHUB_REPO is configured)\\n  - Local file paths to YAML files\\nCan be specified multiple times to include multiple sub-recipes.\",\n753:             action = clap::ArgAction::Append\n754:         )]\n755:         additional_sub_recipes: Vec<String>,\n756: \n757:         /// Output format (text, json, stream-json)\n758:         #[arg(\n759:             long = \"output-format\",\n760:             value_name = \"FORMAT\",\n761:             help = \"Output format (text, json, stream-json)\",\n762:             default_value = \"text\",\n763:             value_parser = clap::builder::PossibleValuesParser::new([\"text\", \"json\", \"stream-json\"])\n764:         )]\n765:         output_format: String,\n766: \n767:         /// Provider to use for this run (overrides environment variable)\n768:         #[arg(\n769:             long = \"provider\",\n770:             value_name = \"PROVIDER\",\n771:             help = \"Specify the LLM provider to use (e.g., 'openai', 'anthropic')\",\n772:             long_help = \"Override the GOOSE_PROVIDER environment variable for this run. Available providers include openai, anthropic, ollama, databricks, gemini-cli, claude-code, and others.\"\n773:         )]\n774:         provider: Option<String>,\n775: \n776:         /// Model to use for this run (overrides environment variable)\n777:         #[arg(\n778:             long = \"model\",\n779:             value_name = \"MODEL\",\n780:             help = \"Specify the model to use (e.g., 'gpt-4o', 'claude-sonnet-4-20250514')\",\n781:             long_help = \"Override the GOOSE_MODEL environment variable for this run. The model must be supported by the specified provider.\"\n782:         )]\n783:         model: Option<String>,\n784:     },\n785: \n786:     /// Recipe utilities for validation and deeplinking\n787:     #[command(about = \"Recipe utilities for validation and deeplinking\")]\n788:     Recipe {\n789:         #[command(subcommand)]\n790:         command: RecipeCommand,\n791:     },\n792: \n793:     /// Manage scheduled jobs\n794:     #[command(about = \"Manage scheduled jobs\", visible_alias = \"sched\")]\n795:     Schedule {\n796:         #[command(subcommand)]\n797:         command: SchedulerCommand,\n798:     },\n799: \n800:     /// Update the goose CLI version\n801:     #[command(about = \"Update the goose CLI version\")]\n802:     Update {\n803:         /// Update to canary version\n804:         #[arg(\n805:             short,\n806:             long,\n807:             help = \"Update to canary version\",\n808:             long_help = \"Update to the latest canary version of the goose CLI, otherwise updates to the latest stable version.\"\n809:         )]\n810:         canary: bool,\n811: \n812:         /// Enforce to re-configure goose during update\n813:         #[arg(short, long, help = \"Enforce to re-configure goose during update\")]\n814:         reconfigure: bool,\n815:     },\n816: \n817:     /// Evaluate system configuration across a range of practical tasks\n818:     #[command(about = \"Evaluate system configuration across a range of practical tasks\")]\n819:     Bench {\n820:         #[command(subcommand)]\n821:         cmd: BenchCommand,\n822:     },\n823: \n824:     /// Start a web server with a chat interface\n825:     #[command(about = \"Experimental: Start a web server with a chat interface\")]\n826:     Web {\n827:         /// Port to run the web server on\n828:         #[arg(\n829:             short,\n830:             long,\n831:             default_value = \"3000\",\n832:             help = \"Port to run the web server on\"\n833:         )]\n834:         port: u16,\n835: \n836:         /// Host to bind the web server to\n837:         #[arg(\n838:             long,\n839:             default_value = \"127.0.0.1\",\n840:             help = \"Host to bind the web server to\"\n841:         )]\n842:         host: String,\n843: \n844:         /// Open browser automatically\n845:         #[arg(long, help = \"Open browser automatically when server starts\")]\n846:         open: bool,\n847: \n848:         /// Authentication token for both Basic Auth (password) and Bearer token\n849:         #[arg(long, help = \"Authentication token to secure the web interface\")]\n850:         auth_token: Option<String>,\n851:     },\n852: \n853:     /// Terminal-integrated session (one session per terminal)\n854:     #[command(\n855:         about = \"Terminal-integrated goose session\",\n856:         long_about = \"Runs a goose session tied to your terminal window.\\n\\\n857:                       Each terminal maintains its own persistent session that resumes automatically.\\n\\n\\\n858:                       Setup:\\n  \\\n859:                         eval \\\"$(goose term init zsh)\\\"  # Add to ~/.zshrc\\n\\n\\\n860:                       Usage:\\n  \\\n861:                         goose term run \\\"list files in this directory\\\"\\n  \\\n862:                         @goose \\\"create a python script\\\"  # using alias\\n  \\\n863:                         @g \\\"quick question\\\"  # short alias\"\n864:     )]\n865:     Term {\n866:         #[command(subcommand)]\n867:         command: TermCommand,\n868:     },\n869: }\n870: \n871: #[derive(Subcommand)]\n872: enum TermCommand {\n873:     /// Print shell initialization script\n874:     #[command(\n875:         about = \"Print shell initialization script\",\n876:         long_about = \"Prints shell configuration to set up terminal-integrated sessions.\\n\\\n877:                       Each terminal gets a persistent goose session that automatically resumes.\\n\\n\\\n878:                       Setup:\\n  \\\n879:                         echo 'eval \\\"$(goose term init zsh)\\\"' >> ~/.zshrc\\n  \\\n880:                         source ~/.zshrc\\n\\n\\\n881:                       With --default (anything typed that isn't a command goes to goose):\\n  \\\n882:                         echo 'eval \\\"$(goose term init zsh --default)\\\"' >> ~/.zshrc\"\n883:     )]\n884:     Init {\n885:         /// Shell type (bash, zsh, fish, powershell)\n886:         #[arg(value_enum)]\n887:         shell: Shell,\n888: \n889:         #[arg(short, long, help = \"Name for the terminal session\")]\n890:         name: Option<String>,\n891: \n892:         /// Make goose the default handler for unknown commands\n893:         #[arg(\n894:             long = \"default\",\n895:             help = \"Make goose the default handler for unknown commands\",\n896:             long_help = \"When enabled, anything you type that isn't a valid command will be sent to goose. Only supported for zsh and bash.\"\n897:         )]\n898:         default: bool,\n899:     },\n900: \n901:     /// Log a shell command (called by shell hook)\n902:     #[command(about = \"Log a shell command to the session\", hide = true)]\n903:     Log {\n904:         /// The command that was executed\n905:         command: String,\n906:     },\n907: \n908:     /// Run a prompt in the terminal session\n909:     #[command(\n910:         about = \"Run a prompt in the terminal session\",\n911:         long_about = \"Run a prompt in the terminal-integrated session.\\n\\n\\\n912:                       Examples:\\n  \\\n913:                         goose term run list files in this directory\\n  \\\n914:                         @goose list files  # using alias\\n  \\\n915:                         @g why did that fail  # short alias\"\n916:     )]\n917:     Run {\n918:         /// The prompt to send to goose (multiple words allowed without quotes)\n919:         #[arg(required = true, num_args = 1..)]\n920:         prompt: Vec<String>,\n921:     },\n922: \n923:     /// Print session info for prompt integration\n924:     #[command(\n925:         about = \"Print session info for prompt integration\",\n926:         long_about = \"Prints compact session info (token usage, model) for shell prompt integration.\\n\\\n927:                       Example output: ●○○○○ sonnet\"\n928:     )]\n929:     Info,\n930: }\n931: \n932: #[derive(clap::ValueEnum, Clone, Debug)]\n933: enum CliProviderVariant {\n934:     OpenAi,\n935:     Databricks,\n936:     Ollama,\n937: }\n938: \n939: #[derive(Debug)]\n940: pub struct InputConfig {\n941:     pub contents: Option<String>,\n942:     pub extensions_override: Option<Vec<ExtensionConfig>>,\n943:     pub additional_system_prompt: Option<String>,\n944: }\n945: \n946: #[derive(Debug)]\n947: pub struct RecipeInfo {\n948:     pub session_settings: Option<SessionSettings>,\n949:     pub sub_recipes: Option<Vec<goose::recipe::SubRecipe>>,\n950:     pub final_output_response: Option<goose::recipe::Response>,\n951:     pub retry_config: Option<goose::agents::types::RetryConfig>,\n952: }\n953: \n954: pub async fn cli() -> anyhow::Result<()> {\n955:     let cli = Cli::parse();\n956: \n957:     if let Err(e) = crate::project_tracker::update_project_tracker(None, None) {\n958:         warn!(\"Warning: Failed to update project tracker: {}\", e);\n959:     }\n960: \n961:     let command_name = match &cli.command {\n962:         Some(Command::Configure {}) => \"configure\",\n963:         Some(Command::Info { .. }) => \"info\",\n964:         Some(Command::Mcp { .. }) => \"mcp\",\n965:         Some(Command::Acp {}) => \"acp\",\n966:         Some(Command::Session { .. }) => \"session\",\n967:         Some(Command::Project {}) => \"project\",\n968:         Some(Command::Projects) => \"projects\",\n969:         Some(Command::Run { .. }) => \"run\",\n970:         Some(Command::Schedule { .. }) => \"schedule\",\n971:         Some(Command::Update { .. }) => \"update\",\n972:         Some(Command::Bench { .. }) => \"bench\",\n973:         Some(Command::Recipe { .. }) => \"recipe\",\n974:         Some(Command::Web { .. }) => \"web\",\n975:         Some(Command::Term { .. }) => \"term\",\n976:         None => \"default_session\",\n977:     };\n978: \n979:     tracing::info!(\n980:         counter.goose.cli_commands = 1,\n981:         command = command_name,\n982:         \"CLI command executed\"\n983:     );\n984: \n985:     match cli.command {\n986:         Some(Command::Configure {}) => handle_configure().await?,\n987:         Some(Command::Info { verbose }) => handle_info(verbose)?,\n988:         Some(Command::Mcp { server }) => {\n989:             let name = server.name();\n990:             crate::logging::setup_logging(Some(&format!(\"mcp-{name}\")), None)?;\n991:             match server {\n992:                 McpCommand::AutoVisualiser => serve(AutoVisualiserRouter::new()).await?,\n993:                 McpCommand::ComputerController => serve(ComputerControllerServer::new()).await?,\n994:                 McpCommand::Develop => serve(DevelopServer::new()).await?,\n995:                 McpCommand::Developer => serve(DeveloperServer::new()).await?,\n996:                 McpCommand::Memory => serve(MemoryServer::new()).await?,\n997:                 McpCommand::Tutorial => serve(TutorialServer::new()).await?,\n998:             }\n999:         }\n1000:         Some(Command::Acp {}) => {\n1001:             run_acp_agent().await?;\n1002:         }\n1003:         Some(Command::Session {\n1004:             command,\n1005:             identifier,\n1006:             resume,\n1007:             history,\n1008:             debug,\n1009:             max_tool_repetitions,\n1010:             max_turns,\n1011:             extensions,\n1012:             remote_extensions,\n1013:             streamable_http_extensions,\n1014:             builtins,\n1015:         }) => {\n1016:             return match command {\n1017:                 Some(SessionCommand::List {\n1018:                     format,\n1019:                     ascending,\n1020:                     working_dir,\n1021:                     limit,\n1022:                 }) => Ok(handle_session_list(format, ascending, working_dir, limit).await?),\n1023:                 Some(SessionCommand::Remove { identifier, regex }) => {\n1024:                     let (session_id, name) = if let Some(id) = identifier {\n1025:                         (id.session_id, id.name)\n1026:                     } else {\n1027:                         (None, None)\n1028:                     };\n1029:                     Ok(handle_session_remove(session_id, name, regex).await?)\n1030:                 }\n1031:                 Some(SessionCommand::Export {\n1032:                     identifier,\n1033:                     output,\n1034:                     format,\n1035:                 }) => {\n1036:                     let session_identifier = if let Some(id) = identifier {\n1037:                         lookup_session_id(id).await?\n1038:                     } else {\n1039:                         // If no identifier is provided, prompt for interactive selection\n1040:                         match crate::commands::session::prompt_interactive_session_selection().await\n1041:                         {\n1042:                             Ok(id) => id,\n1043:                             Err(e) => {\n1044:                                 eprintln!(\"Error: {}\", e);\n1045:                                 return Ok(());\n1046:                             }\n1047:                         }\n1048:                     };\n1049: \n1050:                     crate::commands::session::handle_session_export(\n1051:                         session_identifier,\n1052:                         output,\n1053:                         format,\n1054:                     )\n1055:                     .await?;\n1056:                     Ok(())\n1057:                 }\n1058:                 Some(SessionCommand::Diagnostics { identifier, output }) => {\n1059:                     let session_id = if let Some(id) = identifier {\n1060:                         lookup_session_id(id).await?\n1061:                     } else {\n1062:                         match crate::commands::session::prompt_interactive_session_selection().await\n1063:                         {\n1064:                             Ok(id) => id,\n1065:                             Err(e) => {\n1066:                                 eprintln!(\"Error: {}\", e);\n1067:                                 return Ok(());\n1068:                             }\n1069:                         }\n1070:                     };\n1071:                     crate::commands::session::handle_diagnostics(&session_id, output).await?;\n1072:                     Ok(())\n1073:                 }\n1074:                 None => {\n1075:                     let session_start = std::time::Instant::now();\n1076:                     let session_type = if resume { \"resumed\" } else { \"new\" };\n1077: \n1078:                     tracing::info!(\n1079:                         counter.goose.session_starts = 1,\n1080:                         session_type,\n1081:                         interactive = true,\n1082:                         \"Session started\"\n1083:                     );\n1084: \n1085:                     if let Some(Identifier {\n1086:                         session_id: Some(_),\n1087:                         ..\n1088:                     }) = &identifier\n1089:                     {\n1090:                         if !resume {\n1091:                             eprintln!(\"Error: --session-id can only be used with --resume flag\");\n1092:                             std::process::exit(1);\n1093:                         }\n1094:                     }\n1095: \n1096:                     let session_id = get_or_create_session_id(identifier, resume, false).await?;\n1097: \n1098:                     // Run session command by default\n1099:                     let mut session: crate::CliSession = build_session(SessionBuilderConfig {\n1100:                         session_id,\n1101:                         resume,\n1102:                         no_session: false,\n1103:                         extensions,\n1104:                         remote_extensions,\n1105:                         streamable_http_extensions,\n1106:                         builtins,\n1107:                         extensions_override: None,\n1108:                         additional_system_prompt: None,\n1109:                         settings: None,\n1110:                         provider: None,\n1111:                         model: None,\n1112:                         debug,\n1113:                         max_tool_repetitions,\n1114:                         max_turns,\n1115:                         scheduled_job_id: None,\n1116:                         interactive: true,\n1117:                         quiet: false,\n1118:                         sub_recipes: None,\n1119:                         final_output_response: None,\n1120:                         retry_config: None,\n1121:                         output_format: \"text\".to_string(),\n1122:                     })\n1123:                     .await;\n1124: \n1125:                     // Render previous messages if resuming a session and history flag is set\n1126:                     if resume && history {\n1127:                         session.render_message_history();\n1128:                     }\n1129: \n1130:                     let result = session.interactive(None).await;\n1131: \n1132:                     let session_duration = session_start.elapsed();\n1133:                     let exit_type = if result.is_ok() { \"normal\" } else { \"error\" };\n1134: \n1135:                     let (total_tokens, message_count) = session\n1136:                         .get_session()\n1137:                         .await\n1138:                         .map(|m| (m.total_tokens.unwrap_or(0), m.message_count))\n1139:                         .unwrap_or((0, 0));\n1140: \n1141:                     tracing::info!(\n1142:                         counter.goose.session_completions = 1,\n1143:                         session_type,\n1144:                         exit_type,\n1145:                         duration_ms = session_duration.as_millis() as u64,\n1146:                         total_tokens,\n1147:                         message_count,\n1148:                         \"Session completed\"\n1149:                     );\n1150: \n1151:                     tracing::info!(\n1152:                         counter.goose.session_duration_ms = session_duration.as_millis() as u64,\n1153:                         session_type,\n1154:                         \"Session duration\"\n1155:                     );\n1156: \n1157:                     if total_tokens > 0 {\n1158:                         tracing::info!(\n1159:                             counter.goose.session_tokens = total_tokens,\n1160:                             session_type,\n1161:                             \"Session tokens\"\n1162:                         );\n1163:                     }\n1164: \n1165:                     Ok(())\n1166:                 }\n1167:             };\n1168:         }\n1169:         Some(Command::Project {}) => {\n1170:             // Default behavior: offer to resume the last project\n1171:             handle_project_default()?;\n1172:             return Ok(());\n1173:         }\n1174:         Some(Command::Projects) => {\n1175:             // Interactive project selection\n1176:             handle_projects_interactive()?;\n1177:             return Ok(());\n1178:         }\n1179: \n1180:         Some(Command::Run {\n1181:             instructions,\n1182:             input_text,\n1183:             recipe,\n1184:             system,\n1185:             interactive,\n1186:             identifier,\n1187:             resume,\n1188:             no_session,\n1189:             debug,\n1190:             max_tool_repetitions,\n1191:             max_turns,\n1192:             extensions,\n1193:             remote_extensions,\n1194:             streamable_http_extensions,\n1195:             builtins,\n1196:             params,\n1197:             explain,\n1198:             render_recipe,\n1199:             scheduled_job_id,\n1200:             quiet,\n1201:             additional_sub_recipes,\n1202:             output_format,\n1203:             provider,\n1204:             model,\n1205:         }) => {\n1206:             let (input_config, recipe_info) = match (instructions, input_text, recipe) {\n1207:                 (Some(file), _, _) if file == \"-\" => {\n1208:                     let mut input = String::new();\n1209:                     std::io::stdin()\n1210:                         .read_to_string(&mut input)\n1211:                         .expect(\"Failed to read from stdin\");\n1212: \n1213:                     let input_config = InputConfig {\n1214:                         contents: Some(input),\n1215:                         extensions_override: None,\n1216:                         additional_system_prompt: system,\n1217:                     };\n1218:                     (input_config, None)\n1219:                 }\n1220:                 (Some(file), _, _) => {\n1221:                     let contents = std::fs::read_to_string(&file).unwrap_or_else(|err| {\n1222:                         eprintln!(\n1223:                             \"Instruction file not found — did you mean to use goose run --text?\\n{}\",\n1224:                             err\n1225:                         );\n1226:                         std::process::exit(1);\n1227:                     });\n1228:                     let input_config = InputConfig {\n1229:                         contents: Some(contents),\n1230:                         extensions_override: None,\n1231:                         additional_system_prompt: None,\n1232:                     };\n1233:                     (input_config, None)\n1234:                 }\n1235:                 (_, Some(text), _) => {\n1236:                     let input_config = InputConfig {\n1237:                         contents: Some(text),\n1238:                         extensions_override: None,\n1239:                         additional_system_prompt: system,\n1240:                     };\n1241:                     (input_config, None)\n1242:                 }\n1243:                 (_, _, Some(recipe_name)) => {\n1244:                     let recipe_display_name = std::path::Path::new(&recipe_name)\n1245:                         .file_name()\n1246:                         .and_then(|name| name.to_str())\n1247:                         .unwrap_or(&recipe_name);\n1248: \n1249:                     let recipe_version =\n1250:                         crate::recipes::search_recipe::load_recipe_file(&recipe_name)\n1251:                             .ok()\n1252:                             .and_then(|rf| {\n1253:                                 goose::recipe::template_recipe::parse_recipe_content(\n1254:                                     &rf.content,\n1255:                                     Some(rf.parent_dir.display().to_string()),\n1256:                                 )\n1257:                                 .ok()\n1258:                                 .map(|(r, _)| r.version)\n1259:                             })\n1260:                             .unwrap_or_else(|| \"unknown\".to_string());\n1261: \n1262:                     if explain {\n1263:                         explain_recipe(&recipe_name, params)?;\n1264:                         return Ok(());\n1265:                     }\n1266:                     if render_recipe {\n1267:                         if let Err(err) = render_recipe_as_yaml(&recipe_name, params) {\n1268:                             eprintln!(\"{}: {}\", console::style(\"Error\").red().bold(), err);\n1269:                             std::process::exit(1);\n1270:                         }\n1271:                         return Ok(());\n1272:                     }\n1273: \n1274:                     tracing::info!(\n1275:                         counter.goose.recipe_runs = 1,\n1276:                         recipe_name = %recipe_display_name,\n1277:                         recipe_version = %recipe_version,\n1278:                         session_type = \"recipe\",\n1279:                         interface = \"cli\",\n1280:                         \"Recipe execution started\"\n1281:                     );\n1282: \n1283:                     let (input_config, recipe_info) = extract_recipe_info_from_cli(\n1284:                         recipe_name,\n1285:                         params,\n1286:                         additional_sub_recipes,\n1287:                         quiet,\n1288:                     )?;\n1289:                     (input_config, Some(recipe_info))\n1290:                 }\n1291:                 (None, None, None) => {\n1292:                     eprintln!(\"Error: Must provide either --instructions (-i), --text (-t), or --recipe. Use -i - for stdin.\");\n1293:                     std::process::exit(1);\n1294:                 }\n1295:             };\n1296: \n1297:             if let Some(Identifier {\n1298:                 session_id: Some(_),\n1299:                 ..\n1300:             }) = &identifier\n1301:             {\n1302:                 if !resume {\n1303:                     eprintln!(\"Error: --session-id can only be used with --resume flag\");\n1304:                     std::process::exit(1);\n1305:                 }\n1306:             }\n1307: \n1308:             let session_id = get_or_create_session_id(identifier, resume, no_session).await?;\n1309: \n1310:             let mut session = build_session(SessionBuilderConfig {\n1311:                 session_id,\n1312:                 resume,\n1313:                 no_session,\n1314:                 extensions,\n1315:                 remote_extensions,\n1316:                 streamable_http_extensions,\n1317:                 builtins,\n1318:                 extensions_override: input_config.extensions_override,\n1319:                 additional_system_prompt: input_config.additional_system_prompt,\n1320:                 settings: recipe_info\n1321:                     .as_ref()\n1322:                     .and_then(|r| r.session_settings.clone()),\n1323:                 provider,\n1324:                 model,\n1325:                 debug,\n1326:                 max_tool_repetitions,\n1327:                 max_turns,\n1328:                 scheduled_job_id,\n1329:                 interactive, // Use the interactive flag from the Run command\n1330:                 quiet,\n1331:                 sub_recipes: recipe_info.as_ref().and_then(|r| r.sub_recipes.clone()),\n1332:                 final_output_response: recipe_info\n1333:                     .as_ref()\n1334:                     .and_then(|r| r.final_output_response.clone()),\n1335:                 retry_config: recipe_info.as_ref().and_then(|r| r.retry_config.clone()),\n1336:                 output_format,\n1337:             })\n1338:             .await;\n1339: \n1340:             if interactive {\n1341:                 session.interactive(input_config.contents).await?;\n1342:             } else if let Some(contents) = input_config.contents {\n1343:                 let session_start = std::time::Instant::now();\n1344:                 let session_type = if recipe_info.is_some() {\n1345:                     \"recipe\"\n1346:                 } else {\n1347:                     \"run\"\n1348:                 };\n1349: \n1350:                 tracing::info!(\n1351:                     counter.goose.session_starts = 1,\n1352:                     session_type,\n1353:                     interactive = false,\n1354:                     \"Headless session started\"\n1355:                 );\n1356: \n1357:                 let result = session.headless(contents).await;\n1358: \n1359:                 let session_duration = session_start.elapsed();\n1360:                 let exit_type = if result.is_ok() { \"normal\" } else { \"error\" };\n1361: \n1362:                 let (total_tokens, message_count) = session\n1363:                     .get_session()\n1364:                     .await\n1365:                     .map(|m| (m.total_tokens.unwrap_or(0), m.message_count))\n1366:                     .unwrap_or((0, 0));\n1367: \n1368:                 tracing::info!(\n1369:                     counter.goose.session_completions = 1,\n1370:                     session_type,\n1371:                     exit_type,\n1372:                     duration_ms = session_duration.as_millis() as u64,\n1373:                     total_tokens,\n1374:                     message_count,\n1375:                     interactive = false,\n1376:                     \"Headless session completed\"\n1377:                 );\n1378: \n1379:                 tracing::info!(\n1380:                     counter.goose.session_duration_ms = session_duration.as_millis() as u64,\n1381:                     session_type,\n1382:                     \"Headless session duration\"\n1383:                 );\n1384: \n1385:                 if total_tokens > 0 {\n1386:                     tracing::info!(\n1387:                         counter.goose.session_tokens = total_tokens,\n1388:                         session_type,\n1389:                         \"Headless session tokens\"\n1390:                     );\n1391:                 }\n1392: \n1393:                 result?;\n1394:             } else {\n1395:                 return Err(anyhow::anyhow!(\n1396:                     \"no text provided for prompt in headless mode\"\n1397:                 ));\n1398:             }\n1399: \n1400:             return Ok(());\n1401:         }\n1402:         Some(Command::Schedule { command }) => {\n1403:             match command {\n1404:                 SchedulerCommand::Add {\n1405:                     schedule_id,\n1406:                     cron,\n1407:                     recipe_source,\n1408:                 } => {\n1409:                     handle_schedule_add(schedule_id, cron, recipe_source).await?;\n1410:                 }\n1411:                 SchedulerCommand::List {} => {\n1412:                     handle_schedule_list().await?;\n1413:                 }\n1414:                 SchedulerCommand::Remove { schedule_id } => {\n1415:                     handle_schedule_remove(schedule_id).await?;\n1416:                 }\n1417:                 SchedulerCommand::Sessions { schedule_id, limit } => {\n1418:                     // New arm\n1419:                     handle_schedule_sessions(schedule_id, limit).await?;\n1420:                 }\n1421:                 SchedulerCommand::RunNow { schedule_id } => {\n1422:                     // New arm\n1423:                     handle_schedule_run_now(schedule_id).await?;\n1424:                 }\n1425:                 SchedulerCommand::ServicesStatus {} => {\n1426:                     handle_schedule_services_status().await?;\n1427:                 }\n1428:                 SchedulerCommand::ServicesStop {} => {\n1429:                     handle_schedule_services_stop().await?;\n1430:                 }\n1431:                 SchedulerCommand::CronHelp {} => {\n1432:                     handle_schedule_cron_help().await?;\n1433:                 }\n1434:             }\n1435:             return Ok(());\n1436:         }\n1437:         Some(Command::Update {\n1438:             canary,\n1439:             reconfigure,\n1440:         }) => {\n1441:             crate::commands::update::update(canary, reconfigure)?;\n1442:             return Ok(());\n1443:         }\n1444:         Some(Command::Bench { cmd }) => {\n1445:             match cmd {\n1446:                 BenchCommand::Selectors { config } => BenchRunner::list_selectors(config)?,\n1447:                 BenchCommand::InitConfig { name } => {\n1448:                     let mut config = BenchRunConfig::default();\n1449:                     let cwd = std::env::current_dir()?;\n1450:                     config.output_dir = Some(cwd);\n1451:                     config.save(name);\n1452:                 }\n1453:                 BenchCommand::Run { config } => BenchRunner::new(config)?.run()?,\n1454:                 BenchCommand::EvalModel { config } => ModelRunner::from(config)?.run()?,\n1455:                 BenchCommand::ExecEval { config } => {\n1456:                     EvalRunner::from(config)?.run(agent_generator).await?\n1457:                 }\n1458:                 BenchCommand::GenerateLeaderboard { benchmark_dir } => {\n1459:                     MetricAggregator::generate_csv_from_benchmark_dir(&benchmark_dir)?\n1460:                 }\n1461:             }\n1462:             return Ok(());\n1463:         }\n1464:         Some(Command::Recipe { command }) => {\n1465:             match command {\n1466:                 RecipeCommand::Validate { recipe_name } => {\n1467:                     handle_validate(&recipe_name)?;\n1468:                 }\n1469:                 RecipeCommand::Deeplink {\n1470:                     recipe_name,\n1471:                     params,\n1472:                 } => {\n1473:                     handle_deeplink(&recipe_name, &params)?;\n1474:                 }\n1475:                 RecipeCommand::Open {\n1476:                     recipe_name,\n1477:                     params,\n1478:                 } => {\n1479:                     handle_open(&recipe_name, &params)?;\n1480:                 }\n1481:                 RecipeCommand::List { format, verbose } => {\n1482:                     handle_list(&format, verbose)?;\n1483:                 }\n1484:             }\n1485:             return Ok(());\n1486:         }\n1487:         Some(Command::Web {\n1488:             port,\n1489:             host,\n1490:             open,\n1491:             auth_token,\n1492:         }) => {\n1493:             crate::commands::web::handle_web(port, host, open, auth_token).await?;\n1494:             return Ok(());\n1495:         }\n1496:         Some(Command::Term { command }) => {\n1497:             match command {\n1498:                 TermCommand::Init {\n1499:                     shell,\n1500:                     name,\n1501:                     default,\n1502:                 } => {\n1503:                     handle_term_init(shell, name, default).await?;\n1504:                 }\n1505:                 TermCommand::Log { command } => {\n1506:                     handle_term_log(command).await?;\n1507:                 }\n1508:                 TermCommand::Run { prompt } => {\n1509:                     handle_term_run(prompt).await?;\n1510:                 }\n1511:                 TermCommand::Info => {\n1512:                     handle_term_info().await?;\n1513:                 }\n1514:             }\n1515:             return Ok(());\n1516:         }\n1517:         None => {\n1518:             return if !Config::global().exists() {\n1519:                 handle_configure().await?;\n1520:                 Ok(())\n1521:             } else {\n1522:                 // Run session command by default\n1523:                 let session_id = get_or_create_session_id(None, false, false).await?;\n1524: \n1525:                 let mut session = build_session(SessionBuilderConfig {\n1526:                     session_id,\n1527:                     resume: false,\n1528:                     no_session: false,\n1529:                     extensions: Vec::new(),\n1530:                     remote_extensions: Vec::new(),\n1531:                     streamable_http_extensions: Vec::new(),\n1532:                     builtins: Vec::new(),\n1533:                     extensions_override: None,\n1534:                     additional_system_prompt: None,\n1535:                     settings: None::<SessionSettings>,\n1536:                     provider: None,\n1537:                     model: None,\n1538:                     debug: false,\n1539:                     max_tool_repetitions: None,\n1540:                     max_turns: None,\n1541:                     scheduled_job_id: None,\n1542:                     interactive: true,\n1543:                     quiet: false,\n1544:                     sub_recipes: None,\n1545:                     final_output_response: None,\n1546:                     retry_config: None,\n1547:                     output_format: \"text\".to_string(),\n1548:                 })\n1549:                 .await;\n1550:                 session.interactive(None).await?;\n1551:                 Ok(())\n1552:             };\n1553:         }\n1554:     }\n1555:     Ok(())\n1556: }\n```\n",
                  "annotations": {
                    "audience": [
                      "user"
                    ],
                    "priority": 0.0
                  }
                }
              ],
              "isError": false
            }
          }
        }
      ],
      "metadata": {
        "userVisible": true,
        "agentVisible": true
      }
    },
    {
      "id": "msg_b8f144d2-f1e8-4d61-b06c-99bfe81b2974",
      "role": "user",
      "created": 1766962614,
      "content": [
        {
          "type": "toolResponse",
          "id": "toolu_01U6qotsW281FRMNfG3Q5LAR",
          "toolResult": {
            "status": "success",
            "value": {
              "content": [
                {
                  "type": "text",
                  "text": "'/Users/baxen/Development/goose/crates/goose-cli/src/session' is a directory. Contents:\n\nDirectories:\n  task_execution_display/\n\nFiles:\n  builder.rs\n  completion.rs\n  elicitation.rs\n  export.rs\n  input.rs\n  mod.rs\n  output.rs\n  prompt.rs\n  thinking.rs\n"
                }
              ],
              "isError": false
            }
          }
        }
      ],
      "metadata": {
        "userVisible": true,
        "agentVisible": true
      }
    },
    {
      "id": "msg_01NhS3rCUTuMEPFkQ48SXNwo",
      "role": "assistant",
      "created": 1766962617,
      "content": [
        {
          "type": "toolRequest",
          "id": "toolu_01UPaWBT6ZgNWGXczf68hdf9",
          "toolCall": {
            "status": "success",
            "value": {
              "name": "developer__text_editor",
              "arguments": {
                "command": "view",
                "path": "/Users/baxen/Development/goose/crates/goose-cli/src/session/mod.rs"
              }
            }
          }
        }
      ],
      "metadata": {
        "userVisible": true,
        "agentVisible": true
      }
    },
    {
      "id": "msg_19f046d6-ce94-485f-8145-a1bc41deb759",
      "role": "user",
      "created": 1766962617,
      "content": [
        {
          "type": "toolResponse",
          "id": "toolu_01UPaWBT6ZgNWGXczf68hdf9",
          "toolResult": {
            "status": "success",
            "value": {
              "content": [
                {
                  "type": "resource",
                  "resource": {
                    "uri": "file:///Users/baxen/Development/goose/crates/goose-cli/src/session/mod.rs",
                    "mimeType": "text",
                    "text": "mod builder;\nmod completion;\nmod elicitation;\nmod export;\nmod input;\nmod output;\nmod prompt;\nmod task_execution_display;\nmod thinking;\n\nuse crate::session::task_execution_display::{\n    format_task_execution_notification, TASK_EXECUTION_NOTIFICATION_TYPE,\n};\nuse goose::conversation::Conversation;\nuse std::io::Write;\nuse std::str::FromStr;\nuse tokio::signal::ctrl_c;\nuse tokio_util::task::AbortOnDropHandle;\n\npub use self::export::message_to_markdown;\npub use builder::{build_session, SessionBuilderConfig, SessionSettings};\nuse console::Color;\nuse goose::agents::AgentEvent;\nuse goose::permission::permission_confirmation::PrincipalType;\nuse goose::permission::Permission;\nuse goose::permission::PermissionConfirmation;\nuse goose::providers::base::Provider;\nuse goose::utils::safe_truncate;\n\nuse anyhow::{Context, Result};\nuse completion::GooseCompleter;\nuse goose::agents::extension::{Envs, ExtensionConfig, PLATFORM_EXTENSIONS};\nuse goose::agents::types::RetryConfig;\nuse goose::agents::{Agent, SessionConfig, COMPACT_TRIGGERS};\nuse goose::config::{Config, GooseMode};\nuse goose::session::SessionManager;\nuse input::InputResult;\nuse rmcp::model::PromptMessage;\nuse rmcp::model::ServerNotification;\nuse rmcp::model::{ErrorCode, ErrorData};\n\nuse goose::config::paths::Paths;\nuse goose::conversation::message::{ActionRequiredData, Message, MessageContent};\nuse rand::{distributions::Alphanumeric, Rng};\nuse rustyline::EditMode;\nuse serde::{Deserialize, Serialize};\nuse serde_json::Value;\nuse std::collections::HashMap;\nuse std::path::PathBuf;\nuse std::sync::Arc;\nuse std::time::Instant;\nuse tokio;\nuse tokio_util::sync::CancellationToken;\nuse tracing::warn;\n\n#[derive(Serialize, Deserialize, Debug)]\nstruct JsonOutput {\n    messages: Vec<Message>,\n    metadata: JsonMetadata,\n}\n\n#[derive(Serialize, Deserialize, Debug)]\nstruct JsonMetadata {\n    total_tokens: Option<i32>,\n    input_tokens: Option<i32>,\n    output_tokens: Option<i32>,\n    accumulated_total_tokens: Option<i32>,\n    accumulated_input_tokens: Option<i32>,\n    accumulated_output_tokens: Option<i32>,\n    status: String,\n}\n\n#[derive(Serialize, Debug)]\n#[serde(tag = \"type\", rename_all = \"snake_case\")]\nenum StreamEvent {\n    Message {\n        message: Message,\n    },\n    Notification {\n        extension_id: String,\n        #[serde(flatten)]\n        data: NotificationData,\n    },\n    ModelChange {\n        model: String,\n        mode: String,\n    },\n    Error {\n        error: String,\n    },\n    Complete {\n        total_tokens: Option<i32>,\n    },\n}\n\n#[derive(Serialize, Debug)]\n#[serde(rename_all = \"snake_case\")]\nenum NotificationData {\n    Log {\n        message: String,\n    },\n    Progress {\n        progress: f64,\n        total: Option<f64>,\n        message: Option<String>,\n    },\n}\n\npub enum RunMode {\n    Normal,\n    Plan,\n}\n\npub struct CliSession {\n    agent: Agent,\n    messages: Conversation,\n    session_id: String,\n    completion_cache: Arc<std::sync::RwLock<CompletionCache>>,\n    debug: bool,\n    run_mode: RunMode,\n    scheduled_job_id: Option<String>, // ID of the scheduled job that triggered this session\n    max_turns: Option<u32>,\n    edit_mode: Option<EditMode>,\n    retry_config: Option<RetryConfig>,\n    output_format: String,\n}\n\n// Cache structure for completion data\nstruct CompletionCache {\n    prompts: HashMap<String, Vec<String>>,\n    prompt_info: HashMap<String, output::PromptInfo>,\n    last_updated: Instant,\n}\n\nimpl CompletionCache {\n    fn new() -> Self {\n        Self {\n            prompts: HashMap::new(),\n            prompt_info: HashMap::new(),\n            last_updated: Instant::now(),\n        }\n    }\n}\n\npub enum PlannerResponseType {\n    Plan,\n    ClarifyingQuestions,\n}\n\n/// Decide if the planner's reponse is a plan or a clarifying question\n///\n/// This function is called after the planner has generated a response\n/// to the user's message. The response is either a plan or a clarifying\n/// question.\npub async fn classify_planner_response(\n    message_text: String,\n    provider: Arc<dyn Provider>,\n) -> Result<PlannerResponseType> {\n    let prompt = format!(\"The text below is the output from an AI model which can either provide a plan or list of clarifying questions. Based on the text below, decide if the output is a \\\"plan\\\" or \\\"clarifying questions\\\".\\n---\\n{message_text}\");\n\n    // Generate the description\n    let message = Message::user().with_text(&prompt);\n    let (result, _usage) = provider\n        .complete(\n            \"Reply only with the classification label: \\\"plan\\\" or \\\"clarifying questions\\\"\",\n            &[message],\n            &[],\n        )\n        .await?;\n\n    let predicted = result.as_concat_text();\n    if predicted.to_lowercase().contains(\"plan\") {\n        Ok(PlannerResponseType::Plan)\n    } else {\n        Ok(PlannerResponseType::ClarifyingQuestions)\n    }\n}\n\nfn generate_extension_name(extension_command: &str) -> String {\n    let cmd_name: String = extension_command\n        .split([' ', '/'])\n        .next_back()\n        .unwrap_or(\"\")\n        .chars()\n        .filter(|c| c.is_alphanumeric())\n        .collect();\n\n    let prefix: String = cmd_name.chars().take(16).collect();\n\n    let random_suffix: String = rand::thread_rng()\n        .sample_iter(&Alphanumeric)\n        .take(8)\n        .map(char::from)\n        .collect();\n\n    let name = format!(\"{}_{}\", prefix, random_suffix);\n\n    if name.chars().next().is_none_or(|c| !c.is_alphabetic()) {\n        format!(\"g{}\", name)\n    } else {\n        name\n    }\n}\n\nimpl CliSession {\n    #[allow(clippy::too_many_arguments)]\n    pub async fn new(\n        agent: Agent,\n        session_id: String,\n        debug: bool,\n        scheduled_job_id: Option<String>,\n        max_turns: Option<u32>,\n        edit_mode: Option<EditMode>,\n        retry_config: Option<RetryConfig>,\n        output_format: String,\n    ) -> Self {\n        let messages = SessionManager::get_session(&session_id, true)\n            .await\n            .map(|session| session.conversation.unwrap_or_default())\n            .unwrap();\n\n        CliSession {\n            agent,\n            messages,\n            session_id,\n            completion_cache: Arc::new(std::sync::RwLock::new(CompletionCache::new())),\n            debug,\n            run_mode: RunMode::Normal,\n            scheduled_job_id,\n            max_turns,\n            edit_mode,\n            retry_config,\n            output_format,\n        }\n    }\n\n    pub fn session_id(&self) -> &String {\n        &self.session_id\n    }\n\n    /// Add a stdio extension to the session\n    ///\n    /// # Arguments\n    /// * `extension_command` - Full command string including environment variables\n    ///   Format: \"ENV1=val1 ENV2=val2 command args...\"\n    pub async fn add_extension(&mut self, extension_command: String) -> Result<()> {\n        let mut parts: Vec<&str> = extension_command.split_whitespace().collect();\n        let mut envs = HashMap::new();\n\n        while let Some(part) = parts.first() {\n            if !part.contains('=') {\n                break;\n            }\n            let env_part = parts.remove(0);\n            let (key, value) = env_part.split_once('=').unwrap();\n            envs.insert(key.to_string(), value.to_string());\n        }\n\n        if parts.is_empty() {\n            return Err(anyhow::anyhow!(\"No command provided in extension string\"));\n        }\n\n        let cmd = parts.remove(0).to_string();\n        let name = generate_extension_name(&extension_command);\n\n        let config = ExtensionConfig::Stdio {\n            name,\n            cmd,\n            args: parts.iter().map(|s| s.to_string()).collect(),\n            envs: Envs::new(envs),\n            env_keys: Vec::new(),\n            description: goose::config::DEFAULT_EXTENSION_DESCRIPTION.to_string(),\n            // TODO: should set timeout\n            timeout: Some(goose::config::DEFAULT_EXTENSION_TIMEOUT),\n            bundled: None,\n            available_tools: Vec::new(),\n        };\n\n        self.agent\n            .add_extension(config)\n            .await\n            .map_err(|e| anyhow::anyhow!(\"Failed to start extension: {}\", e))?;\n\n        // Invalidate the completion cache when a new extension is added\n        self.invalidate_completion_cache().await;\n\n        Ok(())\n    }\n\n    /// Add a remote extension to the session\n    ///\n    /// # Arguments\n    /// * `extension_url` - URL of the server\n    pub async fn add_remote_extension(&mut self, extension_url: String) -> Result<()> {\n        let name = generate_extension_name(&extension_url);\n\n        let config = ExtensionConfig::Sse {\n            name,\n            uri: extension_url,\n            envs: Envs::new(HashMap::new()),\n            env_keys: Vec::new(),\n            description: goose::config::DEFAULT_EXTENSION_DESCRIPTION.to_string(),\n            // TODO: should set timeout\n            timeout: Some(goose::config::DEFAULT_EXTENSION_TIMEOUT),\n            bundled: None,\n            available_tools: Vec::new(),\n        };\n\n        self.agent\n            .add_extension(config)\n            .await\n            .map_err(|e| anyhow::anyhow!(\"Failed to start extension: {}\", e))?;\n\n        // Invalidate the completion cache when a new extension is added\n        self.invalidate_completion_cache().await;\n\n        Ok(())\n    }\n\n    /// Add a streamable HTTP extension to the session\n    ///\n    /// # Arguments\n    /// * `extension_url` - URL of the server\n    pub async fn add_streamable_http_extension(&mut self, extension_url: String) -> Result<()> {\n        let name = generate_extension_name(&extension_url);\n\n        let config = ExtensionConfig::StreamableHttp {\n            name,\n            uri: extension_url,\n            envs: Envs::new(HashMap::new()),\n            env_keys: Vec::new(),\n            headers: HashMap::new(),\n            description: goose::config::DEFAULT_EXTENSION_DESCRIPTION.to_string(),\n            // TODO: should set timeout\n            timeout: Some(goose::config::DEFAULT_EXTENSION_TIMEOUT),\n            bundled: None,\n            available_tools: Vec::new(),\n        };\n\n        self.agent\n            .add_extension(config)\n            .await\n            .map_err(|e| anyhow::anyhow!(\"Failed to start extension: {}\", e))?;\n\n        // Invalidate the completion cache when a new extension is added\n        self.invalidate_completion_cache().await;\n\n        Ok(())\n    }\n\n    /// Add a builtin extension to the session\n    ///\n    /// # Arguments\n    /// * `builtin_name` - Name of the builtin extension(s), comma separated\n    pub async fn add_builtin(&mut self, builtin_name: String) -> Result<()> {\n        for name in builtin_name.split(',') {\n            let extension_name = name.trim();\n\n            let config = if PLATFORM_EXTENSIONS.contains_key(extension_name) {\n                ExtensionConfig::Platform {\n                    name: extension_name.to_string(),\n                    bundled: None,\n                    description: name.to_string(),\n                    available_tools: Vec::new(),\n                }\n            } else {\n                ExtensionConfig::Builtin {\n                    name: extension_name.to_string(),\n                    display_name: None,\n                    timeout: None,\n                    bundled: None,\n                    description: name.to_string(),\n                    available_tools: Vec::new(),\n                }\n            };\n            self.agent\n                .add_extension(config)\n                .await\n                .map_err(|e| anyhow::anyhow!(\"Failed to start builtin extension: {}\", e))?;\n        }\n\n        // Invalidate the completion cache when a new extension is added\n        self.invalidate_completion_cache().await;\n\n        Ok(())\n    }\n\n    pub async fn list_prompts(\n        &mut self,\n        extension: Option<String>,\n    ) -> Result<HashMap<String, Vec<String>>> {\n        let prompts = self.agent.list_extension_prompts().await;\n\n        // Early validation if filtering by extension\n        if let Some(filter) = &extension {\n            if !prompts.contains_key(filter) {\n                return Err(anyhow::anyhow!(\"Extension '{}' not found\", filter));\n            }\n        }\n\n        // Convert prompts into filtered map of extension names to prompt names\n        Ok(prompts\n            .into_iter()\n            .filter(|(ext, _)| extension.as_ref().is_none_or(|f| f == ext))\n            .map(|(extension, prompt_list)| {\n                let names = prompt_list.into_iter().map(|p| p.name).collect();\n                (extension, names)\n            })\n            .collect())\n    }\n\n    pub async fn get_prompt_info(&mut self, name: &str) -> Result<Option<output::PromptInfo>> {\n        let prompts = self.agent.list_extension_prompts().await;\n\n        // Find which extension has this prompt\n        for (extension, prompt_list) in prompts {\n            if let Some(prompt) = prompt_list.iter().find(|p| p.name == name) {\n                return Ok(Some(output::PromptInfo {\n                    name: prompt.name.clone(),\n                    description: prompt.description.clone(),\n                    arguments: prompt.arguments.clone(),\n                    extension: Some(extension),\n                }));\n            }\n        }\n\n        Ok(None)\n    }\n\n    pub async fn get_prompt(&mut self, name: &str, arguments: Value) -> Result<Vec<PromptMessage>> {\n        Ok(self.agent.get_prompt(name, arguments).await?.messages)\n    }\n\n    /// Process a single message and get the response\n    pub(crate) async fn process_message(\n        &mut self,\n        message: Message,\n        cancel_token: CancellationToken,\n    ) -> Result<()> {\n        let cancel_token = cancel_token.clone();\n        self.push_message(message);\n        self.process_agent_response(false, cancel_token).await?;\n        Ok(())\n    }\n\n    /// Start an interactive session, optionally with an initial message\n    pub async fn interactive(&mut self, prompt: Option<String>) -> Result<()> {\n        // Process initial message if provided\n        if let Some(prompt) = prompt {\n            let msg = Message::user().with_text(&prompt);\n            self.process_message(msg, CancellationToken::default())\n                .await?;\n        }\n\n        // Initialize the completion cache\n        self.update_completion_cache().await?;\n\n        // Create a new editor with our custom completer\n        let builder =\n            rustyline::Config::builder().completion_type(rustyline::CompletionType::Circular);\n        let builder = if let Some(edit_mode) = self.edit_mode {\n            builder.edit_mode(edit_mode)\n        } else {\n            // Default to Emacs mode if no edit mode is set\n            builder.edit_mode(EditMode::Emacs)\n        };\n        let config = builder.build();\n        let mut editor =\n            rustyline::Editor::<GooseCompleter, rustyline::history::DefaultHistory>::with_config(\n                config,\n            )?;\n\n        // Set up the completer with a reference to the completion cache\n        let completer = GooseCompleter::new(self.completion_cache.clone());\n        editor.set_helper(Some(completer));\n\n        let history_file = Paths::state_dir().join(\"history.txt\");\n        let old_history_file = Paths::config_dir().join(\"history.txt\");\n\n        if let Some(parent) = history_file.parent() {\n            if !parent.exists() {\n                std::fs::create_dir_all(parent)?;\n            }\n        }\n\n        let history_files = [&history_file, &old_history_file];\n        let load_from = history_files.iter().find(|f| f.exists());\n\n        if let Some(file) = load_from {\n            if let Err(err) = editor.load_history(file) {\n                eprintln!(\"Warning: Failed to load command history: {}\", err);\n            }\n        }\n\n        let save_history =\n            |editor: &mut rustyline::Editor<GooseCompleter, rustyline::history::DefaultHistory>| {\n                if let Err(err) = editor.save_history(&history_file) {\n                    eprintln!(\"Warning: Failed to save command history: {}\", err);\n                } else if old_history_file.exists() {\n                    if let Err(err) = std::fs::remove_file(&old_history_file) {\n                        eprintln!(\"Warning: Failed to remove old history file: {}\", err);\n                    }\n                }\n            };\n\n        output::display_greeting();\n        loop {\n            // Display context usage before each prompt\n            self.display_context_usage().await?;\n\n            match input::get_input(&mut editor)? {\n                InputResult::Message(content) => {\n                    match self.run_mode {\n                        RunMode::Normal => {\n                            save_history(&mut editor);\n\n                            self.push_message(Message::user().with_text(&content));\n\n                            // Track the current directory and last instruction in projects.json\n                            if let Err(e) = crate::project_tracker::update_project_tracker(\n                                Some(&content),\n                                Some(&self.session_id),\n                            ) {\n                                eprintln!(\"Warning: Failed to update project tracker with instruction: {}\", e);\n                            }\n\n                            let _provider = self.agent.provider().await?;\n\n                            output::show_thinking();\n                            let start_time = Instant::now();\n                            self.process_agent_response(true, CancellationToken::default())\n                                .await?;\n                            output::hide_thinking();\n\n                            // Display elapsed time\n                            let elapsed = start_time.elapsed();\n                            let elapsed_str = format_elapsed_time(elapsed);\n                            println!(\n                                \"\\n{}\",\n                                console::style(format!(\"⏱️  Elapsed time: {}\", elapsed_str)).dim()\n                            );\n                        }\n                        RunMode::Plan => {\n                            let mut plan_messages = self.messages.clone();\n                            plan_messages.push(Message::user().with_text(&content));\n                            let reasoner = get_reasoner().await?;\n                            self.plan_with_reasoner_model(plan_messages, reasoner)\n                                .await?;\n                        }\n                    }\n                }\n                input::InputResult::Exit => break,\n                input::InputResult::AddExtension(cmd) => {\n                    save_history(&mut editor);\n\n                    match self.add_extension(cmd.clone()).await {\n                        Ok(_) => output::render_extension_success(&cmd),\n                        Err(e) => output::render_extension_error(&cmd, &e.to_string()),\n                    }\n                }\n                input::InputResult::AddBuiltin(names) => {\n                    save_history(&mut editor);\n\n                    match self.add_builtin(names.clone()).await {\n                        Ok(_) => output::render_builtin_success(&names),\n                        Err(e) => output::render_builtin_error(&names, &e.to_string()),\n                    }\n                }\n                input::InputResult::ToggleTheme => {\n                    save_history(&mut editor);\n\n                    let current = output::get_theme();\n                    let new_theme = match current {\n                        output::Theme::Ansi => {\n                            println!(\"Switching to Light theme\");\n                            output::Theme::Light\n                        }\n                        output::Theme::Light => {\n                            println!(\"Switching to Dark theme\");\n                            output::Theme::Dark\n                        }\n                        output::Theme::Dark => {\n                            println!(\"Switching to Ansi theme\");\n                            output::Theme::Ansi\n                        }\n                    };\n                    output::set_theme(new_theme);\n                    continue;\n                }\n\n                input::InputResult::SelectTheme(theme_name) => {\n                    save_history(&mut editor);\n\n                    let new_theme = match theme_name.as_str() {\n                        \"light\" => {\n                            println!(\"Switching to Light theme\");\n                            output::Theme::Light\n                        }\n                        \"dark\" => {\n                            println!(\"Switching to Dark theme\");\n                            output::Theme::Dark\n                        }\n                        \"ansi\" => {\n                            println!(\"Switching to Ansi theme\");\n                            output::Theme::Ansi\n                        }\n                        _ => output::Theme::Dark,\n                    };\n                    output::set_theme(new_theme);\n                    continue;\n                }\n                input::InputResult::Retry => continue,\n                input::InputResult::ListPrompts(extension) => {\n                    save_history(&mut editor);\n\n                    match self.list_prompts(extension).await {\n                        Ok(prompts) => output::render_prompts(&prompts),\n                        Err(e) => output::render_error(&e.to_string()),\n                    }\n                }\n                input::InputResult::GooseMode(mode) => {\n                    save_history(&mut editor);\n\n                    let config = Config::global();\n                    let mode = match GooseMode::from_str(&mode.to_lowercase()) {\n                        Ok(mode) => mode,\n                        Err(_) => {\n                            output::render_error(&format!(\n                                \"Invalid mode '{}'. Mode must be one of: auto, approve, chat, smart_approve\",\n                                mode\n                            ));\n                            continue;\n                        }\n                    };\n                    config.set_goose_mode(mode)?;\n                    output::goose_mode_message(&format!(\"Goose mode set to '{:?}'\", mode));\n                    continue;\n                }\n                input::InputResult::Plan(options) => {\n                    self.run_mode = RunMode::Plan;\n                    output::render_enter_plan_mode();\n\n                    let message_text = options.message_text;\n                    if message_text.is_empty() {\n                        continue;\n                    }\n                    let mut plan_messages = self.messages.clone();\n                    plan_messages.push(Message::user().with_text(&message_text));\n\n                    let reasoner = get_reasoner().await?;\n                    self.plan_with_reasoner_model(plan_messages, reasoner)\n                        .await?;\n                }\n                input::InputResult::EndPlan => {\n                    self.run_mode = RunMode::Normal;\n                    output::render_exit_plan_mode();\n                    continue;\n                }\n                input::InputResult::Clear => {\n                    save_history(&mut editor);\n\n                    if let Err(e) = SessionManager::replace_conversation(\n                        &self.session_id,\n                        &Conversation::default(),\n                    )\n                    .await\n                    {\n                        output::render_error(&format!(\"Failed to clear session: {}\", e));\n                        continue;\n                    }\n\n                    if let Err(e) = SessionManager::update_session(&self.session_id)\n                        .total_tokens(Some(0))\n                        .input_tokens(Some(0))\n                        .output_tokens(Some(0))\n                        .apply()\n                        .await\n                    {\n                        output::render_error(&format!(\"Failed to reset token counts: {}\", e));\n                        continue;\n                    }\n\n                    self.messages.clear();\n\n                    tracing::info!(\"Chat context cleared by user.\");\n                    output::render_message(\n                        &Message::assistant().with_text(\"Chat context cleared.\\n\"),\n                        self.debug,\n                    );\n\n                    continue;\n                }\n                input::InputResult::PromptCommand(opts) => {\n                    save_history(&mut editor);\n                    self.handle_prompt_command(opts).await?;\n                }\n                InputResult::Recipe(filepath_opt) => {\n                    println!(\"{}\", console::style(\"Generating Recipe\").green());\n\n                    output::show_thinking();\n                    let recipe = self.agent.create_recipe(self.messages.clone()).await;\n                    output::hide_thinking();\n\n                    match recipe {\n                        Ok(recipe) => {\n                            // Use provided filepath or default\n                            let filepath_str = filepath_opt.as_deref().unwrap_or(\"recipe.yaml\");\n                            match self.save_recipe(&recipe, filepath_str) {\n                                Ok(path) => println!(\n                                    \"{}\",\n                                    console::style(format!(\"Saved recipe to {}\", path.display()))\n                                        .green()\n                                ),\n                                Err(e) => {\n                                    println!(\"{}\", console::style(e).red());\n                                }\n                            }\n                        }\n                        Err(e) => {\n                            println!(\n                                \"{}: {:?}\",\n                                console::style(\"Failed to generate recipe\").red(),\n                                e\n                            );\n                        }\n                    }\n\n                    continue;\n                }\n                InputResult::Compact => {\n                    save_history(&mut editor);\n\n                    let prompt = \"Are you sure you want to compact this conversation? This will condense the message history.\";\n                    let should_summarize =\n                        match cliclack::confirm(prompt).initial_value(true).interact() {\n                            Ok(choice) => choice,\n                            Err(e) => {\n                                if e.kind() == std::io::ErrorKind::Interrupted {\n                                    false\n                                } else {\n                                    return Err(e.into());\n                                }\n                            }\n                        };\n\n                    if should_summarize {\n                        self.push_message(Message::user().with_text(COMPACT_TRIGGERS[0]));\n                        output::show_thinking();\n                        self.process_agent_response(true, CancellationToken::default())\n                            .await?;\n                        output::hide_thinking();\n                    } else {\n                        println!(\"{}\", console::style(\"Compaction cancelled.\").yellow());\n                    }\n                    continue;\n                }\n            }\n        }\n\n        println!(\n            \"Closing session. Session ID: {}\",\n            console::style(&self.session_id).cyan()\n        );\n\n        Ok(())\n    }\n\n    async fn plan_with_reasoner_model(\n        &mut self,\n        plan_messages: Conversation,\n        reasoner: Arc<dyn Provider>,\n    ) -> Result<(), anyhow::Error> {\n        let plan_prompt = self.agent.get_plan_prompt().await?;\n        output::show_thinking();\n        let (plan_response, _usage) = reasoner\n            .complete(&plan_prompt, plan_messages.messages(), &[])\n            .await?;\n        output::render_message(&plan_response, self.debug);\n        output::hide_thinking();\n        let planner_response_type =\n            classify_planner_response(plan_response.as_concat_text(), self.agent.provider().await?)\n                .await?;\n\n        match planner_response_type {\n            PlannerResponseType::Plan => {\n                println!();\n                let should_act = match cliclack::confirm(\n                    \"Do you want to clear message history & act on this plan?\",\n                )\n                .initial_value(true)\n                .interact()\n                {\n                    Ok(choice) => choice,\n                    Err(e) => {\n                        if e.kind() == std::io::ErrorKind::Interrupted {\n                            false // If interrupted, set should_act to false\n                        } else {\n                            return Err(e.into());\n                        }\n                    }\n                };\n                if should_act {\n                    output::render_act_on_plan();\n                    self.run_mode = RunMode::Normal;\n                    // set goose mode: auto if that isn't already the case\n                    let config = Config::global();\n                    let curr_goose_mode = config.get_goose_mode().unwrap_or(GooseMode::Auto);\n                    if curr_goose_mode != GooseMode::Auto {\n                        config.set_goose_mode(GooseMode::Auto).unwrap();\n                    }\n\n                    // clear the messages before acting on the plan\n                    self.messages.clear();\n                    // add the plan response as a user message\n                    let plan_message = Message::user().with_text(plan_response.as_concat_text());\n                    self.push_message(plan_message);\n                    // act on the plan\n                    output::show_thinking();\n                    self.process_agent_response(true, CancellationToken::default())\n                        .await?;\n                    output::hide_thinking();\n\n                    // Reset run & goose mode\n                    if curr_goose_mode != GooseMode::Auto {\n                        config.set_goose_mode(curr_goose_mode)?;\n                    }\n                } else {\n                    // add the plan response (assistant message) & carry the conversation forward\n                    // in the next round, the user might wanna slightly modify the plan\n                    self.push_message(plan_response);\n                }\n            }\n            PlannerResponseType::ClarifyingQuestions => {\n                // add the plan response (assistant message) & carry the conversation forward\n                // in the next round, the user will answer the clarifying questions\n                self.push_message(plan_response);\n            }\n        }\n\n        Ok(())\n    }\n\n    /// Process a single message and exit\n    pub async fn headless(&mut self, prompt: String) -> Result<()> {\n        let message = Message::user().with_text(&prompt);\n        self.process_message(message, CancellationToken::default())\n            .await?;\n        Ok(())\n    }\n\n    async fn process_agent_response(\n        &mut self,\n        interactive: bool,\n        cancel_token: CancellationToken,\n    ) -> Result<()> {\n        let is_json_mode = self.output_format == \"json\";\n        let is_stream_json_mode = self.output_format == \"stream-json\";\n\n        // Helper to emit a streaming JSON event\n        let emit_stream_event = |event: &StreamEvent| {\n            if let Ok(json) = serde_json::to_string(event) {\n                println!(\"{}\", json);\n            }\n        };\n\n        let session_config = SessionConfig {\n            id: self.session_id.clone(),\n            schedule_id: self.scheduled_job_id.clone(),\n            max_turns: self.max_turns,\n            retry_config: self.retry_config.clone(),\n        };\n        let user_message = self\n            .messages\n            .last()\n            .ok_or_else(|| anyhow::anyhow!(\"No user message\"))?;\n\n        let cancel_token_interrupt = cancel_token.clone();\n        let handle = tokio::spawn(async move {\n            if ctrl_c().await.is_ok() {\n                cancel_token_interrupt.cancel();\n            }\n        });\n        let _drop_handle = AbortOnDropHandle::new(handle);\n\n        let mut stream = self\n            .agent\n            .reply(\n                user_message.clone(),\n                session_config.clone(),\n                Some(cancel_token.clone()),\n            )\n            .await?;\n\n        let mut progress_bars = output::McpSpinners::new();\n        let cancel_token_clone = cancel_token.clone();\n\n        use futures::StreamExt;\n        loop {\n            tokio::select! {\n                result = stream.next() => {\n                    match result {\n                        Some(Ok(AgentEvent::Message(message))) => {\n                            let tool_call_confirmation = message.content.iter().find_map(|content| {\n                                if let MessageContent::ActionRequired(action) = content {\n                                    #[allow(irrefutable_let_patterns)] // this is a one variant enum right now but it will have more\n                                    if let ActionRequiredData::ToolConfirmation { id, tool_name, arguments, prompt } = &action.data {\n                                        Some((id.clone(), tool_name.clone(), arguments.clone(), prompt.clone()))\n                                    } else {\n                                        None\n                                    }\n                                } else {\n                                    None\n                                }\n                            });\n\n                            let elicitation_request = message.content.iter().find_map(|content| {\n                                if let MessageContent::ActionRequired(action) = content {\n                                    if let ActionRequiredData::Elicitation { id, message, requested_schema } = &action.data {\n                                        Some((id.clone(), message.clone(), requested_schema.clone()))\n                                    } else {\n                                        None\n                                    }\n                                } else {\n                                    None\n                                }\n                            });\n\n                            if let Some((id, _tool_name, _arguments, security_prompt)) = tool_call_confirmation {\n                                output::hide_thinking();\n\n                                // Format the confirmation prompt - use security message if present, otherwise use generic message\n                                let prompt = if let Some(security_message) = &security_prompt {\n                                    println!(\"\\n{}\", security_message);\n                                    \"Do you allow this tool call?\".to_string()\n                                } else {\n                                    \"Goose would like to call the above tool, do you allow?\".to_string()\n                                };\n\n                                // Get confirmation from user\n                                let permission_result = if security_prompt.is_none() {\n                                    // No security message - show all options including \"Always Allow\"\n                                    cliclack::select(prompt)\n                                        .item(Permission::AllowOnce, \"Allow\", \"Allow the tool call once\")\n                                        .item(Permission::AlwaysAllow, \"Always Allow\", \"Always allow the tool call\")\n                                        .item(Permission::DenyOnce, \"Deny\", \"Deny the tool call\")\n                                        .item(Permission::Cancel, \"Cancel\", \"Cancel the AI response and tool call\")\n                                        .interact()\n                                } else {\n                                    // Security message present - don't show \"Always Allow\"\n                                    cliclack::select(prompt)\n                                        .item(Permission::AllowOnce, \"Allow\", \"Allow the tool call once\")\n                                        .item(Permission::DenyOnce, \"Deny\", \"Deny the tool call\")\n                                        .item(Permission::Cancel, \"Cancel\", \"Cancel the AI response and tool call\")\n                                        .interact()\n                                };\n\n                                let permission = match permission_result {\n                                    Ok(p) => p,\n                                    Err(e) => {\n                                        if e.kind() == std::io::ErrorKind::Interrupted {\n                                            Permission::Cancel\n                                        } else {\n                                            return Err(e.into());\n                                        }\n                                    }\n                                };\n\n                                if permission == Permission::Cancel {\n                                    output::render_text(\"Tool call cancelled. Returning to chat...\", Some(Color::Yellow), true);\n\n                                    let mut response_message = Message::user();\n                                    response_message.content.push(MessageContent::tool_response(\n                                        id.clone(),\n                                        Err(ErrorData { code: ErrorCode::INVALID_REQUEST, message: std::borrow::Cow::from(\"Tool call cancelled by user\".to_string()), data: None })\n                                    ));\n                                    self.messages.push(response_message);\n                                    cancel_token_clone.cancel();\n                                    drop(stream);\n                                    break;\n                                } else {\n                                    self.agent.handle_confirmation(id.clone(), PermissionConfirmation {\n                                        principal_type: PrincipalType::Tool,\n                                        permission,\n                                    }).await;\n                                }\n                            }\n                            else if let Some((elicitation_id, elicitation_message, schema)) = elicitation_request {\n                                output::hide_thinking();\n                                let _ = progress_bars.hide();\n\n                                match elicitation::collect_elicitation_input(&elicitation_message, &schema) {\n                                    Ok(Some(user_data)) => {\n                                        let user_data_value = serde_json::to_value(user_data)\n                                            .unwrap_or(serde_json::Value::Object(serde_json::Map::new()));\n\n                                        let response_message = Message::user()\n                                            .with_content(MessageContent::action_required_elicitation_response(\n                                                elicitation_id.clone(),\n                                                user_data_value,\n                                            ))\n                                            .with_visibility(false, true);\n\n                                        self.messages.push(response_message.clone());\n                                        // Elicitation responses return an empty stream - the response\n                                        // unblocks the waiting tool call via ActionRequiredManager\n                                        let _ = self\n                                            .agent\n                                            .reply(\n                                                response_message,\n                                                session_config.clone(),\n                                                Some(cancel_token.clone()),\n                                            )\n                                            .await?;\n                                    }\n                                    Ok(None) => {\n                                        output::render_text(\"Information request cancelled.\", Some(Color::Yellow), true);\n                                        cancel_token_clone.cancel();\n                                        drop(stream);\n                                        break;\n                                    }\n                                    Err(e) => {\n                                        output::render_error(&format!(\"Failed to collect input: {}\", e));\n                                        cancel_token_clone.cancel();\n                                        drop(stream);\n                                        break;\n                                    }\n                                }\n                            }\n                            else {\n                                for content in &message.content {\n                                    if let MessageContent::ToolRequest(tool_request) = content {\n                                        if let Ok(tool_call) = &tool_request.tool_call {\n                                            tracing::info!(counter.goose.tool_calls = 1,\n                                                tool_name = %tool_call.name,\n                                                \"Tool call started\"\n                                            );\n                                        }\n                                    }\n                                    if let MessageContent::ToolResponse(tool_response) = content {\n                                        let tool_name = self.messages\n                                            .iter()\n                                            .rev()\n                                            .find_map(|msg| {\n                                                msg.content.iter().find_map(|c| {\n                                                    if let MessageContent::ToolRequest(req) = c {\n                                                        if req.id == tool_response.id {\n                                                            if let Ok(tool_call) = &req.tool_call {\n                                                                Some(tool_call.name.clone())\n                                                            } else {\n                                                                None\n                                                            }\n                                                        } else {\n                                                            None\n                                                        }\n                                                    } else {\n                                                        None\n                                                    }\n                                                })\n                                            })\n                                            .unwrap_or_else(|| \"unknown\".to_string().into());\n\n                                        let success = tool_response.tool_result.is_ok();\n                                        let result_status = if success { \"success\" } else { \"error\" };\n                                        tracing::info!(\n                                            counter.goose.tool_completions = 1,\n                                            tool_name = %tool_name,\n                                            result = %result_status,\n                                            \"Tool call completed\"\n                                        );\n                                    }\n                                }\n\n                                self.messages.push(message.clone());\n\n                                if interactive {output::hide_thinking()};\n                                let _ = progress_bars.hide();\n\n                                // Handle different output formats\n                                if is_stream_json_mode {\n                                    emit_stream_event(&StreamEvent::Message { message: message.clone() });\n                                } else if !is_json_mode {\n                                    output::render_message(&message, self.debug);\n                                }\n                            }\n                        }\n                        Some(Ok(AgentEvent::McpNotification((extension_id, message)))) => {\n                            match &message {\n                                ServerNotification::LoggingMessageNotification(notification) => {\n                                    let data = &notification.params.data;\n                                    let (formatted_message, subagent_id, message_notification_type) = match data {\n                                        Value::String(s) => (s.clone(), None, None),\n                                        Value::Object(o) => {\n                                            // Check for subagent notification structure first\n                                            if let Some(Value::String(msg)) = o.get(\"message\") {\n                                                // Extract subagent info for better display\n                                                let subagent_id = o.get(\"subagent_id\")\n                                                    .and_then(|v| v.as_str());\n                                                let notification_type = o.get(\"type\")\n                                                    .and_then(|v| v.as_str());\n\n                                                let formatted = match notification_type {\n                                                    Some(\"subagent_created\") | Some(\"completed\") | Some(\"terminated\") => {\n                                                        format!(\"🤖 {}\", msg)\n                                                    }\n                                                    Some(\"tool_usage\") | Some(\"tool_completed\") | Some(\"tool_error\") => {\n                                                        format!(\"🔧 {}\", msg)\n                                                    }\n                                                    Some(\"message_processing\") | Some(\"turn_progress\") => {\n                                                        format!(\"💭 {}\", msg)\n                                                    }\n                                                    Some(\"response_generated\") => {\n                                                        // Check verbosity setting for subagent response content\n                                                        let config = Config::global();\n                                                        let min_priority = config\n                                                            .get_param::<f32>(\"GOOSE_CLI_MIN_PRIORITY\")\n                                                            .ok()\n                                                            .unwrap_or(0.5);\n\n                                                        if min_priority > 0.1 && !self.debug {\n                                                            // High/Medium verbosity: show truncated response\n                                                            if let Some(response_content) = msg.strip_prefix(\"Responded: \") {\n                                                                format!(\"🤖 Responded: {}\", safe_truncate(response_content, 100))\n                                                            } else {\n                                                                format!(\"🤖 {}\", msg)\n                                                            }\n                                                        } else {\n                                                            // All verbosity or debug: show full response\n                                                            format!(\"🤖 {}\", msg)\n                                                        }\n                                                    }\n                                                    _ => {\n                                                        msg.to_string()\n                                                    }\n                                                };\n                                                (formatted, subagent_id.map(str::to_string), notification_type.map(str::to_string))\n                                            } else if let Some(Value::String(output)) = o.get(\"output\") {\n                                                // Extract type if present (e.g., \"shell_output\")\n                                                let notification_type = o.get(\"type\")\n                                                    .and_then(|v| v.as_str())\n                                                    .map(str::to_string);\n\n                                                (output.to_owned(), None, notification_type)\n                                            } else if let Some(result) = format_task_execution_notification(data) {\n                                                result\n                                            } else {\n                                                (data.to_string(), None, None)\n                                            }\n                                        },\n                                        v => {\n                                            (v.to_string(), None, None)\n                                        },\n                                    };\n\n                                    if is_stream_json_mode {\n                                        emit_stream_event(&StreamEvent::Notification {\n                                            extension_id: extension_id.clone(),\n                                            data: NotificationData::Log { message: formatted_message.clone() },\n                                        });\n                                    }\n                                    // Handle subagent notifications - show immediately\n                                    else if let Some(_id) = subagent_id {\n                                        if interactive {\n                                            let _ = progress_bars.hide();\n                                            if !is_json_mode {\n                                                println!(\"{}\", console::style(&formatted_message).green().dim());\n                                            }\n                                        } else if !is_json_mode {\n                                            progress_bars.log(&formatted_message);\n                                        }\n                                    } else if let Some(ref notification_type) = message_notification_type {\n                                        if notification_type == TASK_EXECUTION_NOTIFICATION_TYPE {\n                                            if interactive {\n                                                let _ = progress_bars.hide();\n                                                if !is_json_mode {\n                                                    print!(\"{}\", formatted_message);\n                                                    std::io::stdout().flush().unwrap();\n                                                }\n                                            } else if !is_json_mode {\n                                                print!(\"{}\", formatted_message);\n                                                std::io::stdout().flush().unwrap();\n                                            }\n                                        } else if notification_type == \"shell_output\" {\n                                            if interactive {\n                                                let _ = progress_bars.hide();\n                                            }\n                                            if !is_json_mode {\n                                                println!(\"{}\", formatted_message);\n                                            }\n                                        }\n                                    }\n                                    else if output::is_showing_thinking() {\n                                        output::set_thinking_message(&formatted_message);\n                                    } else {\n                                        progress_bars.log(&formatted_message);\n                                    }\n                                },\n                                ServerNotification::ProgressNotification(notification) => {\n                                    let progress = notification.params.progress;\n                                    let text = notification.params.message.as_deref();\n                                    let total = notification.params.total;\n                                    let token = &notification.params.progress_token;\n\n                                    if is_stream_json_mode {\n                                        emit_stream_event(&StreamEvent::Notification {\n                                            extension_id: extension_id.clone(),\n                                            data: NotificationData::Progress {\n                                                progress,\n                                                total,\n                                                message: text.map(String::from),\n                                            },\n                                        });\n                                    } else {\n                                        progress_bars.update(\n                                            &token.0.to_string(),\n                                            progress,\n                                            total,\n                                            text,\n                                        );\n                                    }\n                                },\n                                _ => (),\n                            }\n                        }\n                        Some(Ok(AgentEvent::HistoryReplaced(updated_conversation))) => {\n                            self.messages = updated_conversation;\n                        }\n                        Some(Ok(AgentEvent::ModelChange { model, mode })) => {\n                            if is_stream_json_mode {\n                                emit_stream_event(&StreamEvent::ModelChange {\n                                    model: model.clone(),\n                                    mode: mode.clone(),\n                                });\n                            } else if self.debug {\n                                eprintln!(\"Model changed to {} in {} mode\", model, mode);\n                            }\n                        }\n\n                        Some(Err(e)) => {\n                            let error_msg = e.to_string();\n\n                            if is_stream_json_mode {\n                                emit_stream_event(&StreamEvent::Error { error: error_msg.clone() });\n                            }\n\n                            if e.downcast_ref::<goose::providers::errors::ProviderError>()\n                                .map(|provider_error| matches!(provider_error, goose::providers::errors::ProviderError::ContextLengthExceeded(_)))\n                                .unwrap_or(false) {\n\n                                if !is_stream_json_mode {\n                                    output::render_text(\n                                        \"Compaction requested. Should have happened in the agent!\",\n                                        Some(Color::Yellow),\n                                        true\n                                    );\n                                }\n                                warn!(\"Compaction requested. Should have happened in the agent!\");\n                            }\n                            if !is_stream_json_mode {\n                                eprintln!(\"Error: {}\", error_msg);\n                            }\n                            cancel_token_clone.cancel();\n                            drop(stream);\n                            if let Err(e) = self.handle_interrupted_messages(false).await {\n                                eprintln!(\"Error handling interruption: {}\", e);\n                            } else if !is_stream_json_mode {\n                                output::render_error(\n                                    \"The error above was an exception we were not able to handle.\\n\\\n                                    These errors are often related to connection or authentication\\n\\\n                                    We've removed the conversation up to the most recent user message\\n\\\n                                    - depending on the error you may be able to continue\",\n                                );\n                            }\n                            break;\n                        }\n                        None => break,\n                    }\n                }\n                _ = cancel_token_clone.cancelled() => {\n                    drop(stream);\n                    if let Err(e) = self.handle_interrupted_messages(true).await {\n                        eprintln!(\"Error handling interruption: {}\", e);\n                    }\n                    break;\n                }\n            }\n        }\n\n        // Output based on format\n        if is_json_mode {\n            let metadata = match SessionManager::get_session(&self.session_id, false).await {\n                Ok(session) => JsonMetadata {\n                    total_tokens: session.total_tokens,\n                    input_tokens: session.input_tokens,\n                    output_tokens: session.output_tokens,\n                    accumulated_total_tokens: session.accumulated_total_tokens,\n                    accumulated_input_tokens: session.accumulated_input_tokens,\n                    accumulated_output_tokens: session.accumulated_output_tokens,\n                    status: \"completed\".to_string(),\n                },\n                Err(_) => JsonMetadata {\n                    total_tokens: None,\n                    input_tokens: None,\n                    output_tokens: None,\n                    accumulated_total_tokens: None,\n                    accumulated_input_tokens: None,\n                    accumulated_output_tokens: None,\n                    status: \"completed\".to_string(),\n                },\n            };\n\n            let json_output = JsonOutput {\n                messages: self.messages.messages().to_vec(),\n                metadata,\n            };\n\n            println!(\"{}\", serde_json::to_string_pretty(&json_output)?);\n        } else if is_stream_json_mode {\n            let total_tokens = SessionManager::get_session(&self.session_id, false)\n                .await\n                .ok()\n                .and_then(|s| s.total_tokens);\n            emit_stream_event(&StreamEvent::Complete { total_tokens });\n        } else {\n            println!();\n        }\n\n        Ok(())\n    }\n\n    async fn handle_interrupted_messages(&mut self, interrupt: bool) -> Result<()> {\n        // First, get any tool requests from the last message if it exists\n        let tool_requests = self\n            .messages\n            .last()\n            .filter(|msg| msg.role == rmcp::model::Role::Assistant)\n            .map_or(Vec::new(), |msg| {\n                msg.content\n                    .iter()\n                    .filter_map(|content| {\n                        if let MessageContent::ToolRequest(req) = content {\n                            Some((req.id.clone(), req.tool_call.clone()))\n                        } else {\n                            None\n                        }\n                    })\n                    .collect()\n            });\n\n        if !tool_requests.is_empty() {\n            // Interrupted during a tool request\n            // Create tool responses for all interrupted tool requests\n            let mut response_message = Message::user();\n            let last_tool_name = tool_requests\n                .last()\n                .and_then(|(_, tool_call)| {\n                    tool_call\n                        .as_ref()\n                        .ok()\n                        .map(|tool| tool.name.to_string().clone())\n                })\n                .unwrap_or_else(|| \"tool\".to_string());\n\n            let notification = if interrupt {\n                \"Interrupted by the user to make a correction\".to_string()\n            } else {\n                \"An uncaught error happened during tool use\".to_string()\n            };\n            for (req_id, _) in &tool_requests {\n                response_message.content.push(MessageContent::tool_response(\n                    req_id.clone(),\n                    Err(ErrorData {\n                        code: ErrorCode::INTERNAL_ERROR,\n                        message: std::borrow::Cow::from(notification.clone()),\n                        data: None,\n                    }),\n                ));\n            }\n            // TODO(Douwe): update also db\n            self.push_message(response_message);\n            let prompt = format!(\n                \"The existing call to {} was interrupted. How would you like to proceed?\",\n                last_tool_name\n            );\n            self.push_message(Message::assistant().with_text(&prompt));\n            output::render_message(&Message::assistant().with_text(&prompt), self.debug);\n        } else {\n            // An interruption occurred outside of a tool request-response.\n            if let Some(last_msg) = self.messages.last() {\n                if last_msg.role == rmcp::model::Role::User {\n                    match last_msg.content.first() {\n                        Some(MessageContent::ToolResponse(_)) => {\n                            // Interruption occurred after a tool had completed but not assistant reply\n                            let prompt = \"The tool calling loop was interrupted. How would you like to proceed?\";\n                            self.push_message(Message::assistant().with_text(prompt));\n                            output::render_message(\n                                &Message::assistant().with_text(prompt),\n                                self.debug,\n                            );\n                        }\n                        Some(_) => {\n                            // A real users message\n                            self.messages.pop();\n                            let prompt = \"Interrupted before the model replied and removed the last message.\";\n                            output::render_message(\n                                &Message::assistant().with_text(prompt),\n                                self.debug,\n                            );\n                        }\n                        None => panic!(\"No content in last message\"),\n                    }\n                }\n            }\n        }\n        Ok(())\n    }\n\n    /// Update the completion cache with fresh data\n    /// This should be called before the interactive session starts\n    pub async fn update_completion_cache(&mut self) -> Result<()> {\n        // Get fresh data\n        let prompts = self.agent.list_extension_prompts().await;\n\n        // Update the cache with write lock\n        let mut cache = self.completion_cache.write().unwrap();\n        cache.prompts.clear();\n        cache.prompt_info.clear();\n\n        for (extension, prompt_list) in prompts {\n            let names: Vec<String> = prompt_list.iter().map(|p| p.name.clone()).collect();\n            cache.prompts.insert(extension.clone(), names);\n\n            for prompt in prompt_list {\n                cache.prompt_info.insert(\n                    prompt.name.clone(),\n                    output::PromptInfo {\n                        name: prompt.name.clone(),\n                        description: prompt.description.clone(),\n                        arguments: prompt.arguments.clone(),\n                        extension: Some(extension.clone()),\n                    },\n                );\n            }\n        }\n\n        cache.last_updated = Instant::now();\n        Ok(())\n    }\n\n    /// Invalidate the completion cache\n    /// This should be called when extensions are added or removed\n    async fn invalidate_completion_cache(&self) {\n        let mut cache = self.completion_cache.write().unwrap();\n        cache.prompts.clear();\n        cache.prompt_info.clear();\n        cache.last_updated = Instant::now();\n    }\n\n    pub fn message_history(&self) -> Conversation {\n        self.messages.clone()\n    }\n\n    /// Render all past messages from the session history\n    pub fn render_message_history(&self) {\n        if self.messages.is_empty() {\n            return;\n        }\n\n        // Print session restored message\n        println!(\n            \"\\n{} {} messages loaded into context.\",\n            console::style(\"Session restored:\").green().bold(),\n            console::style(self.messages.len()).green()\n        );\n\n        // Render each message\n        for message in self.messages.iter() {\n            output::render_message(message, self.debug);\n        }\n\n        // Add a visual separator after restored messages\n        println!(\n            \"\\n{}\\n\",\n            console::style(\"──────── New Messages ────────\").dim()\n        );\n    }\n\n    pub async fn get_session(&self) -> Result<goose::session::Session> {\n        SessionManager::get_session(&self.session_id, false).await\n    }\n\n    // Get the session's total token usage\n    pub async fn get_total_token_usage(&self) -> Result<Option<i32>> {\n        let metadata = self.get_session().await?;\n        Ok(metadata.total_tokens)\n    }\n\n    /// Display enhanced context usage with session totals\n    pub async fn display_context_usage(&self) -> Result<()> {\n        let provider = self.agent.provider().await?;\n        let model_config = provider.get_model_config();\n        let context_limit = model_config.context_limit();\n\n        let config = Config::global();\n        let show_cost = config\n            .get_param::<bool>(\"GOOSE_CLI_SHOW_COST\")\n            .unwrap_or(false);\n\n        let provider_name = config\n            .get_goose_provider()\n            .unwrap_or_else(|_| \"unknown\".to_string());\n\n        match self.get_session().await {\n            Ok(metadata) => {\n                let total_tokens = metadata.total_tokens.unwrap_or(0) as usize;\n\n                output::display_context_usage(total_tokens, context_limit);\n\n                if show_cost {\n                    let input_tokens = metadata.input_tokens.unwrap_or(0) as usize;\n                    let output_tokens = metadata.output_tokens.unwrap_or(0) as usize;\n                    output::display_cost_usage(\n                        &provider_name,\n                        &model_config.model_name,\n                        input_tokens,\n                        output_tokens,\n                    );\n                }\n            }\n            Err(_) => {\n                output::display_context_usage(0, context_limit);\n            }\n        }\n\n        Ok(())\n    }\n\n    /// Handle prompt command execution\n    async fn handle_prompt_command(&mut self, opts: input::PromptCommandOptions) -> Result<()> {\n        // name is required\n        if opts.name.is_empty() {\n            output::render_error(\"Prompt name argument is required\");\n            return Ok(());\n        }\n\n        if opts.info {\n            match self.get_prompt_info(&opts.name).await? {\n                Some(info) => output::render_prompt_info(&info),\n                None => output::render_error(&format!(\"Prompt '{}' not found\", opts.name)),\n            }\n        } else {\n            // Convert the arguments HashMap to a Value\n            let arguments = serde_json::to_value(opts.arguments)\n                .map_err(|e| anyhow::anyhow!(\"Failed to serialize arguments: {}\", e))?;\n\n            match self.get_prompt(&opts.name, arguments).await {\n                Ok(messages) => {\n                    let start_len = self.messages.len();\n                    let mut valid = true;\n                    for (i, prompt_message) in messages.into_iter().enumerate() {\n                        let msg = Message::from(prompt_message);\n                        // ensure we get a User - Assistant - User type pattern\n                        let expected_role = if i % 2 == 0 {\n                            rmcp::model::Role::User\n                        } else {\n                            rmcp::model::Role::Assistant\n                        };\n\n                        if msg.role != expected_role {\n                            output::render_error(&format!(\n                                \"Expected {:?} message at position {}, but found {:?}\",\n                                expected_role, i, msg.role\n                            ));\n                            valid = false;\n                            // get rid of everything we added to messages\n                            self.messages.truncate(start_len);\n                            break;\n                        }\n\n                        if msg.role == rmcp::model::Role::User {\n                            output::render_message(&msg, self.debug);\n                        }\n                        self.push_message(msg);\n                    }\n\n                    if valid {\n                        output::show_thinking();\n                        self.process_agent_response(true, CancellationToken::default())\n                            .await?;\n                        output::hide_thinking();\n                    }\n                }\n                Err(e) => output::render_error(&e.to_string()),\n            }\n        }\n\n        Ok(())\n    }\n\n    /// Save a recipe to a file\n    ///\n    /// # Arguments\n    /// * `recipe` - The recipe to save\n    /// * `filepath_str` - The path to save the recipe to\n    ///\n    /// # Returns\n    /// * `Result<PathBuf, String>` - The path the recipe was saved to or an error message\n    fn save_recipe(\n        &self,\n        recipe: &goose::recipe::Recipe,\n        filepath_str: &str,\n    ) -> anyhow::Result<PathBuf> {\n        let path_buf = PathBuf::from(filepath_str);\n        let mut path = path_buf.clone();\n\n        // Update the final path if it's relative\n        if path_buf.is_relative() {\n            // If the path is relative, resolve it relative to the current working directory\n            let cwd = std::env::current_dir().context(\"Failed to get current directory\")?;\n            path = cwd.join(&path_buf);\n        }\n\n        // Check if parent directory exists\n        if let Some(parent) = path.parent() {\n            if !parent.exists() {\n                return Err(anyhow::anyhow!(\n                    \"Directory '{}' does not exist\",\n                    parent.display()\n                ));\n            }\n        }\n\n        // Try creating the file\n        let file = std::fs::File::create(path.as_path())\n            .context(format!(\"Failed to create file '{}'\", path.display()))?;\n\n        // Write YAML\n        serde_yaml::to_writer(file, recipe).context(\"Failed to save recipe\")?;\n\n        Ok(path)\n    }\n\n    fn push_message(&mut self, message: Message) {\n        self.messages.push(message);\n    }\n}\n\nasync fn get_reasoner() -> Result<Arc<dyn Provider>, anyhow::Error> {\n    use goose::model::ModelConfig;\n    use goose::providers::create;\n\n    let config = Config::global();\n\n    // Try planner-specific provider first, fallback to default provider\n    let provider = if let Ok(provider) = config.get_param::<String>(\"GOOSE_PLANNER_PROVIDER\") {\n        provider\n    } else {\n        println!(\"WARNING: GOOSE_PLANNER_PROVIDER not found. Using default provider...\");\n        config\n            .get_goose_provider()\n            .expect(\"No provider configured. Run 'goose configure' first\")\n    };\n\n    // Try planner-specific model first, fallback to default model\n    let model = if let Ok(model) = config.get_param::<String>(\"GOOSE_PLANNER_MODEL\") {\n        model\n    } else {\n        println!(\"WARNING: GOOSE_PLANNER_MODEL not found. Using default model...\");\n        config\n            .get_goose_model()\n            .expect(\"No model configured. Run 'goose configure' first\")\n    };\n\n    let model_config =\n        ModelConfig::new_with_context_env(model, Some(\"GOOSE_PLANNER_CONTEXT_LIMIT\"))?;\n    let reasoner = create(&provider, model_config).await?;\n\n    Ok(reasoner)\n}\n\n/// Format elapsed time duration\n/// Shows seconds if less than 60, otherwise shows minutes:seconds\nfn format_elapsed_time(duration: std::time::Duration) -> String {\n    let total_secs = duration.as_secs();\n    if total_secs < 60 {\n        format!(\"{:.2}s\", duration.as_secs_f64())\n    } else {\n        let minutes = total_secs / 60;\n        let seconds = total_secs % 60;\n        format!(\"{}m {:02}s\", minutes, seconds)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::time::Duration;\n\n    #[test]\n    fn test_format_elapsed_time_under_60_seconds() {\n        // Test sub-second duration\n        let duration = Duration::from_millis(500);\n        assert_eq!(format_elapsed_time(duration), \"0.50s\");\n\n        // Test exactly 1 second\n        let duration = Duration::from_secs(1);\n        assert_eq!(format_elapsed_time(duration), \"1.00s\");\n\n        // Test 45.75 seconds\n        let duration = Duration::from_millis(45750);\n        assert_eq!(format_elapsed_time(duration), \"45.75s\");\n\n        // Test 59.99 seconds\n        let duration = Duration::from_millis(59990);\n        assert_eq!(format_elapsed_time(duration), \"59.99s\");\n    }\n\n    #[test]\n    fn test_format_elapsed_time_minutes() {\n        // Test exactly 60 seconds (1 minute)\n        let duration = Duration::from_secs(60);\n        assert_eq!(format_elapsed_time(duration), \"1m 00s\");\n\n        // Test 61 seconds (1 minute 1 second)\n        let duration = Duration::from_secs(61);\n        assert_eq!(format_elapsed_time(duration), \"1m 01s\");\n\n        // Test 90 seconds (1 minute 30 seconds)\n        let duration = Duration::from_secs(90);\n        assert_eq!(format_elapsed_time(duration), \"1m 30s\");\n\n        // Test 119 seconds (1 minute 59 seconds)\n        let duration = Duration::from_secs(119);\n        assert_eq!(format_elapsed_time(duration), \"1m 59s\");\n\n        // Test 120 seconds (2 minutes)\n        let duration = Duration::from_secs(120);\n        assert_eq!(format_elapsed_time(duration), \"2m 00s\");\n\n        // Test 605 seconds (10 minutes 5 seconds)\n        let duration = Duration::from_secs(605);\n        assert_eq!(format_elapsed_time(duration), \"10m 05s\");\n\n        // Test 3661 seconds (61 minutes 1 second)\n        let duration = Duration::from_secs(3661);\n        assert_eq!(format_elapsed_time(duration), \"61m 01s\");\n    }\n\n    #[test]\n    fn test_format_elapsed_time_edge_cases() {\n        // Test zero duration\n        let duration = Duration::from_secs(0);\n        assert_eq!(format_elapsed_time(duration), \"0.00s\");\n\n        // Test very small duration (1 millisecond)\n        let duration = Duration::from_millis(1);\n        assert_eq!(format_elapsed_time(duration), \"0.00s\");\n\n        // Test fractional seconds are truncated for minute display\n        // 60.5 seconds should still show as 1m 00s (not 1m 00.5s)\n        let duration = Duration::from_millis(60500);\n        assert_eq!(format_elapsed_time(duration), \"1m 00s\");\n    }\n}\n"
                  },
                  "annotations": {
                    "audience": [
                      "assistant"
                    ]
                  }
                },
                {
                  "type": "text",
                  "text": "### /Users/baxen/Development/goose/crates/goose-cli/src/session/mod.rs\n```rust\n1: mod builder;\n2: mod completion;\n3: mod elicitation;\n4: mod export;\n5: mod input;\n6: mod output;\n7: mod prompt;\n8: mod task_execution_display;\n9: mod thinking;\n10: \n11: use crate::session::task_execution_display::{\n12:     format_task_execution_notification, TASK_EXECUTION_NOTIFICATION_TYPE,\n13: };\n14: use goose::conversation::Conversation;\n15: use std::io::Write;\n16: use std::str::FromStr;\n17: use tokio::signal::ctrl_c;\n18: use tokio_util::task::AbortOnDropHandle;\n19: \n20: pub use self::export::message_to_markdown;\n21: pub use builder::{build_session, SessionBuilderConfig, SessionSettings};\n22: use console::Color;\n23: use goose::agents::AgentEvent;\n24: use goose::permission::permission_confirmation::PrincipalType;\n25: use goose::permission::Permission;\n26: use goose::permission::PermissionConfirmation;\n27: use goose::providers::base::Provider;\n28: use goose::utils::safe_truncate;\n29: \n30: use anyhow::{Context, Result};\n31: use completion::GooseCompleter;\n32: use goose::agents::extension::{Envs, ExtensionConfig, PLATFORM_EXTENSIONS};\n33: use goose::agents::types::RetryConfig;\n34: use goose::agents::{Agent, SessionConfig, COMPACT_TRIGGERS};\n35: use goose::config::{Config, GooseMode};\n36: use goose::session::SessionManager;\n37: use input::InputResult;\n38: use rmcp::model::PromptMessage;\n39: use rmcp::model::ServerNotification;\n40: use rmcp::model::{ErrorCode, ErrorData};\n41: \n42: use goose::config::paths::Paths;\n43: use goose::conversation::message::{ActionRequiredData, Message, MessageContent};\n44: use rand::{distributions::Alphanumeric, Rng};\n45: use rustyline::EditMode;\n46: use serde::{Deserialize, Serialize};\n47: use serde_json::Value;\n48: use std::collections::HashMap;\n49: use std::path::PathBuf;\n50: use std::sync::Arc;\n51: use std::time::Instant;\n52: use tokio;\n53: use tokio_util::sync::CancellationToken;\n54: use tracing::warn;\n55: \n56: #[derive(Serialize, Deserialize, Debug)]\n57: struct JsonOutput {\n58:     messages: Vec<Message>,\n59:     metadata: JsonMetadata,\n60: }\n61: \n62: #[derive(Serialize, Deserialize, Debug)]\n63: struct JsonMetadata {\n64:     total_tokens: Option<i32>,\n65:     input_tokens: Option<i32>,\n66:     output_tokens: Option<i32>,\n67:     accumulated_total_tokens: Option<i32>,\n68:     accumulated_input_tokens: Option<i32>,\n69:     accumulated_output_tokens: Option<i32>,\n70:     status: String,\n71: }\n72: \n73: #[derive(Serialize, Debug)]\n74: #[serde(tag = \"type\", rename_all = \"snake_case\")]\n75: enum StreamEvent {\n76:     Message {\n77:         message: Message,\n78:     },\n79:     Notification {\n80:         extension_id: String,\n81:         #[serde(flatten)]\n82:         data: NotificationData,\n83:     },\n84:     ModelChange {\n85:         model: String,\n86:         mode: String,\n87:     },\n88:     Error {\n89:         error: String,\n90:     },\n91:     Complete {\n92:         total_tokens: Option<i32>,\n93:     },\n94: }\n95: \n96: #[derive(Serialize, Debug)]\n97: #[serde(rename_all = \"snake_case\")]\n98: enum NotificationData {\n99:     Log {\n100:         message: String,\n101:     },\n102:     Progress {\n103:         progress: f64,\n104:         total: Option<f64>,\n105:         message: Option<String>,\n106:     },\n107: }\n108: \n109: pub enum RunMode {\n110:     Normal,\n111:     Plan,\n112: }\n113: \n114: pub struct CliSession {\n115:     agent: Agent,\n116:     messages: Conversation,\n117:     session_id: String,\n118:     completion_cache: Arc<std::sync::RwLock<CompletionCache>>,\n119:     debug: bool,\n120:     run_mode: RunMode,\n121:     scheduled_job_id: Option<String>, // ID of the scheduled job that triggered this session\n122:     max_turns: Option<u32>,\n123:     edit_mode: Option<EditMode>,\n124:     retry_config: Option<RetryConfig>,\n125:     output_format: String,\n126: }\n127: \n128: // Cache structure for completion data\n129: struct CompletionCache {\n130:     prompts: HashMap<String, Vec<String>>,\n131:     prompt_info: HashMap<String, output::PromptInfo>,\n132:     last_updated: Instant,\n133: }\n134: \n135: impl CompletionCache {\n136:     fn new() -> Self {\n137:         Self {\n138:             prompts: HashMap::new(),\n139:             prompt_info: HashMap::new(),\n140:             last_updated: Instant::now(),\n141:         }\n142:     }\n143: }\n144: \n145: pub enum PlannerResponseType {\n146:     Plan,\n147:     ClarifyingQuestions,\n148: }\n149: \n150: /// Decide if the planner's reponse is a plan or a clarifying question\n151: ///\n152: /// This function is called after the planner has generated a response\n153: /// to the user's message. The response is either a plan or a clarifying\n154: /// question.\n155: pub async fn classify_planner_response(\n156:     message_text: String,\n157:     provider: Arc<dyn Provider>,\n158: ) -> Result<PlannerResponseType> {\n159:     let prompt = format!(\"The text below is the output from an AI model which can either provide a plan or list of clarifying questions. Based on the text below, decide if the output is a \\\"plan\\\" or \\\"clarifying questions\\\".\\n---\\n{message_text}\");\n160: \n161:     // Generate the description\n162:     let message = Message::user().with_text(&prompt);\n163:     let (result, _usage) = provider\n164:         .complete(\n165:             \"Reply only with the classification label: \\\"plan\\\" or \\\"clarifying questions\\\"\",\n166:             &[message],\n167:             &[],\n168:         )\n169:         .await?;\n170: \n171:     let predicted = result.as_concat_text();\n172:     if predicted.to_lowercase().contains(\"plan\") {\n173:         Ok(PlannerResponseType::Plan)\n174:     } else {\n175:         Ok(PlannerResponseType::ClarifyingQuestions)\n176:     }\n177: }\n178: \n179: fn generate_extension_name(extension_command: &str) -> String {\n180:     let cmd_name: String = extension_command\n181:         .split([' ', '/'])\n182:         .next_back()\n183:         .unwrap_or(\"\")\n184:         .chars()\n185:         .filter(|c| c.is_alphanumeric())\n186:         .collect();\n187: \n188:     let prefix: String = cmd_name.chars().take(16).collect();\n189: \n190:     let random_suffix: String = rand::thread_rng()\n191:         .sample_iter(&Alphanumeric)\n192:         .take(8)\n193:         .map(char::from)\n194:         .collect();\n195: \n196:     let name = format!(\"{}_{}\", prefix, random_suffix);\n197: \n198:     if name.chars().next().is_none_or(|c| !c.is_alphabetic()) {\n199:         format!(\"g{}\", name)\n200:     } else {\n201:         name\n202:     }\n203: }\n204: \n205: impl CliSession {\n206:     #[allow(clippy::too_many_arguments)]\n207:     pub async fn new(\n208:         agent: Agent,\n209:         session_id: String,\n210:         debug: bool,\n211:         scheduled_job_id: Option<String>,\n212:         max_turns: Option<u32>,\n213:         edit_mode: Option<EditMode>,\n214:         retry_config: Option<RetryConfig>,\n215:         output_format: String,\n216:     ) -> Self {\n217:         let messages = SessionManager::get_session(&session_id, true)\n218:             .await\n219:             .map(|session| session.conversation.unwrap_or_default())\n220:             .unwrap();\n221: \n222:         CliSession {\n223:             agent,\n224:             messages,\n225:             session_id,\n226:             completion_cache: Arc::new(std::sync::RwLock::new(CompletionCache::new())),\n227:             debug,\n228:             run_mode: RunMode::Normal,\n229:             scheduled_job_id,\n230:             max_turns,\n231:             edit_mode,\n232:             retry_config,\n233:             output_format,\n234:         }\n235:     }\n236: \n237:     pub fn session_id(&self) -> &String {\n238:         &self.session_id\n239:     }\n240: \n241:     /// Add a stdio extension to the session\n242:     ///\n243:     /// # Arguments\n244:     /// * `extension_command` - Full command string including environment variables\n245:     ///   Format: \"ENV1=val1 ENV2=val2 command args...\"\n246:     pub async fn add_extension(&mut self, extension_command: String) -> Result<()> {\n247:         let mut parts: Vec<&str> = extension_command.split_whitespace().collect();\n248:         let mut envs = HashMap::new();\n249: \n250:         while let Some(part) = parts.first() {\n251:             if !part.contains('=') {\n252:                 break;\n253:             }\n254:             let env_part = parts.remove(0);\n255:             let (key, value) = env_part.split_once('=').unwrap();\n256:             envs.insert(key.to_string(), value.to_string());\n257:         }\n258: \n259:         if parts.is_empty() {\n260:             return Err(anyhow::anyhow!(\"No command provided in extension string\"));\n261:         }\n262: \n263:         let cmd = parts.remove(0).to_string();\n264:         let name = generate_extension_name(&extension_command);\n265: \n266:         let config = ExtensionConfig::Stdio {\n267:             name,\n268:             cmd,\n269:             args: parts.iter().map(|s| s.to_string()).collect(),\n270:             envs: Envs::new(envs),\n271:             env_keys: Vec::new(),\n272:             description: goose::config::DEFAULT_EXTENSION_DESCRIPTION.to_string(),\n273:             // TODO: should set timeout\n274:             timeout: Some(goose::config::DEFAULT_EXTENSION_TIMEOUT),\n275:             bundled: None,\n276:             available_tools: Vec::new(),\n277:         };\n278: \n279:         self.agent\n280:             .add_extension(config)\n281:             .await\n282:             .map_err(|e| anyhow::anyhow!(\"Failed to start extension: {}\", e))?;\n283: \n284:         // Invalidate the completion cache when a new extension is added\n285:         self.invalidate_completion_cache().await;\n286: \n287:         Ok(())\n288:     }\n289: \n290:     /// Add a remote extension to the session\n291:     ///\n292:     /// # Arguments\n293:     /// * `extension_url` - URL of the server\n294:     pub async fn add_remote_extension(&mut self, extension_url: String) -> Result<()> {\n295:         let name = generate_extension_name(&extension_url);\n296: \n297:         let config = ExtensionConfig::Sse {\n298:             name,\n299:             uri: extension_url,\n300:             envs: Envs::new(HashMap::new()),\n301:             env_keys: Vec::new(),\n302:             description: goose::config::DEFAULT_EXTENSION_DESCRIPTION.to_string(),\n303:             // TODO: should set timeout\n304:             timeout: Some(goose::config::DEFAULT_EXTENSION_TIMEOUT),\n305:             bundled: None,\n306:             available_tools: Vec::new(),\n307:         };\n308: \n309:         self.agent\n310:             .add_extension(config)\n311:             .await\n312:             .map_err(|e| anyhow::anyhow!(\"Failed to start extension: {}\", e))?;\n313: \n314:         // Invalidate the completion cache when a new extension is added\n315:         self.invalidate_completion_cache().await;\n316: \n317:         Ok(())\n318:     }\n319: \n320:     /// Add a streamable HTTP extension to the session\n321:     ///\n322:     /// # Arguments\n323:     /// * `extension_url` - URL of the server\n324:     pub async fn add_streamable_http_extension(&mut self, extension_url: String) -> Result<()> {\n325:         let name = generate_extension_name(&extension_url);\n326: \n327:         let config = ExtensionConfig::StreamableHttp {\n328:             name,\n329:             uri: extension_url,\n330:             envs: Envs::new(HashMap::new()),\n331:             env_keys: Vec::new(),\n332:             headers: HashMap::new(),\n333:             description: goose::config::DEFAULT_EXTENSION_DESCRIPTION.to_string(),\n334:             // TODO: should set timeout\n335:             timeout: Some(goose::config::DEFAULT_EXTENSION_TIMEOUT),\n336:             bundled: None,\n337:             available_tools: Vec::new(),\n338:         };\n339: \n340:         self.agent\n341:             .add_extension(config)\n342:             .await\n343:             .map_err(|e| anyhow::anyhow!(\"Failed to start extension: {}\", e))?;\n344: \n345:         // Invalidate the completion cache when a new extension is added\n346:         self.invalidate_completion_cache().await;\n347: \n348:         Ok(())\n349:     }\n350: \n351:     /// Add a builtin extension to the session\n352:     ///\n353:     /// # Arguments\n354:     /// * `builtin_name` - Name of the builtin extension(s), comma separated\n355:     pub async fn add_builtin(&mut self, builtin_name: String) -> Result<()> {\n356:         for name in builtin_name.split(',') {\n357:             let extension_name = name.trim();\n358: \n359:             let config = if PLATFORM_EXTENSIONS.contains_key(extension_name) {\n360:                 ExtensionConfig::Platform {\n361:                     name: extension_name.to_string(),\n362:                     bundled: None,\n363:                     description: name.to_string(),\n364:                     available_tools: Vec::new(),\n365:                 }\n366:             } else {\n367:                 ExtensionConfig::Builtin {\n368:                     name: extension_name.to_string(),\n369:                     display_name: None,\n370:                     timeout: None,\n371:                     bundled: None,\n372:                     description: name.to_string(),\n373:                     available_tools: Vec::new(),\n374:                 }\n375:             };\n376:             self.agent\n377:                 .add_extension(config)\n378:                 .await\n379:                 .map_err(|e| anyhow::anyhow!(\"Failed to start builtin extension: {}\", e))?;\n380:         }\n381: \n382:         // Invalidate the completion cache when a new extension is added\n383:         self.invalidate_completion_cache().await;\n384: \n385:         Ok(())\n386:     }\n387: \n388:     pub async fn list_prompts(\n389:         &mut self,\n390:         extension: Option<String>,\n391:     ) -> Result<HashMap<String, Vec<String>>> {\n392:         let prompts = self.agent.list_extension_prompts().await;\n393: \n394:         // Early validation if filtering by extension\n395:         if let Some(filter) = &extension {\n396:             if !prompts.contains_key(filter) {\n397:                 return Err(anyhow::anyhow!(\"Extension '{}' not found\", filter));\n398:             }\n399:         }\n400: \n401:         // Convert prompts into filtered map of extension names to prompt names\n402:         Ok(prompts\n403:             .into_iter()\n404:             .filter(|(ext, _)| extension.as_ref().is_none_or(|f| f == ext))\n405:             .map(|(extension, prompt_list)| {\n406:                 let names = prompt_list.into_iter().map(|p| p.name).collect();\n407:                 (extension, names)\n408:             })\n409:             .collect())\n410:     }\n411: \n412:     pub async fn get_prompt_info(&mut self, name: &str) -> Result<Option<output::PromptInfo>> {\n413:         let prompts = self.agent.list_extension_prompts().await;\n414: \n415:         // Find which extension has this prompt\n416:         for (extension, prompt_list) in prompts {\n417:             if let Some(prompt) = prompt_list.iter().find(|p| p.name == name) {\n418:                 return Ok(Some(output::PromptInfo {\n419:                     name: prompt.name.clone(),\n420:                     description: prompt.description.clone(),\n421:                     arguments: prompt.arguments.clone(),\n422:                     extension: Some(extension),\n423:                 }));\n424:             }\n425:         }\n426: \n427:         Ok(None)\n428:     }\n429: \n430:     pub async fn get_prompt(&mut self, name: &str, arguments: Value) -> Result<Vec<PromptMessage>> {\n431:         Ok(self.agent.get_prompt(name, arguments).await?.messages)\n432:     }\n433: \n434:     /// Process a single message and get the response\n435:     pub(crate) async fn process_message(\n436:         &mut self,\n437:         message: Message,\n438:         cancel_token: CancellationToken,\n439:     ) -> Result<()> {\n440:         let cancel_token = cancel_token.clone();\n441:         self.push_message(message);\n442:         self.process_agent_response(false, cancel_token).await?;\n443:         Ok(())\n444:     }\n445: \n446:     /// Start an interactive session, optionally with an initial message\n447:     pub async fn interactive(&mut self, prompt: Option<String>) -> Result<()> {\n448:         // Process initial message if provided\n449:         if let Some(prompt) = prompt {\n450:             let msg = Message::user().with_text(&prompt);\n451:             self.process_message(msg, CancellationToken::default())\n452:                 .await?;\n453:         }\n454: \n455:         // Initialize the completion cache\n456:         self.update_completion_cache().await?;\n457: \n458:         // Create a new editor with our custom completer\n459:         let builder =\n460:             rustyline::Config::builder().completion_type(rustyline::CompletionType::Circular);\n461:         let builder = if let Some(edit_mode) = self.edit_mode {\n462:             builder.edit_mode(edit_mode)\n463:         } else {\n464:             // Default to Emacs mode if no edit mode is set\n465:             builder.edit_mode(EditMode::Emacs)\n466:         };\n467:         let config = builder.build();\n468:         let mut editor =\n469:             rustyline::Editor::<GooseCompleter, rustyline::history::DefaultHistory>::with_config(\n470:                 config,\n471:             )?;\n472: \n473:         // Set up the completer with a reference to the completion cache\n474:         let completer = GooseCompleter::new(self.completion_cache.clone());\n475:         editor.set_helper(Some(completer));\n476: \n477:         let history_file = Paths::state_dir().join(\"history.txt\");\n478:         let old_history_file = Paths::config_dir().join(\"history.txt\");\n479: \n480:         if let Some(parent) = history_file.parent() {\n481:             if !parent.exists() {\n482:                 std::fs::create_dir_all(parent)?;\n483:             }\n484:         }\n485: \n486:         let history_files = [&history_file, &old_history_file];\n487:         let load_from = history_files.iter().find(|f| f.exists());\n488: \n489:         if let Some(file) = load_from {\n490:             if let Err(err) = editor.load_history(file) {\n491:                 eprintln!(\"Warning: Failed to load command history: {}\", err);\n492:             }\n493:         }\n494: \n495:         let save_history =\n496:             |editor: &mut rustyline::Editor<GooseCompleter, rustyline::history::DefaultHistory>| {\n497:                 if let Err(err) = editor.save_history(&history_file) {\n498:                     eprintln!(\"Warning: Failed to save command history: {}\", err);\n499:                 } else if old_history_file.exists() {\n500:                     if let Err(err) = std::fs::remove_file(&old_history_file) {\n501:                         eprintln!(\"Warning: Failed to remove old history file: {}\", err);\n502:                     }\n503:                 }\n504:             };\n505: \n506:         output::display_greeting();\n507:         loop {\n508:             // Display context usage before each prompt\n509:             self.display_context_usage().await?;\n510: \n511:             match input::get_input(&mut editor)? {\n512:                 InputResult::Message(content) => {\n513:                     match self.run_mode {\n514:                         RunMode::Normal => {\n515:                             save_history(&mut editor);\n516: \n517:                             self.push_message(Message::user().with_text(&content));\n518: \n519:                             // Track the current directory and last instruction in projects.json\n520:                             if let Err(e) = crate::project_tracker::update_project_tracker(\n521:                                 Some(&content),\n522:                                 Some(&self.session_id),\n523:                             ) {\n524:                                 eprintln!(\"Warning: Failed to update project tracker with instruction: {}\", e);\n525:                             }\n526: \n527:                             let _provider = self.agent.provider().await?;\n528: \n529:                             output::show_thinking();\n530:                             let start_time = Instant::now();\n531:                             self.process_agent_response(true, CancellationToken::default())\n532:                                 .await?;\n533:                             output::hide_thinking();\n534: \n535:                             // Display elapsed time\n536:                             let elapsed = start_time.elapsed();\n537:                             let elapsed_str = format_elapsed_time(elapsed);\n538:                             println!(\n539:                                 \"\\n{}\",\n540:                                 console::style(format!(\"⏱️  Elapsed time: {}\", elapsed_str)).dim()\n541:                             );\n542:                         }\n543:                         RunMode::Plan => {\n544:                             let mut plan_messages = self.messages.clone();\n545:                             plan_messages.push(Message::user().with_text(&content));\n546:                             let reasoner = get_reasoner().await?;\n547:                             self.plan_with_reasoner_model(plan_messages, reasoner)\n548:                                 .await?;\n549:                         }\n550:                     }\n551:                 }\n552:                 input::InputResult::Exit => break,\n553:                 input::InputResult::AddExtension(cmd) => {\n554:                     save_history(&mut editor);\n555: \n556:                     match self.add_extension(cmd.clone()).await {\n557:                         Ok(_) => output::render_extension_success(&cmd),\n558:                         Err(e) => output::render_extension_error(&cmd, &e.to_string()),\n559:                     }\n560:                 }\n561:                 input::InputResult::AddBuiltin(names) => {\n562:                     save_history(&mut editor);\n563: \n564:                     match self.add_builtin(names.clone()).await {\n565:                         Ok(_) => output::render_builtin_success(&names),\n566:                         Err(e) => output::render_builtin_error(&names, &e.to_string()),\n567:                     }\n568:                 }\n569:                 input::InputResult::ToggleTheme => {\n570:                     save_history(&mut editor);\n571: \n572:                     let current = output::get_theme();\n573:                     let new_theme = match current {\n574:                         output::Theme::Ansi => {\n575:                             println!(\"Switching to Light theme\");\n576:                             output::Theme::Light\n577:                         }\n578:                         output::Theme::Light => {\n579:                             println!(\"Switching to Dark theme\");\n580:                             output::Theme::Dark\n581:                         }\n582:                         output::Theme::Dark => {\n583:                             println!(\"Switching to Ansi theme\");\n584:                             output::Theme::Ansi\n585:                         }\n586:                     };\n587:                     output::set_theme(new_theme);\n588:                     continue;\n589:                 }\n590: \n591:                 input::InputResult::SelectTheme(theme_name) => {\n592:                     save_history(&mut editor);\n593: \n594:                     let new_theme = match theme_name.as_str() {\n595:                         \"light\" => {\n596:                             println!(\"Switching to Light theme\");\n597:                             output::Theme::Light\n598:                         }\n599:                         \"dark\" => {\n600:                             println!(\"Switching to Dark theme\");\n601:                             output::Theme::Dark\n602:                         }\n603:                         \"ansi\" => {\n604:                             println!(\"Switching to Ansi theme\");\n605:                             output::Theme::Ansi\n606:                         }\n607:                         _ => output::Theme::Dark,\n608:                     };\n609:                     output::set_theme(new_theme);\n610:                     continue;\n611:                 }\n612:                 input::InputResult::Retry => continue,\n613:                 input::InputResult::ListPrompts(extension) => {\n614:                     save_history(&mut editor);\n615: \n616:                     match self.list_prompts(extension).await {\n617:                         Ok(prompts) => output::render_prompts(&prompts),\n618:                         Err(e) => output::render_error(&e.to_string()),\n619:                     }\n620:                 }\n621:                 input::InputResult::GooseMode(mode) => {\n622:                     save_history(&mut editor);\n623: \n624:                     let config = Config::global();\n625:                     let mode = match GooseMode::from_str(&mode.to_lowercase()) {\n626:                         Ok(mode) => mode,\n627:                         Err(_) => {\n628:                             output::render_error(&format!(\n629:                                 \"Invalid mode '{}'. Mode must be one of: auto, approve, chat, smart_approve\",\n630:                                 mode\n631:                             ));\n632:                             continue;\n633:                         }\n634:                     };\n635:                     config.set_goose_mode(mode)?;\n636:                     output::goose_mode_message(&format!(\"Goose mode set to '{:?}'\", mode));\n637:                     continue;\n638:                 }\n639:                 input::InputResult::Plan(options) => {\n640:                     self.run_mode = RunMode::Plan;\n641:                     output::render_enter_plan_mode();\n642: \n643:                     let message_text = options.message_text;\n644:                     if message_text.is_empty() {\n645:                         continue;\n646:                     }\n647:                     let mut plan_messages = self.messages.clone();\n648:                     plan_messages.push(Message::user().with_text(&message_text));\n649: \n650:                     let reasoner = get_reasoner().await?;\n651:                     self.plan_with_reasoner_model(plan_messages, reasoner)\n652:                         .await?;\n653:                 }\n654:                 input::InputResult::EndPlan => {\n655:                     self.run_mode = RunMode::Normal;\n656:                     output::render_exit_plan_mode();\n657:                     continue;\n658:                 }\n659:                 input::InputResult::Clear => {\n660:                     save_history(&mut editor);\n661: \n662:                     if let Err(e) = SessionManager::replace_conversation(\n663:                         &self.session_id,\n664:                         &Conversation::default(),\n665:                     )\n666:                     .await\n667:                     {\n668:                         output::render_error(&format!(\"Failed to clear session: {}\", e));\n669:                         continue;\n670:                     }\n671: \n672:                     if let Err(e) = SessionManager::update_session(&self.session_id)\n673:                         .total_tokens(Some(0))\n674:                         .input_tokens(Some(0))\n675:                         .output_tokens(Some(0))\n676:                         .apply()\n677:                         .await\n678:                     {\n679:                         output::render_error(&format!(\"Failed to reset token counts: {}\", e));\n680:                         continue;\n681:                     }\n682: \n683:                     self.messages.clear();\n684: \n685:                     tracing::info!(\"Chat context cleared by user.\");\n686:                     output::render_message(\n687:                         &Message::assistant().with_text(\"Chat context cleared.\\n\"),\n688:                         self.debug,\n689:                     );\n690: \n691:                     continue;\n692:                 }\n693:                 input::InputResult::PromptCommand(opts) => {\n694:                     save_history(&mut editor);\n695:                     self.handle_prompt_command(opts).await?;\n696:                 }\n697:                 InputResult::Recipe(filepath_opt) => {\n698:                     println!(\"{}\", console::style(\"Generating Recipe\").green());\n699: \n700:                     output::show_thinking();\n701:                     let recipe = self.agent.create_recipe(self.messages.clone()).await;\n702:                     output::hide_thinking();\n703: \n704:                     match recipe {\n705:                         Ok(recipe) => {\n706:                             // Use provided filepath or default\n707:                             let filepath_str = filepath_opt.as_deref().unwrap_or(\"recipe.yaml\");\n708:                             match self.save_recipe(&recipe, filepath_str) {\n709:                                 Ok(path) => println!(\n710:                                     \"{}\",\n711:                                     console::style(format!(\"Saved recipe to {}\", path.display()))\n712:                                         .green()\n713:                                 ),\n714:                                 Err(e) => {\n715:                                     println!(\"{}\", console::style(e).red());\n716:                                 }\n717:                             }\n718:                         }\n719:                         Err(e) => {\n720:                             println!(\n721:                                 \"{}: {:?}\",\n722:                                 console::style(\"Failed to generate recipe\").red(),\n723:                                 e\n724:                             );\n725:                         }\n726:                     }\n727: \n728:                     continue;\n729:                 }\n730:                 InputResult::Compact => {\n731:                     save_history(&mut editor);\n732: \n733:                     let prompt = \"Are you sure you want to compact this conversation? This will condense the message history.\";\n734:                     let should_summarize =\n735:                         match cliclack::confirm(prompt).initial_value(true).interact() {\n736:                             Ok(choice) => choice,\n737:                             Err(e) => {\n738:                                 if e.kind() == std::io::ErrorKind::Interrupted {\n739:                                     false\n740:                                 } else {\n741:                                     return Err(e.into());\n742:                                 }\n743:                             }\n744:                         };\n745: \n746:                     if should_summarize {\n747:                         self.push_message(Message::user().with_text(COMPACT_TRIGGERS[0]));\n748:                         output::show_thinking();\n749:                         self.process_agent_response(true, CancellationToken::default())\n750:                             .await?;\n751:                         output::hide_thinking();\n752:                     } else {\n753:                         println!(\"{}\", console::style(\"Compaction cancelled.\").yellow());\n754:                     }\n755:                     continue;\n756:                 }\n757:             }\n758:         }\n759: \n760:         println!(\n761:             \"Closing session. Session ID: {}\",\n762:             console::style(&self.session_id).cyan()\n763:         );\n764: \n765:         Ok(())\n766:     }\n767: \n768:     async fn plan_with_reasoner_model(\n769:         &mut self,\n770:         plan_messages: Conversation,\n771:         reasoner: Arc<dyn Provider>,\n772:     ) -> Result<(), anyhow::Error> {\n773:         let plan_prompt = self.agent.get_plan_prompt().await?;\n774:         output::show_thinking();\n775:         let (plan_response, _usage) = reasoner\n776:             .complete(&plan_prompt, plan_messages.messages(), &[])\n777:             .await?;\n778:         output::render_message(&plan_response, self.debug);\n779:         output::hide_thinking();\n780:         let planner_response_type =\n781:             classify_planner_response(plan_response.as_concat_text(), self.agent.provider().await?)\n782:                 .await?;\n783: \n784:         match planner_response_type {\n785:             PlannerResponseType::Plan => {\n786:                 println!();\n787:                 let should_act = match cliclack::confirm(\n788:                     \"Do you want to clear message history & act on this plan?\",\n789:                 )\n790:                 .initial_value(true)\n791:                 .interact()\n792:                 {\n793:                     Ok(choice) => choice,\n794:                     Err(e) => {\n795:                         if e.kind() == std::io::ErrorKind::Interrupted {\n796:                             false // If interrupted, set should_act to false\n797:                         } else {\n798:                             return Err(e.into());\n799:                         }\n800:                     }\n801:                 };\n802:                 if should_act {\n803:                     output::render_act_on_plan();\n804:                     self.run_mode = RunMode::Normal;\n805:                     // set goose mode: auto if that isn't already the case\n806:                     let config = Config::global();\n807:                     let curr_goose_mode = config.get_goose_mode().unwrap_or(GooseMode::Auto);\n808:                     if curr_goose_mode != GooseMode::Auto {\n809:                         config.set_goose_mode(GooseMode::Auto).unwrap();\n810:                     }\n811: \n812:                     // clear the messages before acting on the plan\n813:                     self.messages.clear();\n814:                     // add the plan response as a user message\n815:                     let plan_message = Message::user().with_text(plan_response.as_concat_text());\n816:                     self.push_message(plan_message);\n817:                     // act on the plan\n818:                     output::show_thinking();\n819:                     self.process_agent_response(true, CancellationToken::default())\n820:                         .await?;\n821:                     output::hide_thinking();\n822: \n823:                     // Reset run & goose mode\n824:                     if curr_goose_mode != GooseMode::Auto {\n825:                         config.set_goose_mode(curr_goose_mode)?;\n826:                     }\n827:                 } else {\n828:                     // add the plan response (assistant message) & carry the conversation forward\n829:                     // in the next round, the user might wanna slightly modify the plan\n830:                     self.push_message(plan_response);\n831:                 }\n832:             }\n833:             PlannerResponseType::ClarifyingQuestions => {\n834:                 // add the plan response (assistant message) & carry the conversation forward\n835:                 // in the next round, the user will answer the clarifying questions\n836:                 self.push_message(plan_response);\n837:             }\n838:         }\n839: \n840:         Ok(())\n841:     }\n842: \n843:     /// Process a single message and exit\n844:     pub async fn headless(&mut self, prompt: String) -> Result<()> {\n845:         let message = Message::user().with_text(&prompt);\n846:         self.process_message(message, CancellationToken::default())\n847:             .await?;\n848:         Ok(())\n849:     }\n850: \n851:     async fn process_agent_response(\n852:         &mut self,\n853:         interactive: bool,\n854:         cancel_token: CancellationToken,\n855:     ) -> Result<()> {\n856:         let is_json_mode = self.output_format == \"json\";\n857:         let is_stream_json_mode = self.output_format == \"stream-json\";\n858: \n859:         // Helper to emit a streaming JSON event\n860:         let emit_stream_event = |event: &StreamEvent| {\n861:             if let Ok(json) = serde_json::to_string(event) {\n862:                 println!(\"{}\", json);\n863:             }\n864:         };\n865: \n866:         let session_config = SessionConfig {\n867:             id: self.session_id.clone(),\n868:             schedule_id: self.scheduled_job_id.clone(),\n869:             max_turns: self.max_turns,\n870:             retry_config: self.retry_config.clone(),\n871:         };\n872:         let user_message = self\n873:             .messages\n874:             .last()\n875:             .ok_or_else(|| anyhow::anyhow!(\"No user message\"))?;\n876: \n877:         let cancel_token_interrupt = cancel_token.clone();\n878:         let handle = tokio::spawn(async move {\n879:             if ctrl_c().await.is_ok() {\n880:                 cancel_token_interrupt.cancel();\n881:             }\n882:         });\n883:         let _drop_handle = AbortOnDropHandle::new(handle);\n884: \n885:         let mut stream = self\n886:             .agent\n887:             .reply(\n888:                 user_message.clone(),\n889:                 session_config.clone(),\n890:                 Some(cancel_token.clone()),\n891:             )\n892:             .await?;\n893: \n894:         let mut progress_bars = output::McpSpinners::new();\n895:         let cancel_token_clone = cancel_token.clone();\n896: \n897:         use futures::StreamExt;\n898:         loop {\n899:             tokio::select! {\n900:                 result = stream.next() => {\n901:                     match result {\n902:                         Some(Ok(AgentEvent::Message(message))) => {\n903:                             let tool_call_confirmation = message.content.iter().find_map(|content| {\n904:                                 if let MessageContent::ActionRequired(action) = content {\n905:                                     #[allow(irrefutable_let_patterns)] // this is a one variant enum right now but it will have more\n906:                                     if let ActionRequiredData::ToolConfirmation { id, tool_name, arguments, prompt } = &action.data {\n907:                                         Some((id.clone(), tool_name.clone(), arguments.clone(), prompt.clone()))\n908:                                     } else {\n909:                                         None\n910:                                     }\n911:                                 } else {\n912:                                     None\n913:                                 }\n914:                             });\n915: \n916:                             let elicitation_request = message.content.iter().find_map(|content| {\n917:                                 if let MessageContent::ActionRequired(action) = content {\n918:                                     if let ActionRequiredData::Elicitation { id, message, requested_schema } = &action.data {\n919:                                         Some((id.clone(), message.clone(), requested_schema.clone()))\n920:                                     } else {\n921:                                         None\n922:                                     }\n923:                                 } else {\n924:                                     None\n925:                                 }\n926:                             });\n927: \n928:                             if let Some((id, _tool_name, _arguments, security_prompt)) = tool_call_confirmation {\n929:                                 output::hide_thinking();\n930: \n931:                                 // Format the confirmation prompt - use security message if present, otherwise use generic message\n932:                                 let prompt = if let Some(security_message) = &security_prompt {\n933:                                     println!(\"\\n{}\", security_message);\n934:                                     \"Do you allow this tool call?\".to_string()\n935:                                 } else {\n936:                                     \"Goose would like to call the above tool, do you allow?\".to_string()\n937:                                 };\n938: \n939:                                 // Get confirmation from user\n940:                                 let permission_result = if security_prompt.is_none() {\n941:                                     // No security message - show all options including \"Always Allow\"\n942:                                     cliclack::select(prompt)\n943:                                         .item(Permission::AllowOnce, \"Allow\", \"Allow the tool call once\")\n944:                                         .item(Permission::AlwaysAllow, \"Always Allow\", \"Always allow the tool call\")\n945:                                         .item(Permission::DenyOnce, \"Deny\", \"Deny the tool call\")\n946:                                         .item(Permission::Cancel, \"Cancel\", \"Cancel the AI response and tool call\")\n947:                                         .interact()\n948:                                 } else {\n949:                                     // Security message present - don't show \"Always Allow\"\n950:                                     cliclack::select(prompt)\n951:                                         .item(Permission::AllowOnce, \"Allow\", \"Allow the tool call once\")\n952:                                         .item(Permission::DenyOnce, \"Deny\", \"Deny the tool call\")\n953:                                         .item(Permission::Cancel, \"Cancel\", \"Cancel the AI response and tool call\")\n954:                                         .interact()\n955:                                 };\n956: \n957:                                 let permission = match permission_result {\n958:                                     Ok(p) => p,\n959:                                     Err(e) => {\n960:                                         if e.kind() == std::io::ErrorKind::Interrupted {\n961:                                             Permission::Cancel\n962:                                         } else {\n963:                                             return Err(e.into());\n964:                                         }\n965:                                     }\n966:                                 };\n967: \n968:                                 if permission == Permission::Cancel {\n969:                                     output::render_text(\"Tool call cancelled. Returning to chat...\", Some(Color::Yellow), true);\n970: \n971:                                     let mut response_message = Message::user();\n972:                                     response_message.content.push(MessageContent::tool_response(\n973:                                         id.clone(),\n974:                                         Err(ErrorData { code: ErrorCode::INVALID_REQUEST, message: std::borrow::Cow::from(\"Tool call cancelled by user\".to_string()), data: None })\n975:                                     ));\n976:                                     self.messages.push(response_message);\n977:                                     cancel_token_clone.cancel();\n978:                                     drop(stream);\n979:                                     break;\n980:                                 } else {\n981:                                     self.agent.handle_confirmation(id.clone(), PermissionConfirmation {\n982:                                         principal_type: PrincipalType::Tool,\n983:                                         permission,\n984:                                     }).await;\n985:                                 }\n986:                             }\n987:                             else if let Some((elicitation_id, elicitation_message, schema)) = elicitation_request {\n988:                                 output::hide_thinking();\n989:                                 let _ = progress_bars.hide();\n990: \n991:                                 match elicitation::collect_elicitation_input(&elicitation_message, &schema) {\n992:                                     Ok(Some(user_data)) => {\n993:                                         let user_data_value = serde_json::to_value(user_data)\n994:                                             .unwrap_or(serde_json::Value::Object(serde_json::Map::new()));\n995: \n996:                                         let response_message = Message::user()\n997:                                             .with_content(MessageContent::action_required_elicitation_response(\n998:                                                 elicitation_id.clone(),\n999:                                                 user_data_value,\n1000:                                             ))\n1001:                                             .with_visibility(false, true);\n1002: \n1003:                                         self.messages.push(response_message.clone());\n1004:                                         // Elicitation responses return an empty stream - the response\n1005:                                         // unblocks the waiting tool call via ActionRequiredManager\n1006:                                         let _ = self\n1007:                                             .agent\n1008:                                             .reply(\n1009:                                                 response_message,\n1010:                                                 session_config.clone(),\n1011:                                                 Some(cancel_token.clone()),\n1012:                                             )\n1013:                                             .await?;\n1014:                                     }\n1015:                                     Ok(None) => {\n1016:                                         output::render_text(\"Information request cancelled.\", Some(Color::Yellow), true);\n1017:                                         cancel_token_clone.cancel();\n1018:                                         drop(stream);\n1019:                                         break;\n1020:                                     }\n1021:                                     Err(e) => {\n1022:                                         output::render_error(&format!(\"Failed to collect input: {}\", e));\n1023:                                         cancel_token_clone.cancel();\n1024:                                         drop(stream);\n1025:                                         break;\n1026:                                     }\n1027:                                 }\n1028:                             }\n1029:                             else {\n1030:                                 for content in &message.content {\n1031:                                     if let MessageContent::ToolRequest(tool_request) = content {\n1032:                                         if let Ok(tool_call) = &tool_request.tool_call {\n1033:                                             tracing::info!(counter.goose.tool_calls = 1,\n1034:                                                 tool_name = %tool_call.name,\n1035:                                                 \"Tool call started\"\n1036:                                             );\n1037:                                         }\n1038:                                     }\n1039:                                     if let MessageContent::ToolResponse(tool_response) = content {\n1040:                                         let tool_name = self.messages\n1041:                                             .iter()\n1042:                                             .rev()\n1043:                                             .find_map(|msg| {\n1044:                                                 msg.content.iter().find_map(|c| {\n1045:                                                     if let MessageContent::ToolRequest(req) = c {\n1046:                                                         if req.id == tool_response.id {\n1047:                                                             if let Ok(tool_call) = &req.tool_call {\n1048:                                                                 Some(tool_call.name.clone())\n1049:                                                             } else {\n1050:                                                                 None\n1051:                                                             }\n1052:                                                         } else {\n1053:                                                             None\n1054:                                                         }\n1055:                                                     } else {\n1056:                                                         None\n1057:                                                     }\n1058:                                                 })\n1059:                                             })\n1060:                                             .unwrap_or_else(|| \"unknown\".to_string().into());\n1061: \n1062:                                         let success = tool_response.tool_result.is_ok();\n1063:                                         let result_status = if success { \"success\" } else { \"error\" };\n1064:                                         tracing::info!(\n1065:                                             counter.goose.tool_completions = 1,\n1066:                                             tool_name = %tool_name,\n1067:                                             result = %result_status,\n1068:                                             \"Tool call completed\"\n1069:                                         );\n1070:                                     }\n1071:                                 }\n1072: \n1073:                                 self.messages.push(message.clone());\n1074: \n1075:                                 if interactive {output::hide_thinking()};\n1076:                                 let _ = progress_bars.hide();\n1077: \n1078:                                 // Handle different output formats\n1079:                                 if is_stream_json_mode {\n1080:                                     emit_stream_event(&StreamEvent::Message { message: message.clone() });\n1081:                                 } else if !is_json_mode {\n1082:                                     output::render_message(&message, self.debug);\n1083:                                 }\n1084:                             }\n1085:                         }\n1086:                         Some(Ok(AgentEvent::McpNotification((extension_id, message)))) => {\n1087:                             match &message {\n1088:                                 ServerNotification::LoggingMessageNotification(notification) => {\n1089:                                     let data = &notification.params.data;\n1090:                                     let (formatted_message, subagent_id, message_notification_type) = match data {\n1091:                                         Value::String(s) => (s.clone(), None, None),\n1092:                                         Value::Object(o) => {\n1093:                                             // Check for subagent notification structure first\n1094:                                             if let Some(Value::String(msg)) = o.get(\"message\") {\n1095:                                                 // Extract subagent info for better display\n1096:                                                 let subagent_id = o.get(\"subagent_id\")\n1097:                                                     .and_then(|v| v.as_str());\n1098:                                                 let notification_type = o.get(\"type\")\n1099:                                                     .and_then(|v| v.as_str());\n1100: \n1101:                                                 let formatted = match notification_type {\n1102:                                                     Some(\"subagent_created\") | Some(\"completed\") | Some(\"terminated\") => {\n1103:                                                         format!(\"🤖 {}\", msg)\n1104:                                                     }\n1105:                                                     Some(\"tool_usage\") | Some(\"tool_completed\") | Some(\"tool_error\") => {\n1106:                                                         format!(\"🔧 {}\", msg)\n1107:                                                     }\n1108:                                                     Some(\"message_processing\") | Some(\"turn_progress\") => {\n1109:                                                         format!(\"💭 {}\", msg)\n1110:                                                     }\n1111:                                                     Some(\"response_generated\") => {\n1112:                                                         // Check verbosity setting for subagent response content\n1113:                                                         let config = Config::global();\n1114:                                                         let min_priority = config\n1115:                                                             .get_param::<f32>(\"GOOSE_CLI_MIN_PRIORITY\")\n1116:                                                             .ok()\n1117:                                                             .unwrap_or(0.5);\n1118: \n1119:                                                         if min_priority > 0.1 && !self.debug {\n1120:                                                             // High/Medium verbosity: show truncated response\n1121:                                                             if let Some(response_content) = msg.strip_prefix(\"Responded: \") {\n1122:                                                                 format!(\"🤖 Responded: {}\", safe_truncate(response_content, 100))\n1123:                                                             } else {\n1124:                                                                 format!(\"🤖 {}\", msg)\n1125:                                                             }\n1126:                                                         } else {\n1127:                                                             // All verbosity or debug: show full response\n1128:                                                             format!(\"🤖 {}\", msg)\n1129:                                                         }\n1130:                                                     }\n1131:                                                     _ => {\n1132:                                                         msg.to_string()\n1133:                                                     }\n1134:                                                 };\n1135:                                                 (formatted, subagent_id.map(str::to_string), notification_type.map(str::to_string))\n1136:                                             } else if let Some(Value::String(output)) = o.get(\"output\") {\n1137:                                                 // Extract type if present (e.g., \"shell_output\")\n1138:                                                 let notification_type = o.get(\"type\")\n1139:                                                     .and_then(|v| v.as_str())\n1140:                                                     .map(str::to_string);\n1141: \n1142:                                                 (output.to_owned(), None, notification_type)\n1143:                                             } else if let Some(result) = format_task_execution_notification(data) {\n1144:                                                 result\n1145:                                             } else {\n1146:                                                 (data.to_string(), None, None)\n1147:                                             }\n1148:                                         },\n1149:                                         v => {\n1150:                                             (v.to_string(), None, None)\n1151:                                         },\n1152:                                     };\n1153: \n1154:                                     if is_stream_json_mode {\n1155:                                         emit_stream_event(&StreamEvent::Notification {\n1156:                                             extension_id: extension_id.clone(),\n1157:                                             data: NotificationData::Log { message: formatted_message.clone() },\n1158:                                         });\n1159:                                     }\n1160:                                     // Handle subagent notifications - show immediately\n1161:                                     else if let Some(_id) = subagent_id {\n1162:                                         if interactive {\n1163:                                             let _ = progress_bars.hide();\n1164:                                             if !is_json_mode {\n1165:                                                 println!(\"{}\", console::style(&formatted_message).green().dim());\n1166:                                             }\n1167:                                         } else if !is_json_mode {\n1168:                                             progress_bars.log(&formatted_message);\n1169:                                         }\n1170:                                     } else if let Some(ref notification_type) = message_notification_type {\n1171:                                         if notification_type == TASK_EXECUTION_NOTIFICATION_TYPE {\n1172:                                             if interactive {\n1173:                                                 let _ = progress_bars.hide();\n1174:                                                 if !is_json_mode {\n1175:                                                     print!(\"{}\", formatted_message);\n1176:                                                     std::io::stdout().flush().unwrap();\n1177:                                                 }\n1178:                                             } else if !is_json_mode {\n1179:                                                 print!(\"{}\", formatted_message);\n1180:                                                 std::io::stdout().flush().unwrap();\n1181:                                             }\n1182:                                         } else if notification_type == \"shell_output\" {\n1183:                                             if interactive {\n1184:                                                 let _ = progress_bars.hide();\n1185:                                             }\n1186:                                             if !is_json_mode {\n1187:                                                 println!(\"{}\", formatted_message);\n1188:                                             }\n1189:                                         }\n1190:                                     }\n1191:                                     else if output::is_showing_thinking() {\n1192:                                         output::set_thinking_message(&formatted_message);\n1193:                                     } else {\n1194:                                         progress_bars.log(&formatted_message);\n1195:                                     }\n1196:                                 },\n1197:                                 ServerNotification::ProgressNotification(notification) => {\n1198:                                     let progress = notification.params.progress;\n1199:                                     let text = notification.params.message.as_deref();\n1200:                                     let total = notification.params.total;\n1201:                                     let token = &notification.params.progress_token;\n1202: \n1203:                                     if is_stream_json_mode {\n1204:                                         emit_stream_event(&StreamEvent::Notification {\n1205:                                             extension_id: extension_id.clone(),\n1206:                                             data: NotificationData::Progress {\n1207:                                                 progress,\n1208:                                                 total,\n1209:                                                 message: text.map(String::from),\n1210:                                             },\n1211:                                         });\n1212:                                     } else {\n1213:                                         progress_bars.update(\n1214:                                             &token.0.to_string(),\n1215:                                             progress,\n1216:                                             total,\n1217:                                             text,\n1218:                                         );\n1219:                                     }\n1220:                                 },\n1221:                                 _ => (),\n1222:                             }\n1223:                         }\n1224:                         Some(Ok(AgentEvent::HistoryReplaced(updated_conversation))) => {\n1225:                             self.messages = updated_conversation;\n1226:                         }\n1227:                         Some(Ok(AgentEvent::ModelChange { model, mode })) => {\n1228:                             if is_stream_json_mode {\n1229:                                 emit_stream_event(&StreamEvent::ModelChange {\n1230:                                     model: model.clone(),\n1231:                                     mode: mode.clone(),\n1232:                                 });\n1233:                             } else if self.debug {\n1234:                                 eprintln!(\"Model changed to {} in {} mode\", model, mode);\n1235:                             }\n1236:                         }\n1237: \n1238:                         Some(Err(e)) => {\n1239:                             let error_msg = e.to_string();\n1240: \n1241:                             if is_stream_json_mode {\n1242:                                 emit_stream_event(&StreamEvent::Error { error: error_msg.clone() });\n1243:                             }\n1244: \n1245:                             if e.downcast_ref::<goose::providers::errors::ProviderError>()\n1246:                                 .map(|provider_error| matches!(provider_error, goose::providers::errors::ProviderError::ContextLengthExceeded(_)))\n1247:                                 .unwrap_or(false) {\n1248: \n1249:                                 if !is_stream_json_mode {\n1250:                                     output::render_text(\n1251:                                         \"Compaction requested. Should have happened in the agent!\",\n1252:                                         Some(Color::Yellow),\n1253:                                         true\n1254:                                     );\n1255:                                 }\n1256:                                 warn!(\"Compaction requested. Should have happened in the agent!\");\n1257:                             }\n1258:                             if !is_stream_json_mode {\n1259:                                 eprintln!(\"Error: {}\", error_msg);\n1260:                             }\n1261:                             cancel_token_clone.cancel();\n1262:                             drop(stream);\n1263:                             if let Err(e) = self.handle_interrupted_messages(false).await {\n1264:                                 eprintln!(\"Error handling interruption: {}\", e);\n1265:                             } else if !is_stream_json_mode {\n1266:                                 output::render_error(\n1267:                                     \"The error above was an exception we were not able to handle.\\n\\\n1268:                                     These errors are often related to connection or authentication\\n\\\n1269:                                     We've removed the conversation up to the most recent user message\\n\\\n1270:                                     - depending on the error you may be able to continue\",\n1271:                                 );\n1272:                             }\n1273:                             break;\n1274:                         }\n1275:                         None => break,\n1276:                     }\n1277:                 }\n1278:                 _ = cancel_token_clone.cancelled() => {\n1279:                     drop(stream);\n1280:                     if let Err(e) = self.handle_interrupted_messages(true).await {\n1281:                         eprintln!(\"Error handling interruption: {}\", e);\n1282:                     }\n1283:                     break;\n1284:                 }\n1285:             }\n1286:         }\n1287: \n1288:         // Output based on format\n1289:         if is_json_mode {\n1290:             let metadata = match SessionManager::get_session(&self.session_id, false).await {\n1291:                 Ok(session) => JsonMetadata {\n1292:                     total_tokens: session.total_tokens,\n1293:                     input_tokens: session.input_tokens,\n1294:                     output_tokens: session.output_tokens,\n1295:                     accumulated_total_tokens: session.accumulated_total_tokens,\n1296:                     accumulated_input_tokens: session.accumulated_input_tokens,\n1297:                     accumulated_output_tokens: session.accumulated_output_tokens,\n1298:                     status: \"completed\".to_string(),\n1299:                 },\n1300:                 Err(_) => JsonMetadata {\n1301:                     total_tokens: None,\n1302:                     input_tokens: None,\n1303:                     output_tokens: None,\n1304:                     accumulated_total_tokens: None,\n1305:                     accumulated_input_tokens: None,\n1306:                     accumulated_output_tokens: None,\n1307:                     status: \"completed\".to_string(),\n1308:                 },\n1309:             };\n1310: \n1311:             let json_output = JsonOutput {\n1312:                 messages: self.messages.messages().to_vec(),\n1313:                 metadata,\n1314:             };\n1315: \n1316:             println!(\"{}\", serde_json::to_string_pretty(&json_output)?);\n1317:         } else if is_stream_json_mode {\n1318:             let total_tokens = SessionManager::get_session(&self.session_id, false)\n1319:                 .await\n1320:                 .ok()\n1321:                 .and_then(|s| s.total_tokens);\n1322:             emit_stream_event(&StreamEvent::Complete { total_tokens });\n1323:         } else {\n1324:             println!();\n1325:         }\n1326: \n1327:         Ok(())\n1328:     }\n1329: \n1330:     async fn handle_interrupted_messages(&mut self, interrupt: bool) -> Result<()> {\n1331:         // First, get any tool requests from the last message if it exists\n1332:         let tool_requests = self\n1333:             .messages\n1334:             .last()\n1335:             .filter(|msg| msg.role == rmcp::model::Role::Assistant)\n1336:             .map_or(Vec::new(), |msg| {\n1337:                 msg.content\n1338:                     .iter()\n1339:                     .filter_map(|content| {\n1340:                         if let MessageContent::ToolRequest(req) = content {\n1341:                             Some((req.id.clone(), req.tool_call.clone()))\n1342:                         } else {\n1343:                             None\n1344:                         }\n1345:                     })\n1346:                     .collect()\n1347:             });\n1348: \n1349:         if !tool_requests.is_empty() {\n1350:             // Interrupted during a tool request\n1351:             // Create tool responses for all interrupted tool requests\n1352:             let mut response_message = Message::user();\n1353:             let last_tool_name = tool_requests\n1354:                 .last()\n1355:                 .and_then(|(_, tool_call)| {\n1356:                     tool_call\n1357:                         .as_ref()\n1358:                         .ok()\n1359:                         .map(|tool| tool.name.to_string().clone())\n1360:                 })\n1361:                 .unwrap_or_else(|| \"tool\".to_string());\n1362: \n1363:             let notification = if interrupt {\n1364:                 \"Interrupted by the user to make a correction\".to_string()\n1365:             } else {\n1366:                 \"An uncaught error happened during tool use\".to_string()\n1367:             };\n1368:             for (req_id, _) in &tool_requests {\n1369:                 response_message.content.push(MessageContent::tool_response(\n1370:                     req_id.clone(),\n1371:                     Err(ErrorData {\n1372:                         code: ErrorCode::INTERNAL_ERROR,\n1373:                         message: std::borrow::Cow::from(notification.clone()),\n1374:                         data: None,\n1375:                     }),\n1376:                 ));\n1377:             }\n1378:             // TODO(Douwe): update also db\n1379:             self.push_message(response_message);\n1380:             let prompt = format!(\n1381:                 \"The existing call to {} was interrupted. How would you like to proceed?\",\n1382:                 last_tool_name\n1383:             );\n1384:             self.push_message(Message::assistant().with_text(&prompt));\n1385:             output::render_message(&Message::assistant().with_text(&prompt), self.debug);\n1386:         } else {\n1387:             // An interruption occurred outside of a tool request-response.\n1388:             if let Some(last_msg) = self.messages.last() {\n1389:                 if last_msg.role == rmcp::model::Role::User {\n1390:                     match last_msg.content.first() {\n1391:                         Some(MessageContent::ToolResponse(_)) => {\n1392:                             // Interruption occurred after a tool had completed but not assistant reply\n1393:                             let prompt = \"The tool calling loop was interrupted. How would you like to proceed?\";\n1394:                             self.push_message(Message::assistant().with_text(prompt));\n1395:                             output::render_message(\n1396:                                 &Message::assistant().with_text(prompt),\n1397:                                 self.debug,\n1398:                             );\n1399:                         }\n1400:                         Some(_) => {\n1401:                             // A real users message\n1402:                             self.messages.pop();\n1403:                             let prompt = \"Interrupted before the model replied and removed the last message.\";\n1404:                             output::render_message(\n1405:                                 &Message::assistant().with_text(prompt),\n1406:                                 self.debug,\n1407:                             );\n1408:                         }\n1409:                         None => panic!(\"No content in last message\"),\n1410:                     }\n1411:                 }\n1412:             }\n1413:         }\n1414:         Ok(())\n1415:     }\n1416: \n1417:     /// Update the completion cache with fresh data\n1418:     /// This should be called before the interactive session starts\n1419:     pub async fn update_completion_cache(&mut self) -> Result<()> {\n1420:         // Get fresh data\n1421:         let prompts = self.agent.list_extension_prompts().await;\n1422: \n1423:         // Update the cache with write lock\n1424:         let mut cache = self.completion_cache.write().unwrap();\n1425:         cache.prompts.clear();\n1426:         cache.prompt_info.clear();\n1427: \n1428:         for (extension, prompt_list) in prompts {\n1429:             let names: Vec<String> = prompt_list.iter().map(|p| p.name.clone()).collect();\n1430:             cache.prompts.insert(extension.clone(), names);\n1431: \n1432:             for prompt in prompt_list {\n1433:                 cache.prompt_info.insert(\n1434:                     prompt.name.clone(),\n1435:                     output::PromptInfo {\n1436:                         name: prompt.name.clone(),\n1437:                         description: prompt.description.clone(),\n1438:                         arguments: prompt.arguments.clone(),\n1439:                         extension: Some(extension.clone()),\n1440:                     },\n1441:                 );\n1442:             }\n1443:         }\n1444: \n1445:         cache.last_updated = Instant::now();\n1446:         Ok(())\n1447:     }\n1448: \n1449:     /// Invalidate the completion cache\n1450:     /// This should be called when extensions are added or removed\n1451:     async fn invalidate_completion_cache(&self) {\n1452:         let mut cache = self.completion_cache.write().unwrap();\n1453:         cache.prompts.clear();\n1454:         cache.prompt_info.clear();\n1455:         cache.last_updated = Instant::now();\n1456:     }\n1457: \n1458:     pub fn message_history(&self) -> Conversation {\n1459:         self.messages.clone()\n1460:     }\n1461: \n1462:     /// Render all past messages from the session history\n1463:     pub fn render_message_history(&self) {\n1464:         if self.messages.is_empty() {\n1465:             return;\n1466:         }\n1467: \n1468:         // Print session restored message\n1469:         println!(\n1470:             \"\\n{} {} messages loaded into context.\",\n1471:             console::style(\"Session restored:\").green().bold(),\n1472:             console::style(self.messages.len()).green()\n1473:         );\n1474: \n1475:         // Render each message\n1476:         for message in self.messages.iter() {\n1477:             output::render_message(message, self.debug);\n1478:         }\n1479: \n1480:         // Add a visual separator after restored messages\n1481:         println!(\n1482:             \"\\n{}\\n\",\n1483:             console::style(\"──────── New Messages ────────\").dim()\n1484:         );\n1485:     }\n1486: \n1487:     pub async fn get_session(&self) -> Result<goose::session::Session> {\n1488:         SessionManager::get_session(&self.session_id, false).await\n1489:     }\n1490: \n1491:     // Get the session's total token usage\n1492:     pub async fn get_total_token_usage(&self) -> Result<Option<i32>> {\n1493:         let metadata = self.get_session().await?;\n1494:         Ok(metadata.total_tokens)\n1495:     }\n1496: \n1497:     /// Display enhanced context usage with session totals\n1498:     pub async fn display_context_usage(&self) -> Result<()> {\n1499:         let provider = self.agent.provider().await?;\n1500:         let model_config = provider.get_model_config();\n1501:         let context_limit = model_config.context_limit();\n1502: \n1503:         let config = Config::global();\n1504:         let show_cost = config\n1505:             .get_param::<bool>(\"GOOSE_CLI_SHOW_COST\")\n1506:             .unwrap_or(false);\n1507: \n1508:         let provider_name = config\n1509:             .get_goose_provider()\n1510:             .unwrap_or_else(|_| \"unknown\".to_string());\n1511: \n1512:         match self.get_session().await {\n1513:             Ok(metadata) => {\n1514:                 let total_tokens = metadata.total_tokens.unwrap_or(0) as usize;\n1515: \n1516:                 output::display_context_usage(total_tokens, context_limit);\n1517: \n1518:                 if show_cost {\n1519:                     let input_tokens = metadata.input_tokens.unwrap_or(0) as usize;\n1520:                     let output_tokens = metadata.output_tokens.unwrap_or(0) as usize;\n1521:                     output::display_cost_usage(\n1522:                         &provider_name,\n1523:                         &model_config.model_name,\n1524:                         input_tokens,\n1525:                         output_tokens,\n1526:                     );\n1527:                 }\n1528:             }\n1529:             Err(_) => {\n1530:                 output::display_context_usage(0, context_limit);\n1531:             }\n1532:         }\n1533: \n1534:         Ok(())\n1535:     }\n1536: \n1537:     /// Handle prompt command execution\n1538:     async fn handle_prompt_command(&mut self, opts: input::PromptCommandOptions) -> Result<()> {\n1539:         // name is required\n1540:         if opts.name.is_empty() {\n1541:             output::render_error(\"Prompt name argument is required\");\n1542:             return Ok(());\n1543:         }\n1544: \n1545:         if opts.info {\n1546:             match self.get_prompt_info(&opts.name).await? {\n1547:                 Some(info) => output::render_prompt_info(&info),\n1548:                 None => output::render_error(&format!(\"Prompt '{}' not found\", opts.name)),\n1549:             }\n1550:         } else {\n1551:             // Convert the arguments HashMap to a Value\n1552:             let arguments = serde_json::to_value(opts.arguments)\n1553:                 .map_err(|e| anyhow::anyhow!(\"Failed to serialize arguments: {}\", e))?;\n1554: \n1555:             match self.get_prompt(&opts.name, arguments).await {\n1556:                 Ok(messages) => {\n1557:                     let start_len = self.messages.len();\n1558:                     let mut valid = true;\n1559:                     for (i, prompt_message) in messages.into_iter().enumerate() {\n1560:                         let msg = Message::from(prompt_message);\n1561:                         // ensure we get a User - Assistant - User type pattern\n1562:                         let expected_role = if i % 2 == 0 {\n1563:                             rmcp::model::Role::User\n1564:                         } else {\n1565:                             rmcp::model::Role::Assistant\n1566:                         };\n1567: \n1568:                         if msg.role != expected_role {\n1569:                             output::render_error(&format!(\n1570:                                 \"Expected {:?} message at position {}, but found {:?}\",\n1571:                                 expected_role, i, msg.role\n1572:                             ));\n1573:                             valid = false;\n1574:                             // get rid of everything we added to messages\n1575:                             self.messages.truncate(start_len);\n1576:                             break;\n1577:                         }\n1578: \n1579:                         if msg.role == rmcp::model::Role::User {\n1580:                             output::render_message(&msg, self.debug);\n1581:                         }\n1582:                         self.push_message(msg);\n1583:                     }\n1584: \n1585:                     if valid {\n1586:                         output::show_thinking();\n1587:                         self.process_agent_response(true, CancellationToken::default())\n1588:                             .await?;\n1589:                         output::hide_thinking();\n1590:                     }\n1591:                 }\n1592:                 Err(e) => output::render_error(&e.to_string()),\n1593:             }\n1594:         }\n1595: \n1596:         Ok(())\n1597:     }\n1598: \n1599:     /// Save a recipe to a file\n1600:     ///\n1601:     /// # Arguments\n1602:     /// * `recipe` - The recipe to save\n1603:     /// * `filepath_str` - The path to save the recipe to\n1604:     ///\n1605:     /// # Returns\n1606:     /// * `Result<PathBuf, String>` - The path the recipe was saved to or an error message\n1607:     fn save_recipe(\n1608:         &self,\n1609:         recipe: &goose::recipe::Recipe,\n1610:         filepath_str: &str,\n1611:     ) -> anyhow::Result<PathBuf> {\n1612:         let path_buf = PathBuf::from(filepath_str);\n1613:         let mut path = path_buf.clone();\n1614: \n1615:         // Update the final path if it's relative\n1616:         if path_buf.is_relative() {\n1617:             // If the path is relative, resolve it relative to the current working directory\n1618:             let cwd = std::env::current_dir().context(\"Failed to get current directory\")?;\n1619:             path = cwd.join(&path_buf);\n1620:         }\n1621: \n1622:         // Check if parent directory exists\n1623:         if let Some(parent) = path.parent() {\n1624:             if !parent.exists() {\n1625:                 return Err(anyhow::anyhow!(\n1626:                     \"Directory '{}' does not exist\",\n1627:                     parent.display()\n1628:                 ));\n1629:             }\n1630:         }\n1631: \n1632:         // Try creating the file\n1633:         let file = std::fs::File::create(path.as_path())\n1634:             .context(format!(\"Failed to create file '{}'\", path.display()))?;\n1635: \n1636:         // Write YAML\n1637:         serde_yaml::to_writer(file, recipe).context(\"Failed to save recipe\")?;\n1638: \n1639:         Ok(path)\n1640:     }\n1641: \n1642:     fn push_message(&mut self, message: Message) {\n1643:         self.messages.push(message);\n1644:     }\n1645: }\n1646: \n1647: async fn get_reasoner() -> Result<Arc<dyn Provider>, anyhow::Error> {\n1648:     use goose::model::ModelConfig;\n1649:     use goose::providers::create;\n1650: \n1651:     let config = Config::global();\n1652: \n1653:     // Try planner-specific provider first, fallback to default provider\n1654:     let provider = if let Ok(provider) = config.get_param::<String>(\"GOOSE_PLANNER_PROVIDER\") {\n1655:         provider\n1656:     } else {\n1657:         println!(\"WARNING: GOOSE_PLANNER_PROVIDER not found. Using default provider...\");\n1658:         config\n1659:             .get_goose_provider()\n1660:             .expect(\"No provider configured. Run 'goose configure' first\")\n1661:     };\n1662: \n1663:     // Try planner-specific model first, fallback to default model\n1664:     let model = if let Ok(model) = config.get_param::<String>(\"GOOSE_PLANNER_MODEL\") {\n1665:         model\n1666:     } else {\n1667:         println!(\"WARNING: GOOSE_PLANNER_MODEL not found. Using default model...\");\n1668:         config\n1669:             .get_goose_model()\n1670:             .expect(\"No model configured. Run 'goose configure' first\")\n1671:     };\n1672: \n1673:     let model_config =\n1674:         ModelConfig::new_with_context_env(model, Some(\"GOOSE_PLANNER_CONTEXT_LIMIT\"))?;\n1675:     let reasoner = create(&provider, model_config).await?;\n1676: \n1677:     Ok(reasoner)\n1678: }\n1679: \n1680: /// Format elapsed time duration\n1681: /// Shows seconds if less than 60, otherwise shows minutes:seconds\n1682: fn format_elapsed_time(duration: std::time::Duration) -> String {\n1683:     let total_secs = duration.as_secs();\n1684:     if total_secs < 60 {\n1685:         format!(\"{:.2}s\", duration.as_secs_f64())\n1686:     } else {\n1687:         let minutes = total_secs / 60;\n1688:         let seconds = total_secs % 60;\n1689:         format!(\"{}m {:02}s\", minutes, seconds)\n1690:     }\n1691: }\n1692: \n1693: #[cfg(test)]\n1694: mod tests {\n1695:     use super::*;\n1696:     use std::time::Duration;\n1697: \n1698:     #[test]\n1699:     fn test_format_elapsed_time_under_60_seconds() {\n1700:         // Test sub-second duration\n1701:         let duration = Duration::from_millis(500);\n1702:         assert_eq!(format_elapsed_time(duration), \"0.50s\");\n1703: \n1704:         // Test exactly 1 second\n1705:         let duration = Duration::from_secs(1);\n1706:         assert_eq!(format_elapsed_time(duration), \"1.00s\");\n1707: \n1708:         // Test 45.75 seconds\n1709:         let duration = Duration::from_millis(45750);\n1710:         assert_eq!(format_elapsed_time(duration), \"45.75s\");\n1711: \n1712:         // Test 59.99 seconds\n1713:         let duration = Duration::from_millis(59990);\n1714:         assert_eq!(format_elapsed_time(duration), \"59.99s\");\n1715:     }\n1716: \n1717:     #[test]\n1718:     fn test_format_elapsed_time_minutes() {\n1719:         // Test exactly 60 seconds (1 minute)\n1720:         let duration = Duration::from_secs(60);\n1721:         assert_eq!(format_elapsed_time(duration), \"1m 00s\");\n1722: \n1723:         // Test 61 seconds (1 minute 1 second)\n1724:         let duration = Duration::from_secs(61);\n1725:         assert_eq!(format_elapsed_time(duration), \"1m 01s\");\n1726: \n1727:         // Test 90 seconds (1 minute 30 seconds)\n1728:         let duration = Duration::from_secs(90);\n1729:         assert_eq!(format_elapsed_time(duration), \"1m 30s\");\n1730: \n1731:         // Test 119 seconds (1 minute 59 seconds)\n1732:         let duration = Duration::from_secs(119);\n1733:         assert_eq!(format_elapsed_time(duration), \"1m 59s\");\n1734: \n1735:         // Test 120 seconds (2 minutes)\n1736:         let duration = Duration::from_secs(120);\n1737:         assert_eq!(format_elapsed_time(duration), \"2m 00s\");\n1738: \n1739:         // Test 605 seconds (10 minutes 5 seconds)\n1740:         let duration = Duration::from_secs(605);\n1741:         assert_eq!(format_elapsed_time(duration), \"10m 05s\");\n1742: \n1743:         // Test 3661 seconds (61 minutes 1 second)\n1744:         let duration = Duration::from_secs(3661);\n1745:         assert_eq!(format_elapsed_time(duration), \"61m 01s\");\n1746:     }\n1747: \n1748:     #[test]\n1749:     fn test_format_elapsed_time_edge_cases() {\n1750:         // Test zero duration\n1751:         let duration = Duration::from_secs(0);\n1752:         assert_eq!(format_elapsed_time(duration), \"0.00s\");\n1753: \n1754:         // Test very small duration (1 millisecond)\n1755:         let duration = Duration::from_millis(1);\n1756:         assert_eq!(format_elapsed_time(duration), \"0.00s\");\n1757: \n1758:         // Test fractional seconds are truncated for minute display\n1759:         // 60.5 seconds should still show as 1m 00s (not 1m 00.5s)\n1760:         let duration = Duration::from_millis(60500);\n1761:         assert_eq!(format_elapsed_time(duration), \"1m 00s\");\n1762:     }\n1763: }\n```\n",
                  "annotations": {
                    "audience": [
                      "user"
                    ],
                    "priority": 0.0
                  }
                }
              ],
              "isError": false
            }
          }
        }
      ],
      "metadata": {
        "userVisible": true,
        "agentVisible": true
      }
    },
    {
      "id": "msg_01WcRHXjxxDbpcUxS1aEKQ42",
      "role": "assistant",
      "created": 1766962620,
      "content": [
        {
          "type": "text",
          "text": "Now I can see the CLI session structure. Let me look at the agent and how it processes messages:"
        },
        {
          "type": "toolRequest",
          "id": "toolu_01Fk2SX9821w7BASJU8xhnQe",
          "toolCall": {
            "status": "success",
            "value": {
              "name": "developer__text_editor",
              "arguments": {
                "command": "view",
                "path": "/Users/baxen/Development/goose/crates/goose/src/agents"
              }
            }
          }
        }
      ],
      "metadata": {
        "userVisible": true,
        "agentVisible": true
      }
    },
    {
      "id": "msg_3ff3384a-3639-4cd1-8799-24cb4f740487",
      "role": "user",
      "created": 1766962622,
      "content": [
        {
          "type": "toolResponse",
          "id": "toolu_01Fk2SX9821w7BASJU8xhnQe",
          "toolResult": {
            "status": "success",
            "value": {
              "content": [
                {
                  "type": "text",
                  "text": "'/Users/baxen/Development/goose/crates/goose/src/agents' is a directory. Contents:\n\nDirectories:\n  snapshots/\n  subagent_execution_tool/\n\nFiles:\n  agent.rs\n  chatrecall_extension.rs\n  code_execution_extension.rs\n  execute_commands.rs\n  extension.rs\n  extension_malware_check.rs\n  extension_manager.rs\n  extension_manager_extension.rs\n  final_output_tool.rs\n  large_response_handler.rs\n  mcp_client.rs\n  mod.rs\n  moim.rs\n  platform_tools.rs\n  prompt_manager.rs\n  reply_parts.rs\n  retry.rs\n  schedule_tool.rs\n  skills_extension.rs\n  subagent_handler.rs\n  subagent_task_config.rs\n  subagent_tool.rs\n  todo_extension.rs\n  tool_execution.rs\n  types.rs\n"
                }
              ],
              "isError": false
            }
          }
        }
      ],
      "metadata": {
        "userVisible": true,
        "agentVisible": true
      }
    },
    {
      "id": "msg_011hgy1hV5n8KQwUurfH1i2j",
      "role": "assistant",
      "created": 1766962625,
      "content": [
        {
          "type": "toolRequest",
          "id": "toolu_013xECDUsHxNLpR2fUm1zYim",
          "toolCall": {
            "status": "success",
            "value": {
              "name": "developer__text_editor",
              "arguments": {
                "command": "view",
                "path": "/Users/baxen/Development/goose/crates/goose/src/agents/agent.rs"
              }
            }
          }
        }
      ],
      "metadata": {
        "userVisible": true,
        "agentVisible": true
      }
    },
    {
      "id": "msg_7a9cc276-59ac-4fc7-bdea-b6a40830163a",
      "role": "user",
      "created": 1766962625,
      "content": [
        {
          "type": "toolResponse",
          "id": "toolu_013xECDUsHxNLpR2fUm1zYim",
          "toolResult": {
            "status": "success",
            "value": {
              "content": [
                {
                  "type": "resource",
                  "resource": {
                    "uri": "file:///Users/baxen/Development/goose/crates/goose/src/agents/agent.rs",
                    "mimeType": "text",
                    "text": "use std::collections::HashMap;\nuse std::future::Future;\nuse std::pin::Pin;\nuse std::sync::Arc;\n\nuse anyhow::{anyhow, Context, Result};\nuse futures::stream::BoxStream;\nuse futures::{stream, FutureExt, Stream, StreamExt, TryStreamExt};\nuse uuid::Uuid;\n\nuse super::final_output_tool::FinalOutputTool;\nuse super::platform_tools;\nuse super::tool_execution::{ToolCallResult, CHAT_MODE_TOOL_SKIPPED_RESPONSE, DECLINED_RESPONSE};\nuse crate::action_required_manager::ActionRequiredManager;\nuse crate::agents::extension::{ExtensionConfig, ExtensionResult, ToolInfo};\nuse crate::agents::extension_manager::{get_parameter_names, ExtensionManager};\nuse crate::agents::extension_manager_extension::MANAGE_EXTENSIONS_TOOL_NAME_COMPLETE;\nuse crate::agents::final_output_tool::{FINAL_OUTPUT_CONTINUATION_MESSAGE, FINAL_OUTPUT_TOOL_NAME};\nuse crate::agents::platform_tools::PLATFORM_MANAGE_SCHEDULE_TOOL_NAME;\nuse crate::agents::prompt_manager::PromptManager;\nuse crate::agents::retry::{RetryManager, RetryResult};\nuse crate::agents::subagent_task_config::TaskConfig;\nuse crate::agents::subagent_tool::{\n    create_subagent_tool, handle_subagent_tool, SUBAGENT_TOOL_NAME,\n};\nuse crate::agents::types::SessionConfig;\nuse crate::agents::types::{FrontendTool, SharedProvider, ToolResultReceiver};\nuse crate::config::{get_enabled_extensions, Config, GooseMode};\nuse crate::context_mgmt::{\n    check_if_compaction_needed, compact_messages, DEFAULT_COMPACTION_THRESHOLD,\n};\nuse crate::conversation::message::{\n    ActionRequiredData, Message, MessageContent, ProviderMetadata, SystemNotificationType,\n    ToolRequest,\n};\nuse crate::conversation::{debug_conversation_fix, fix_conversation, Conversation};\nuse crate::mcp_utils::ToolResult;\nuse crate::permission::permission_inspector::PermissionInspector;\nuse crate::permission::permission_judge::PermissionCheckResult;\nuse crate::permission::PermissionConfirmation;\nuse crate::providers::base::Provider;\nuse crate::providers::errors::ProviderError;\nuse crate::recipe::{Author, Recipe, Response, Settings, SubRecipe};\nuse crate::scheduler_trait::SchedulerTrait;\nuse crate::security::security_inspector::SecurityInspector;\nuse crate::session::extension_data::{EnabledExtensionsState, ExtensionState};\nuse crate::session::{Session, SessionManager, SessionType};\nuse crate::tool_inspection::ToolInspectionManager;\nuse crate::tool_monitor::RepetitionInspector;\nuse crate::utils::is_token_cancelled;\nuse regex::Regex;\nuse rmcp::model::{\n    CallToolRequestParam, CallToolResult, Content, ErrorCode, ErrorData, GetPromptResult, Prompt,\n    ServerNotification, Tool,\n};\nuse serde_json::Value;\nuse tokio::sync::{mpsc, Mutex};\nuse tokio_util::sync::CancellationToken;\nuse tracing::{debug, error, info, instrument, warn};\n\nconst DEFAULT_MAX_TURNS: u32 = 1000;\nconst COMPACTION_THINKING_TEXT: &str = \"goose is compacting the conversation...\";\n\n/// Context needed for the reply function\npub struct ReplyContext {\n    pub conversation: Conversation,\n    pub tools: Vec<Tool>,\n    pub toolshim_tools: Vec<Tool>,\n    pub system_prompt: String,\n    pub goose_mode: GooseMode,\n    pub initial_messages: Vec<Message>,\n}\n\npub struct ToolCategorizeResult {\n    pub frontend_requests: Vec<ToolRequest>,\n    pub remaining_requests: Vec<ToolRequest>,\n    pub filtered_response: Message,\n}\n\n/// The main goose Agent\npub struct Agent {\n    pub(super) provider: SharedProvider,\n\n    pub extension_manager: Arc<ExtensionManager>,\n    pub(super) sub_recipes: Mutex<HashMap<String, SubRecipe>>,\n    pub(super) final_output_tool: Arc<Mutex<Option<FinalOutputTool>>>,\n    pub(super) frontend_tools: Mutex<HashMap<String, FrontendTool>>,\n    pub(super) frontend_instructions: Mutex<Option<String>>,\n    pub(super) prompt_manager: Mutex<PromptManager>,\n    pub(super) confirmation_tx: mpsc::Sender<(String, PermissionConfirmation)>,\n    pub(super) confirmation_rx: Mutex<mpsc::Receiver<(String, PermissionConfirmation)>>,\n    pub(super) tool_result_tx: mpsc::Sender<(String, ToolResult<CallToolResult>)>,\n    pub(super) tool_result_rx: ToolResultReceiver,\n\n    pub(super) scheduler_service: Mutex<Option<Arc<dyn SchedulerTrait>>>,\n    pub(super) retry_manager: RetryManager,\n    pub(super) tool_inspection_manager: ToolInspectionManager,\n}\n\n#[derive(Clone, Debug)]\npub enum AgentEvent {\n    Message(Message),\n    McpNotification((String, ServerNotification)),\n    ModelChange { model: String, mode: String },\n    HistoryReplaced(Conversation),\n}\n\nimpl Default for Agent {\n    fn default() -> Self {\n        Self::new()\n    }\n}\n\npub enum ToolStreamItem<T> {\n    Message(ServerNotification),\n    Result(T),\n}\n\npub type ToolStream =\n    Pin<Box<dyn Stream<Item = ToolStreamItem<ToolResult<CallToolResult>>> + Send>>;\n\n// tool_stream combines a stream of ServerNotifications with a future representing the\n// final result of the tool call. MCP notifications are not request-scoped, but\n// this lets us capture all notifications emitted during the tool call for\n// simpler consumption\npub fn tool_stream<S, F>(rx: S, done: F) -> ToolStream\nwhere\n    S: Stream<Item = ServerNotification> + Send + Unpin + 'static,\n    F: Future<Output = ToolResult<CallToolResult>> + Send + 'static,\n{\n    Box::pin(async_stream::stream! {\n        tokio::pin!(done);\n        let mut rx = rx;\n\n        loop {\n            tokio::select! {\n                Some(msg) = rx.next() => {\n                    yield ToolStreamItem::Message(msg);\n                }\n                r = &mut done => {\n                    yield ToolStreamItem::Result(r);\n                    break;\n                }\n            }\n        }\n    })\n}\n\nimpl Agent {\n    pub fn new() -> Self {\n        // Create channels with buffer size 32 (adjust if needed)\n        let (confirm_tx, confirm_rx) = mpsc::channel(32);\n        let (tool_tx, tool_rx) = mpsc::channel(32);\n        let provider = Arc::new(Mutex::new(None));\n\n        Self {\n            provider: provider.clone(),\n            extension_manager: Arc::new(ExtensionManager::new(provider.clone())),\n            sub_recipes: Mutex::new(HashMap::new()),\n            final_output_tool: Arc::new(Mutex::new(None)),\n            frontend_tools: Mutex::new(HashMap::new()),\n            frontend_instructions: Mutex::new(None),\n            prompt_manager: Mutex::new(PromptManager::new()),\n            confirmation_tx: confirm_tx,\n            confirmation_rx: Mutex::new(confirm_rx),\n            tool_result_tx: tool_tx,\n            tool_result_rx: Arc::new(Mutex::new(tool_rx)),\n            scheduler_service: Mutex::new(None),\n            retry_manager: RetryManager::new(),\n            tool_inspection_manager: Self::create_default_tool_inspection_manager(),\n        }\n    }\n\n    /// Create a tool inspection manager with default inspectors\n    fn create_default_tool_inspection_manager() -> ToolInspectionManager {\n        let mut tool_inspection_manager = ToolInspectionManager::new();\n\n        // Add security inspector (highest priority - runs first)\n        tool_inspection_manager.add_inspector(Box::new(SecurityInspector::new()));\n\n        // Add permission inspector (medium-high priority)\n        // Note: mode will be updated dynamically based on session config\n        tool_inspection_manager.add_inspector(Box::new(PermissionInspector::new(\n            GooseMode::SmartApprove,\n            std::collections::HashSet::new(), // readonly tools - will be populated from extension manager\n            std::collections::HashSet::new(), // regular tools - will be populated from extension manager\n        )));\n\n        // Add repetition inspector (lower priority - basic repetition checking)\n        tool_inspection_manager.add_inspector(Box::new(RepetitionInspector::new(None)));\n\n        tool_inspection_manager\n    }\n\n    /// Reset the retry attempts counter to 0\n    pub async fn reset_retry_attempts(&self) {\n        self.retry_manager.reset_attempts().await;\n    }\n\n    /// Increment the retry attempts counter and return the new value\n    pub async fn increment_retry_attempts(&self) -> u32 {\n        self.retry_manager.increment_attempts().await\n    }\n\n    /// Get the current retry attempts count\n    pub async fn get_retry_attempts(&self) -> u32 {\n        self.retry_manager.get_attempts().await\n    }\n\n    async fn handle_retry_logic(\n        &self,\n        messages: &mut Conversation,\n        session_config: &SessionConfig,\n        initial_messages: &[Message],\n    ) -> Result<bool> {\n        let result = self\n            .retry_manager\n            .handle_retry_logic(\n                messages,\n                session_config,\n                initial_messages,\n                &self.final_output_tool,\n            )\n            .await?;\n\n        match result {\n            RetryResult::Retried => Ok(true),\n            RetryResult::Skipped\n            | RetryResult::MaxAttemptsReached\n            | RetryResult::SuccessChecksPassed => Ok(false),\n        }\n    }\n    async fn drain_elicitation_messages(session_id: &str) -> Vec<Message> {\n        let mut messages = Vec::new();\n        let mut elicitation_rx = ActionRequiredManager::global().request_rx.lock().await;\n        while let Ok(elicitation_message) = elicitation_rx.try_recv() {\n            if let Err(e) = SessionManager::add_message(session_id, &elicitation_message).await {\n                warn!(\"Failed to save elicitation message to session: {}\", e);\n            }\n            messages.push(elicitation_message);\n        }\n        messages\n    }\n\n    async fn prepare_reply_context(\n        &self,\n        unfixed_conversation: Conversation,\n        working_dir: &std::path::Path,\n    ) -> Result<ReplyContext> {\n        let unfixed_messages = unfixed_conversation.messages().clone();\n        let (conversation, issues) = fix_conversation(unfixed_conversation.clone());\n        if !issues.is_empty() {\n            debug!(\n                \"Conversation issue fixed: {}\",\n                debug_conversation_fix(\n                    unfixed_messages.as_slice(),\n                    conversation.messages(),\n                    &issues\n                )\n            );\n        }\n        let initial_messages = conversation.messages().clone();\n        let config = Config::global();\n\n        let (tools, toolshim_tools, system_prompt) =\n            self.prepare_tools_and_prompt(working_dir).await?;\n        let goose_mode = config.get_goose_mode().unwrap_or(GooseMode::Auto);\n\n        self.tool_inspection_manager\n            .update_permission_inspector_mode(goose_mode)\n            .await;\n\n        Ok(ReplyContext {\n            conversation,\n            tools,\n            toolshim_tools,\n            system_prompt,\n            goose_mode,\n            initial_messages,\n        })\n    }\n\n    async fn categorize_tools(\n        &self,\n        response: &Message,\n        tools: &[rmcp::model::Tool],\n    ) -> ToolCategorizeResult {\n        // Categorize tool requests\n        let (frontend_requests, remaining_requests, filtered_response) =\n            self.categorize_tool_requests(response, tools).await;\n\n        ToolCategorizeResult {\n            frontend_requests,\n            remaining_requests,\n            filtered_response,\n        }\n    }\n\n    async fn handle_approved_and_denied_tools(\n        &self,\n        permission_check_result: &PermissionCheckResult,\n        request_to_response_map: &HashMap<String, Arc<Mutex<Message>>>,\n        cancel_token: Option<tokio_util::sync::CancellationToken>,\n        session: &Session,\n    ) -> Result<Vec<(String, ToolStream)>> {\n        let mut tool_futures: Vec<(String, ToolStream)> = Vec::new();\n\n        // Handle pre-approved and read-only tools\n        for request in &permission_check_result.approved {\n            if let Ok(tool_call) = request.tool_call.clone() {\n                let (req_id, tool_result) = self\n                    .dispatch_tool_call(\n                        tool_call,\n                        request.id.clone(),\n                        cancel_token.clone(),\n                        session,\n                    )\n                    .await;\n\n                tool_futures.push((\n                    req_id,\n                    match tool_result {\n                        Ok(result) => tool_stream(\n                            result\n                                .notification_stream\n                                .unwrap_or_else(|| Box::new(stream::empty())),\n                            result.result,\n                        ),\n                        Err(e) => {\n                            tool_stream(Box::new(stream::empty()), futures::future::ready(Err(e)))\n                        }\n                    },\n                ));\n            }\n        }\n\n        Self::handle_denied_tools(permission_check_result, request_to_response_map).await;\n        Ok(tool_futures)\n    }\n\n    async fn handle_denied_tools(\n        permission_check_result: &PermissionCheckResult,\n        request_to_response_map: &HashMap<String, Arc<Mutex<Message>>>,\n    ) {\n        for request in &permission_check_result.denied {\n            if let Some(response_msg) = request_to_response_map.get(&request.id) {\n                let mut response = response_msg.lock().await;\n                *response = response.clone().with_tool_response_with_metadata(\n                    request.id.clone(),\n                    Ok(CallToolResult {\n                        content: vec![rmcp::model::Content::text(DECLINED_RESPONSE)],\n                        structured_content: None,\n                        is_error: Some(true),\n                        meta: None,\n                    }),\n                    request.metadata.as_ref(),\n                );\n            }\n        }\n    }\n\n    pub async fn set_scheduler(&self, scheduler: Arc<dyn SchedulerTrait>) {\n        let mut scheduler_service = self.scheduler_service.lock().await;\n        *scheduler_service = Some(scheduler);\n    }\n\n    /// Get a reference count clone to the provider\n    pub async fn provider(&self) -> Result<Arc<dyn Provider>, anyhow::Error> {\n        match &*self.provider.lock().await {\n            Some(provider) => Ok(Arc::clone(provider)),\n            None => Err(anyhow!(\"Provider not set\")),\n        }\n    }\n\n    /// Check if a tool is a frontend tool\n    pub async fn is_frontend_tool(&self, name: &str) -> bool {\n        self.frontend_tools.lock().await.contains_key(name)\n    }\n\n    /// Get a reference to a frontend tool\n    pub async fn get_frontend_tool(&self, name: &str) -> Option<FrontendTool> {\n        self.frontend_tools.lock().await.get(name).cloned()\n    }\n\n    pub async fn add_final_output_tool(&self, response: Response) {\n        let mut final_output_tool = self.final_output_tool.lock().await;\n        let created_final_output_tool = FinalOutputTool::new(response);\n        let final_output_system_prompt = created_final_output_tool.system_prompt();\n        *final_output_tool = Some(created_final_output_tool);\n        self.extend_system_prompt(final_output_system_prompt).await;\n    }\n\n    pub async fn add_sub_recipes(&self, sub_recipes_to_add: Vec<SubRecipe>) {\n        let mut sub_recipes = self.sub_recipes.lock().await;\n        for sr in sub_recipes_to_add {\n            sub_recipes.insert(sr.name.clone(), sr);\n        }\n    }\n\n    pub async fn apply_recipe_components(\n        &self,\n        sub_recipes: Option<Vec<SubRecipe>>,\n        response: Option<Response>,\n        include_final_output: bool,\n    ) {\n        if let Some(sub_recipes) = sub_recipes {\n            self.add_sub_recipes(sub_recipes).await;\n        }\n\n        if include_final_output {\n            if let Some(response) = response {\n                self.add_final_output_tool(response).await;\n            }\n        }\n    }\n\n    /// Dispatch a single tool call to the appropriate client\n    #[instrument(skip(self, tool_call, request_id), fields(input, output))]\n    pub async fn dispatch_tool_call(\n        &self,\n        tool_call: CallToolRequestParam,\n        request_id: String,\n        cancellation_token: Option<CancellationToken>,\n        session: &Session,\n    ) -> (String, Result<ToolCallResult, ErrorData>) {\n        // Prevent subagents from creating other subagents\n        if session.session_type == SessionType::SubAgent && tool_call.name == SUBAGENT_TOOL_NAME {\n            return (\n                request_id,\n                Err(ErrorData::new(\n                    ErrorCode::INVALID_REQUEST,\n                    \"Subagents cannot create other subagents\".to_string(),\n                    None,\n                )),\n            );\n        }\n\n        if tool_call.name == PLATFORM_MANAGE_SCHEDULE_TOOL_NAME {\n            let arguments = tool_call\n                .arguments\n                .map(Value::Object)\n                .unwrap_or(Value::Object(serde_json::Map::new()));\n            let result = self\n                .handle_schedule_management(arguments, request_id.clone())\n                .await;\n            let wrapped_result = result.map(|content| CallToolResult {\n                content,\n                structured_content: None,\n                is_error: Some(false),\n                meta: None,\n            });\n            return (request_id, Ok(ToolCallResult::from(wrapped_result)));\n        }\n\n        if tool_call.name == FINAL_OUTPUT_TOOL_NAME {\n            return if let Some(final_output_tool) = self.final_output_tool.lock().await.as_mut() {\n                let result = final_output_tool.execute_tool_call(tool_call.clone()).await;\n                (request_id, Ok(result))\n            } else {\n                (\n                    request_id,\n                    Err(ErrorData::new(\n                        ErrorCode::INTERNAL_ERROR,\n                        \"Final output tool not defined\".to_string(),\n                        None,\n                    )),\n                )\n            };\n        }\n\n        debug!(\"WAITING_TOOL_START: {}\", tool_call.name);\n        let result: ToolCallResult = if tool_call.name == SUBAGENT_TOOL_NAME {\n            let provider = match self.provider().await {\n                Ok(p) => p,\n                Err(_) => {\n                    return (\n                        request_id,\n                        Err(ErrorData::new(\n                            ErrorCode::INTERNAL_ERROR,\n                            \"Provider is required\".to_string(),\n                            None,\n                        )),\n                    );\n                }\n            };\n\n            let extensions = self.get_extension_configs().await;\n            let task_config =\n                TaskConfig::new(provider, &session.id, &session.working_dir, extensions);\n            let sub_recipes = self.sub_recipes.lock().await.clone();\n\n            let arguments = tool_call\n                .arguments\n                .clone()\n                .map(Value::Object)\n                .unwrap_or(Value::Object(serde_json::Map::new()));\n\n            handle_subagent_tool(\n                arguments,\n                task_config,\n                sub_recipes,\n                session.working_dir.clone(),\n                cancellation_token,\n            )\n        } else if self.is_frontend_tool(&tool_call.name).await {\n            // For frontend tools, return an error indicating we need frontend execution\n            ToolCallResult::from(Err(ErrorData::new(\n                ErrorCode::INTERNAL_ERROR,\n                \"Frontend tool execution required\".to_string(),\n                None,\n            )))\n        } else {\n            // Clone the result to ensure no references to extension_manager are returned\n            let result = self\n                .extension_manager\n                .dispatch_tool_call(tool_call.clone(), cancellation_token.unwrap_or_default())\n                .await;\n            result.unwrap_or_else(|e| {\n                crate::posthog::emit_error(\n                    \"tool_execution_failed\",\n                    &format!(\"{}: {}\", tool_call.name, e),\n                );\n                ToolCallResult::from(Err(ErrorData::new(\n                    ErrorCode::INTERNAL_ERROR,\n                    e.to_string(),\n                    None,\n                )))\n            })\n        };\n\n        debug!(\"WAITING_TOOL_END: {}\", tool_call.name);\n\n        (\n            request_id,\n            Ok(ToolCallResult {\n                notification_stream: result.notification_stream,\n                result: Box::new(\n                    result\n                        .result\n                        .map(super::large_response_handler::process_tool_response),\n                ),\n            }),\n        )\n    }\n\n    /// Save current extension state to session metadata\n    /// Should be called after any extension add/remove operation\n    pub async fn save_extension_state(&self, session: &SessionConfig) -> Result<()> {\n        let extension_configs = self.extension_manager.get_extension_configs().await;\n\n        let extensions_state = EnabledExtensionsState::new(extension_configs);\n\n        let mut session_data = SessionManager::get_session(&session.id, false).await?;\n\n        if let Err(e) = extensions_state.to_extension_data(&mut session_data.extension_data) {\n            warn!(\"Failed to serialize extension state: {}\", e);\n            return Err(anyhow!(\"Extension state serialization failed: {}\", e));\n        }\n\n        SessionManager::update_session(&session.id)\n            .extension_data(session_data.extension_data)\n            .apply()\n            .await?;\n\n        Ok(())\n    }\n\n    pub async fn add_extension(&self, extension: ExtensionConfig) -> ExtensionResult<()> {\n        match &extension {\n            ExtensionConfig::Frontend {\n                tools,\n                instructions,\n                ..\n            } => {\n                // For frontend tools, just store them in the frontend_tools map\n                let mut frontend_tools = self.frontend_tools.lock().await;\n                for tool in tools {\n                    let frontend_tool = FrontendTool {\n                        name: tool.name.to_string(),\n                        tool: tool.clone(),\n                    };\n                    frontend_tools.insert(tool.name.to_string(), frontend_tool);\n                }\n                // Store instructions if provided, using \"frontend\" as the key\n                let mut frontend_instructions = self.frontend_instructions.lock().await;\n                if let Some(instructions) = instructions {\n                    *frontend_instructions = Some(instructions.clone());\n                } else {\n                    // Default frontend instructions if none provided\n                    *frontend_instructions = Some(\n                        \"The following tools are provided directly by the frontend and will be executed by the frontend when called.\".to_string(),\n                    );\n                }\n            }\n            _ => {\n                self.extension_manager\n                    .add_extension(extension.clone())\n                    .await?;\n            }\n        }\n\n        Ok(())\n    }\n\n    pub async fn subagents_enabled(&self) -> bool {\n        let config = crate::config::Config::global();\n        let is_autonomous = config.get_goose_mode().unwrap_or(GooseMode::Auto) == GooseMode::Auto;\n        if !is_autonomous {\n            return false;\n        }\n        if self\n            .provider()\n            .await\n            .map(|provider| provider.get_active_model_name().starts_with(\"gemini\"))\n            .unwrap_or(false)\n        {\n            return false;\n        }\n        if let Some(ref session_id) = self.extension_manager.get_context().await.session_id {\n            if matches!(\n                SessionManager::get_session(session_id, false)\n                    .await\n                    .ok()\n                    .map(|session| session.session_type),\n                Some(SessionType::SubAgent)\n            ) {\n                return false;\n            }\n        }\n        !self\n            .extension_manager\n            .list_extensions()\n            .await\n            .map(|ext| ext.is_empty())\n            .unwrap_or(true)\n    }\n\n    pub async fn list_tools(&self, extension_name: Option<String>) -> Vec<Tool> {\n        let mut prefixed_tools = self\n            .extension_manager\n            .get_prefixed_tools(extension_name.clone())\n            .await\n            .unwrap_or_default();\n\n        let subagents_enabled = self.subagents_enabled().await;\n        if extension_name.is_none() || extension_name.as_deref() == Some(\"platform\") {\n            prefixed_tools.push(platform_tools::manage_schedule_tool());\n        }\n\n        if extension_name.is_none() {\n            if let Some(final_output_tool) = self.final_output_tool.lock().await.as_ref() {\n                prefixed_tools.push(final_output_tool.tool());\n            }\n\n            if subagents_enabled {\n                let sub_recipes = self.sub_recipes.lock().await;\n                let sub_recipes_vec: Vec<_> = sub_recipes.values().cloned().collect();\n                prefixed_tools.push(create_subagent_tool(&sub_recipes_vec));\n            }\n        }\n\n        prefixed_tools\n    }\n\n    pub async fn remove_extension(&self, name: &str) -> Result<()> {\n        self.extension_manager.remove_extension(name).await?;\n        Ok(())\n    }\n\n    pub async fn list_extensions(&self) -> Vec<String> {\n        self.extension_manager\n            .list_extensions()\n            .await\n            .expect(\"Failed to list extensions\")\n    }\n\n    pub async fn get_extension_configs(&self) -> Vec<ExtensionConfig> {\n        self.extension_manager.get_extension_configs().await\n    }\n\n    /// Handle a confirmation response for a tool request\n    pub async fn handle_confirmation(\n        &self,\n        request_id: String,\n        confirmation: PermissionConfirmation,\n    ) {\n        if let Err(e) = self.confirmation_tx.send((request_id, confirmation)).await {\n            error!(\"Failed to send confirmation: {}\", e);\n        }\n    }\n\n    #[instrument(skip(self, user_message, session_config), fields(user_message))]\n    pub async fn reply(\n        &self,\n        user_message: Message,\n        session_config: SessionConfig,\n        cancel_token: Option<CancellationToken>,\n    ) -> Result<BoxStream<'_, Result<AgentEvent>>> {\n        for content in &user_message.content {\n            if let MessageContent::ActionRequired(action_required) = content {\n                if let ActionRequiredData::ElicitationResponse { id, user_data } =\n                    &action_required.data\n                {\n                    if let Err(e) = ActionRequiredManager::global()\n                        .submit_response(id.clone(), user_data.clone())\n                        .await\n                    {\n                        let error_text = format!(\"Failed to submit elicitation response: {}\", e);\n                        error!(error_text);\n                        return Ok(Box::pin(stream::once(async {\n                            Ok(AgentEvent::Message(\n                                Message::assistant().with_text(error_text),\n                            ))\n                        })));\n                    }\n                    SessionManager::add_message(&session_config.id, &user_message).await?;\n                    return Ok(Box::pin(futures::stream::empty()));\n                }\n            }\n        }\n\n        let message_text = user_message.as_concat_text();\n\n        // Track custom slash command usage (don't track command name for privacy)\n        if message_text.trim().starts_with('/') {\n            let command = message_text.split_whitespace().next();\n            if let Some(cmd) = command {\n                if crate::slash_commands::get_recipe_for_command(cmd).is_some() {\n                    crate::posthog::emit_custom_slash_command_used();\n                }\n            }\n        }\n\n        let command_result = self\n            .execute_command(&message_text, &session_config.id)\n            .await;\n\n        match command_result {\n            Err(e) => {\n                let error_message = Message::assistant()\n                    .with_text(e.to_string())\n                    .with_visibility(true, false);\n                return Ok(Box::pin(stream::once(async move {\n                    Ok(AgentEvent::Message(error_message))\n                })));\n            }\n            Ok(Some(response)) if response.role == rmcp::model::Role::Assistant => {\n                SessionManager::add_message(\n                    &session_config.id,\n                    &user_message.clone().with_visibility(true, false),\n                )\n                .await?;\n                SessionManager::add_message(\n                    &session_config.id,\n                    &response.clone().with_visibility(true, false),\n                )\n                .await?;\n\n                // Check if this was a command that modifies conversation history\n                let modifies_history = crate::agents::execute_commands::COMPACT_TRIGGERS\n                    .contains(&message_text.trim())\n                    || message_text.trim() == \"/clear\";\n\n                return Ok(Box::pin(async_stream::try_stream! {\n                    yield AgentEvent::Message(user_message);\n                    yield AgentEvent::Message(response);\n\n                    // After commands that modify history, notify UI that history was replaced\n                    if modifies_history {\n                        let updated_session = SessionManager::get_session(&session_config.id, true)\n                            .await\n                            .map_err(|e| anyhow!(\"Failed to fetch updated session: {}\", e))?;\n                        let updated_conversation = updated_session\n                            .conversation\n                            .ok_or_else(|| anyhow!(\"Session has no conversation after history modification\"))?;\n                        yield AgentEvent::HistoryReplaced(updated_conversation);\n                    }\n                }));\n            }\n            Ok(Some(resolved_message)) => {\n                SessionManager::add_message(\n                    &session_config.id,\n                    &user_message.clone().with_visibility(true, false),\n                )\n                .await?;\n                SessionManager::add_message(\n                    &session_config.id,\n                    &resolved_message.clone().with_visibility(false, true),\n                )\n                .await?;\n            }\n            Ok(None) => {\n                SessionManager::add_message(&session_config.id, &user_message).await?;\n            }\n        }\n        let session = SessionManager::get_session(&session_config.id, true).await?;\n        let conversation = session\n            .conversation\n            .clone()\n            .ok_or_else(|| anyhow::anyhow!(\"Session {} has no conversation\", session_config.id))?;\n\n        let needs_auto_compact = check_if_compaction_needed(\n            self.provider().await?.as_ref(),\n            &conversation,\n            None,\n            &session,\n        )\n        .await?;\n\n        let conversation_to_compact = conversation.clone();\n\n        Ok(Box::pin(async_stream::try_stream! {\n            let final_conversation = if !needs_auto_compact {\n                conversation\n            } else {\n                let config = Config::global();\n                let threshold = config\n                    .get_param::<f64>(\"GOOSE_AUTO_COMPACT_THRESHOLD\")\n                    .unwrap_or(DEFAULT_COMPACTION_THRESHOLD);\n                let threshold_percentage = (threshold * 100.0) as u32;\n\n                let inline_msg = format!(\n                    \"Exceeded auto-compact threshold of {}%. Performing auto-compaction...\",\n                    threshold_percentage\n                );\n\n                yield AgentEvent::Message(\n                    Message::assistant().with_system_notification(\n                        SystemNotificationType::InlineMessage,\n                        inline_msg,\n                    )\n                );\n\n                yield AgentEvent::Message(\n                    Message::assistant().with_system_notification(\n                        SystemNotificationType::ThinkingMessage,\n                        COMPACTION_THINKING_TEXT,\n                    )\n                );\n\n                match compact_messages(self.provider().await?.as_ref(), &conversation_to_compact, false).await {\n                    Ok((compacted_conversation, summarization_usage)) => {\n                        SessionManager::replace_conversation(&session_config.id, &compacted_conversation).await?;\n                        Self::update_session_metrics(&session_config, &summarization_usage, true).await?;\n\n                        yield AgentEvent::HistoryReplaced(compacted_conversation.clone());\n\n                        yield AgentEvent::Message(\n                            Message::assistant().with_system_notification(\n                                SystemNotificationType::InlineMessage,\n                                \"Compaction complete\",\n                            )\n                        );\n\n                        compacted_conversation\n                    }\n                    Err(e) => {\n                        yield AgentEvent::Message(\n                            Message::assistant().with_text(\n                                format!(\"Ran into this error trying to compact: {e}.\\n\\nPlease try again or create a new session\")\n                            )\n                        );\n                        return;\n                    }\n                }\n            };\n\n            let mut reply_stream = self.reply_internal(final_conversation, session_config, session, cancel_token).await?;\n            while let Some(event) = reply_stream.next().await {\n                yield event?;\n            }\n        }))\n    }\n\n    async fn reply_internal(\n        &self,\n        conversation: Conversation,\n        session_config: SessionConfig,\n        session: Session,\n        cancel_token: Option<CancellationToken>,\n    ) -> Result<BoxStream<'_, Result<AgentEvent>>> {\n        let context = self\n            .prepare_reply_context(conversation, &session.working_dir)\n            .await?;\n        let ReplyContext {\n            mut conversation,\n            mut tools,\n            mut toolshim_tools,\n            mut system_prompt,\n            goose_mode,\n            initial_messages,\n        } = context;\n        let reply_span = tracing::Span::current();\n        self.reset_retry_attempts().await;\n\n        let provider = self.provider().await?;\n        let session_id = session_config.id.clone();\n        let working_dir = session.working_dir.clone();\n        tokio::spawn(async move {\n            if let Err(e) = SessionManager::maybe_update_name(&session_id, provider).await {\n                warn!(\"Failed to generate session description: {}\", e);\n            }\n        });\n\n        Ok(Box::pin(async_stream::try_stream! {\n            let _ = reply_span.enter();\n            let mut turns_taken = 0u32;\n            let max_turns = session_config.max_turns.unwrap_or(DEFAULT_MAX_TURNS);\n            let mut compaction_attempts = 0;\n\n            loop {\n                if is_token_cancelled(&cancel_token) {\n                    break;\n                }\n\n                if let Some(final_output_tool) = self.final_output_tool.lock().await.as_ref() {\n                    if final_output_tool.final_output.is_some() {\n                        let final_event = AgentEvent::Message(\n                            Message::assistant().with_text(final_output_tool.final_output.clone().unwrap())\n                        );\n                        yield final_event;\n                        break;\n                    }\n                }\n\n                turns_taken += 1;\n                if turns_taken > max_turns {\n                    yield AgentEvent::Message(\n                        Message::assistant().with_text(\n                            \"I've reached the maximum number of actions I can do without user input. Would you like me to continue?\"\n                        )\n                    );\n                    break;\n                }\n\n                let conversation_with_moim = super::moim::inject_moim(\n                    conversation.clone(),\n                    &self.extension_manager,\n                ).await;\n\n                let mut stream = Self::stream_response_from_provider(\n                    self.provider().await?,\n                    &system_prompt,\n                    conversation_with_moim.messages(),\n                    &tools,\n                    &toolshim_tools,\n                ).await?;\n\n                let mut no_tools_called = true;\n                let mut messages_to_add = Conversation::default();\n                let mut tools_updated = false;\n                let mut did_recovery_compact_this_iteration = false;\n\n                while let Some(next) = stream.next().await {\n                    if is_token_cancelled(&cancel_token) {\n                        break;\n                    }\n\n                    match next {\n                        Ok((response, usage)) => {\n                            compaction_attempts = 0;\n\n                            // Emit model change event if provider is lead-worker\n                            let provider = self.provider().await?;\n                            if let Some(lead_worker) = provider.as_lead_worker() {\n                                if let Some(ref usage) = usage {\n                                    let active_model = usage.model.clone();\n                                    let (lead_model, worker_model) = lead_worker.get_model_info();\n                                    let mode = if active_model == lead_model {\n                                        \"lead\"\n                                    } else if active_model == worker_model {\n                                        \"worker\"\n                                    } else {\n                                        \"unknown\"\n                                    };\n\n                                    yield AgentEvent::ModelChange {\n                                        model: active_model,\n                                        mode: mode.to_string(),\n                                    };\n                                }\n                            }\n\n                            if let Some(ref usage) = usage {\n                                Self::update_session_metrics(&session_config, usage, false).await?;\n                            }\n\n                            if let Some(response) = response {\n                                let ToolCategorizeResult {\n                                    frontend_requests,\n                                    remaining_requests,\n                                    filtered_response,\n                                } = self.categorize_tools(&response, &tools).await;\n\n                                yield AgentEvent::Message(filtered_response.clone());\n                                tokio::task::yield_now().await;\n\n                                let num_tool_requests = frontend_requests.len() + remaining_requests.len();\n                                if num_tool_requests == 0 {\n                                    messages_to_add.push(response.clone());\n                                    continue;\n                                }\n\n                                let tool_response_messages: Vec<Arc<Mutex<Message>>> = (0..num_tool_requests)\n                                    .map(|_| Arc::new(Mutex::new(Message::user().with_id(\n                                        format!(\"msg_{}\", Uuid::new_v4())\n                                    ))))\n                                    .collect();\n\n                                let mut request_to_response_map = HashMap::new();\n                                let mut request_metadata: HashMap<String, Option<ProviderMetadata>> = HashMap::new();\n                                for (idx, request) in frontend_requests.iter().chain(remaining_requests.iter()).enumerate() {\n                                    request_to_response_map.insert(request.id.clone(), tool_response_messages[idx].clone());\n                                    request_metadata.insert(request.id.clone(), request.metadata.clone());\n                                }\n\n                                for (idx, request) in frontend_requests.iter().enumerate() {\n                                    let mut frontend_tool_stream = self.handle_frontend_tool_request(\n                                        request,\n                                        tool_response_messages[idx].clone(),\n                                    );\n\n                                    while let Some(msg) = frontend_tool_stream.try_next().await? {\n                                        yield AgentEvent::Message(msg);\n                                    }\n                                }\n                                if goose_mode == GooseMode::Chat {\n                                    // Skip all remaining tool calls in chat mode\n                                    for request in remaining_requests.iter() {\n                                        if let Some(response_msg) = request_to_response_map.get(&request.id) {\n                                            let mut response = response_msg.lock().await;\n                                            *response = response.clone().with_tool_response_with_metadata(\n                                                request.id.clone(),\n                                                Ok(CallToolResult {\n                                                    content: vec![Content::text(CHAT_MODE_TOOL_SKIPPED_RESPONSE)],\n                                                    structured_content: None,\n                                                    is_error: Some(false),\n                                                    meta: None,\n                                                }),\n                                                request.metadata.as_ref(),\n                                            );\n                                        }\n                                    }\n                                } else {\n                                    // Run all tool inspectors\n                                    let inspection_results = self.tool_inspection_manager\n                                        .inspect_tools(\n                                            &remaining_requests,\n                                            conversation.messages(),\n                                        )\n                                        .await?;\n\n                                    let permission_check_result = self.tool_inspection_manager\n                                        .process_inspection_results_with_permission_inspector(\n                                            &remaining_requests,\n                                            &inspection_results,\n                                        )\n                                        .unwrap_or_else(|| {\n                                            let mut result = PermissionCheckResult {\n                                                approved: vec![],\n                                                needs_approval: vec![],\n                                                denied: vec![],\n                                            };\n                                            result.needs_approval.extend(remaining_requests.iter().cloned());\n                                            result\n                                        });\n\n                                    // Track extension requests\n                                    let mut enable_extension_request_ids = vec![];\n                                    for request in &remaining_requests {\n                                        if let Ok(tool_call) = &request.tool_call {\n                                            if tool_call.name == MANAGE_EXTENSIONS_TOOL_NAME_COMPLETE {\n                                                enable_extension_request_ids.push(request.id.clone());\n                                            }\n                                        }\n                                    }\n\n                                    let mut tool_futures = self.handle_approved_and_denied_tools(\n                                        &permission_check_result,\n                                        &request_to_response_map,\n                                        cancel_token.clone(),\n                                        &session,\n                                    ).await?;\n\n                                    let tool_futures_arc = Arc::new(Mutex::new(tool_futures));\n\n                                    let mut tool_approval_stream = self.handle_approval_tool_requests(\n                                        &permission_check_result.needs_approval,\n                                        tool_futures_arc.clone(),\n                                        &request_to_response_map,\n                                        cancel_token.clone(),\n                                        &session,\n                                        &inspection_results,\n                                    );\n\n                                    while let Some(msg) = tool_approval_stream.try_next().await? {\n                                        yield AgentEvent::Message(msg);\n                                    }\n\n                                    tool_futures = {\n                                        let mut futures_lock = tool_futures_arc.lock().await;\n                                        futures_lock.drain(..).collect::<Vec<_>>()\n                                    };\n\n                                    let with_id = tool_futures\n                                        .into_iter()\n                                        .map(|(request_id, stream)| {\n                                            stream.map(move |item| (request_id.clone(), item))\n                                        })\n                                        .collect::<Vec<_>>();\n\n                                    let mut combined = stream::select_all(with_id);\n                                    let mut all_install_successful = true;\n\n                                    while let Some((request_id, item)) = combined.next().await {\n                                        if is_token_cancelled(&cancel_token) {\n                                            break;\n                                        }\n\n                                        for msg in Self::drain_elicitation_messages(&session_config.id).await {\n                                            yield AgentEvent::Message(msg);\n                                        }\n\n                                        match item {\n                                            ToolStreamItem::Result(output) => {\n                                                if enable_extension_request_ids.contains(&request_id)\n                                                    && output.is_err()\n                                                {\n                                                    all_install_successful = false;\n                                                }\n                                                if let Some(response_msg) = request_to_response_map.get(&request_id) {\n                                                    let metadata = request_metadata.get(&request_id).and_then(|m| m.as_ref());\n                                                    let mut response = response_msg.lock().await;\n                                                    *response = response.clone().with_tool_response_with_metadata(request_id, output, metadata);\n                                                }\n                                            }\n                                            ToolStreamItem::Message(msg) => {\n                                                yield AgentEvent::McpNotification((request_id, msg));\n                                            }\n                                        }\n                                    }\n\n                                    // check for remaining elicitation messages after all tools complete\n                                    for msg in Self::drain_elicitation_messages(&session_config.id).await {\n                                        yield AgentEvent::Message(msg);\n                                    }\n\n                                    if all_install_successful && !enable_extension_request_ids.is_empty() {\n                                        if let Err(e) = self.save_extension_state(&session_config).await {\n                                            warn!(\"Failed to save extension state after runtime changes: {}\", e);\n                                        }\n                                        tools_updated = true;\n                                    }\n                                }\n\n                                // Preserve thinking content from the original response\n                                // Gemini (and other thinking models) require thinking to be echoed back\n                                let thinking_content: Vec<MessageContent> = response.content.iter()\n                                    .filter(|c| matches!(c, MessageContent::Thinking(_)))\n                                    .cloned()\n                                    .collect();\n                                if !thinking_content.is_empty() {\n                                    let thinking_msg = Message::new(\n                                        response.role.clone(),\n                                        response.created,\n                                        thinking_content,\n                                    ).with_id(format!(\"msg_{}\", Uuid::new_v4()));\n                                    messages_to_add.push(thinking_msg);\n                                }\n\n                                for (idx, request) in frontend_requests.iter().chain(remaining_requests.iter()).enumerate() {\n                                    if request.tool_call.is_ok() {\n                                        let request_msg = Message::assistant()\n                                            .with_id(format!(\"msg_{}\", Uuid::new_v4()))\n                                            .with_tool_request_with_metadata(\n                                                request.id.clone(),\n                                                request.tool_call.clone(),\n                                                request.metadata.as_ref(),\n                                            );\n                                        messages_to_add.push(request_msg);\n                                        let final_response = tool_response_messages[idx]\n                                                                .lock().await.clone();\n                                        yield AgentEvent::Message(final_response.clone());\n                                        messages_to_add.push(final_response);\n                                    }\n                                }\n\n                                no_tools_called = false;\n                            }\n                        }\n                        Err(ref provider_err @ ProviderError::ContextLengthExceeded(_)) => {\n                            crate::posthog::emit_error(provider_err.telemetry_type(), &provider_err.to_string());\n                            compaction_attempts += 1;\n\n                            if compaction_attempts >= 2 {\n                                error!(\"Context limit exceeded after compaction - prompt too large\");\n                                yield AgentEvent::Message(\n                                    Message::assistant().with_system_notification(\n                                        SystemNotificationType::InlineMessage,\n                                        \"Unable to continue: Context limit still exceeded after compaction. Try using a shorter message, a model with a larger context window, or start a new session.\"\n                                    )\n                                );\n                                break;\n                            }\n\n                            yield AgentEvent::Message(\n                                Message::assistant().with_system_notification(\n                                    SystemNotificationType::InlineMessage,\n                                    \"Context limit reached. Compacting to continue conversation...\",\n                                )\n                            );\n                            yield AgentEvent::Message(\n                                Message::assistant().with_system_notification(\n                                    SystemNotificationType::ThinkingMessage,\n                                    COMPACTION_THINKING_TEXT,\n                                )\n                            );\n\n                            match compact_messages(self.provider().await?.as_ref(), &conversation, false).await {\n                                Ok((compacted_conversation, usage)) => {\n                                    SessionManager::replace_conversation(&session_config.id, &compacted_conversation).await?;\n                                    Self::update_session_metrics(&session_config, &usage, true).await?;\n                                    conversation = compacted_conversation;\n                                    did_recovery_compact_this_iteration = true;\n                                    yield AgentEvent::HistoryReplaced(conversation.clone());\n                                    break;\n                                }\n                                Err(e) => {\n                                    crate::posthog::emit_error(\"compaction_failed\", &e.to_string());\n                                    error!(\"Compaction failed: {}\", e);\n                                    break;\n                                }\n                            }\n                        }\n                        Err(ref provider_err) => {\n                            crate::posthog::emit_error(provider_err.telemetry_type(), &provider_err.to_string());\n                            error!(\"Error: {}\", provider_err);\n                            yield AgentEvent::Message(\n                                Message::assistant().with_text(\n                                    format!(\"Ran into this error: {provider_err}.\\n\\nPlease retry if you think this is a transient or recoverable error.\")\n                                )\n                            );\n                            break;\n                        }\n                    }\n                }\n                if tools_updated {\n                    (tools, toolshim_tools, system_prompt) =\n                        self.prepare_tools_and_prompt(&working_dir).await?;\n                }\n                let mut exit_chat = false;\n                if no_tools_called {\n                    if let Some(final_output_tool) = self.final_output_tool.lock().await.as_ref() {\n                        if final_output_tool.final_output.is_none() {\n                            warn!(\"Final output tool has not been called yet. Continuing agent loop.\");\n                            let message = Message::user().with_text(FINAL_OUTPUT_CONTINUATION_MESSAGE);\n                            messages_to_add.push(message.clone());\n                            yield AgentEvent::Message(message);\n                        } else {\n                            let message = Message::assistant().with_text(final_output_tool.final_output.clone().unwrap());\n                            messages_to_add.push(message.clone());\n                            yield AgentEvent::Message(message);\n                            exit_chat = true;\n                        }\n                    } else if did_recovery_compact_this_iteration {\n                        // Avoid setting exit_chat; continue from last user message in the conversation\n                    } else {\n                        match self.handle_retry_logic(&mut conversation, &session_config, &initial_messages).await {\n                            Ok(should_retry) => {\n                                if should_retry {\n                                    info!(\"Retry logic triggered, restarting agent loop\");\n                                } else {\n                                    exit_chat = true;\n                                }\n                            }\n                            Err(e) => {\n                                error!(\"Retry logic failed: {}\", e);\n                                yield AgentEvent::Message(\n                                    Message::assistant().with_text(\n                                        format!(\"Retry logic encountered an error: {}\", e)\n                                    )\n                                );\n                                exit_chat = true;\n                            }\n                        }\n                    }\n                }\n\n                for msg in &messages_to_add {\n                    SessionManager::add_message(&session_config.id, msg).await?;\n                }\n                conversation.extend(messages_to_add);\n                if exit_chat {\n                    break;\n                }\n\n                tokio::task::yield_now().await;\n            }\n        }))\n    }\n\n    pub async fn extend_system_prompt(&self, instruction: String) {\n        let mut prompt_manager = self.prompt_manager.lock().await;\n        prompt_manager.add_system_prompt_extra(instruction);\n    }\n\n    pub async fn update_provider(\n        &self,\n        provider: Arc<dyn Provider>,\n        session_id: &str,\n    ) -> Result<()> {\n        let mut current_provider = self.provider.lock().await;\n        *current_provider = Some(provider.clone());\n\n        SessionManager::update_session(session_id)\n            .provider_name(provider.get_name())\n            .model_config(provider.get_model_config())\n            .apply()\n            .await\n            .context(\"Failed to persist provider config to session\")\n    }\n\n    /// Override the system prompt with a custom template\n    pub async fn override_system_prompt(&self, template: String) {\n        let mut prompt_manager = self.prompt_manager.lock().await;\n        prompt_manager.set_system_prompt_override(template);\n    }\n\n    pub async fn list_extension_prompts(&self) -> HashMap<String, Vec<Prompt>> {\n        self.extension_manager\n            .list_prompts(CancellationToken::default())\n            .await\n            .expect(\"Failed to list prompts\")\n    }\n\n    pub async fn get_prompt(&self, name: &str, arguments: Value) -> Result<GetPromptResult> {\n        // First find which extension has this prompt\n        let prompts = self\n            .extension_manager\n            .list_prompts(CancellationToken::default())\n            .await\n            .map_err(|e| anyhow!(\"Failed to list prompts: {}\", e))?;\n\n        if let Some(extension) = prompts\n            .iter()\n            .find(|(_, prompt_list)| prompt_list.iter().any(|p| p.name == name))\n            .map(|(extension, _)| extension)\n        {\n            return self\n                .extension_manager\n                .get_prompt(extension, name, arguments, CancellationToken::default())\n                .await\n                .map_err(|e| anyhow!(\"Failed to get prompt: {}\", e));\n        }\n\n        Err(anyhow!(\"Prompt '{}' not found\", name))\n    }\n\n    pub async fn get_plan_prompt(&self) -> Result<String> {\n        let tools = self.extension_manager.get_prefixed_tools(None).await?;\n        let tools_info = tools\n            .into_iter()\n            .map(|tool| {\n                ToolInfo::new(\n                    &tool.name,\n                    tool.description\n                        .as_ref()\n                        .map(|d| d.as_ref())\n                        .unwrap_or_default(),\n                    get_parameter_names(&tool),\n                    None,\n                )\n            })\n            .collect();\n\n        let plan_prompt = self.extension_manager.get_planning_prompt(tools_info).await;\n\n        Ok(plan_prompt)\n    }\n\n    pub async fn handle_tool_result(&self, id: String, result: ToolResult<CallToolResult>) {\n        if let Err(e) = self.tool_result_tx.send((id, result)).await {\n            error!(\"Failed to send tool result: {}\", e);\n        }\n    }\n\n    pub async fn create_recipe(&self, mut messages: Conversation) -> Result<Recipe> {\n        tracing::info!(\"Starting recipe creation with {} messages\", messages.len());\n\n        let extensions_info = self.extension_manager.get_extensions_info().await;\n        tracing::debug!(\"Retrieved {} extensions info\", extensions_info.len());\n        let (extension_count, tool_count) =\n            self.extension_manager.get_extension_and_tool_counts().await;\n\n        // Get model name from provider\n        let provider = self.provider().await.map_err(|e| {\n            tracing::error!(\"Failed to get provider for recipe creation: {}\", e);\n            e\n        })?;\n        let model_config = provider.get_model_config();\n        let model_name = &model_config.model_name;\n        tracing::debug!(\"Using model: {}\", model_name);\n\n        let prompt_manager = self.prompt_manager.lock().await;\n        let system_prompt = prompt_manager\n            .builder()\n            .with_extensions(extensions_info.into_iter())\n            .with_frontend_instructions(self.frontend_instructions.lock().await.clone())\n            .with_extension_and_tool_counts(extension_count, tool_count)\n            .build();\n\n        let recipe_prompt = prompt_manager.get_recipe_prompt().await;\n        let tools = self\n            .extension_manager\n            .get_prefixed_tools(None)\n            .await\n            .map_err(|e| {\n                tracing::error!(\"Failed to get tools for recipe creation: {}\", e);\n                e\n            })?;\n\n        messages.push(Message::user().with_text(recipe_prompt));\n\n        let (messages, issues) = fix_conversation(messages);\n        if !issues.is_empty() {\n            issues\n                .iter()\n                .for_each(|issue| tracing::warn!(recipe.conversation.issue = issue));\n        }\n\n        tracing::debug!(\n            \"Added recipe prompt to messages, total messages: {}\",\n            messages.len()\n        );\n\n        tracing::info!(\"Calling provider to generate recipe content\");\n        let (result, _usage) = self\n            .provider\n            .lock()\n            .await\n            .as_ref()\n            .ok_or_else(|| {\n                let error = anyhow!(\"Provider not available during recipe creation\");\n                tracing::error!(\"{}\", error);\n                error\n            })?\n            .complete(&system_prompt, messages.messages(), &tools)\n            .await\n            .map_err(|e| {\n                tracing::error!(\"Provider completion failed during recipe creation: {}\", e);\n                e\n            })?;\n\n        let content = result.as_concat_text();\n        tracing::debug!(\n            \"Provider returned content with {} characters\",\n            content.len()\n        );\n\n        // the response may be contained in ```json ```, strip that before parsing json\n        let re = Regex::new(r\"(?s)```[^\\n]*\\n(.*?)\\n```\").unwrap();\n        let clean_content = re\n            .captures(&content)\n            .and_then(|caps| caps.get(1).map(|m| m.as_str()))\n            .unwrap_or(&content)\n            .trim()\n            .to_string();\n\n        let (instructions, activities) =\n            if let Ok(json_content) = serde_json::from_str::<Value>(&clean_content) {\n                let instructions = json_content\n                    .get(\"instructions\")\n                    .ok_or_else(|| anyhow!(\"Missing 'instructions' in json response\"))?\n                    .as_str()\n                    .ok_or_else(|| anyhow!(\"instructions' is not a string\"))?\n                    .to_string();\n\n                let activities = json_content\n                    .get(\"activities\")\n                    .ok_or_else(|| anyhow!(\"Missing 'activities' in json response\"))?\n                    .as_array()\n                    .ok_or_else(|| anyhow!(\"'activities' is not an array'\"))?\n                    .iter()\n                    .map(|act| {\n                        act.as_str()\n                            .map(|s| s.to_string())\n                            .ok_or(anyhow!(\"'activities' array element is not a string\"))\n                    })\n                    .collect::<Result<_, _>>()?;\n\n                (instructions, activities)\n            } else {\n                tracing::warn!(\"Failed to parse JSON, falling back to string parsing\");\n                // If we can't get valid JSON, try string parsing\n                // Use split_once to get the content after \"Instructions:\".\n                let after_instructions = content\n                    .split_once(\"instructions:\")\n                    .map(|(_, rest)| rest)\n                    .unwrap_or(&content);\n\n                // Split once more to separate instructions from activities.\n                let (instructions_part, activities_text) = after_instructions\n                    .split_once(\"activities:\")\n                    .unwrap_or((after_instructions, \"\"));\n\n                let instructions = instructions_part\n                    .trim_end_matches(|c: char| c.is_whitespace() || c == '#')\n                    .trim()\n                    .to_string();\n                let activities_text = activities_text.trim();\n\n                // Regex to remove bullet markers or numbers with an optional dot.\n                let bullet_re = Regex::new(r\"^[•\\-*\\d]+\\.?\\s*\").expect(\"Invalid regex\");\n\n                // Process each line in the activities section.\n                let activities: Vec<String> = activities_text\n                    .lines()\n                    .map(|line| bullet_re.replace(line, \"\").to_string())\n                    .map(|s| s.trim().to_string())\n                    .filter(|line| !line.is_empty())\n                    .collect();\n\n                (instructions, activities)\n            };\n\n        let extension_configs = get_enabled_extensions();\n\n        let author = Author {\n            contact: std::env::var(\"USER\")\n                .or_else(|_| std::env::var(\"USERNAME\"))\n                .ok(),\n            metadata: None,\n        };\n\n        // Ideally we'd get the name of the provider we are using from the provider itself,\n        // but it doesn't know and the plumbing looks complicated.\n        let config = Config::global();\n        let provider_name: String = config\n            .get_goose_provider()\n            .expect(\"No provider configured. Run 'goose configure' first\");\n\n        let settings = Settings {\n            goose_provider: Some(provider_name.clone()),\n            goose_model: Some(model_name.clone()),\n            temperature: Some(model_config.temperature.unwrap_or(0.0)),\n        };\n\n        tracing::debug!(\n            \"Building recipe with {} activities and {} extensions\",\n            activities.len(),\n            extension_configs.len()\n        );\n\n        let (title, description) =\n            if let Ok(json_content) = serde_json::from_str::<Value>(&clean_content) {\n                let title = json_content\n                    .get(\"title\")\n                    .and_then(|t| t.as_str())\n                    .unwrap_or(\"Custom recipe from chat\")\n                    .to_string();\n\n                let description = json_content\n                    .get(\"description\")\n                    .and_then(|d| d.as_str())\n                    .unwrap_or(\"a custom recipe instance from this chat session\")\n                    .to_string();\n\n                (title, description)\n            } else {\n                (\n                    \"Custom recipe from chat\".to_string(),\n                    \"a custom recipe instance from this chat session\".to_string(),\n                )\n            };\n\n        let recipe = Recipe::builder()\n            .title(title)\n            .description(description)\n            .instructions(instructions)\n            .activities(activities)\n            .extensions(extension_configs)\n            .settings(settings)\n            .author(author)\n            .build()\n            .map_err(|e| {\n                tracing::error!(\"Failed to build recipe: {}\", e);\n                anyhow!(\"Recipe build failed: {}\", e)\n            })?;\n\n        tracing::info!(\"Recipe creation completed successfully\");\n        Ok(recipe)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use crate::recipe::Response;\n\n    #[tokio::test]\n    async fn test_add_final_output_tool() -> Result<()> {\n        let agent = Agent::new();\n\n        let response = Response {\n            json_schema: Some(serde_json::json!({\n                \"type\": \"object\",\n                \"properties\": {\n                    \"result\": {\"type\": \"string\"}\n                }\n            })),\n        };\n\n        agent.add_final_output_tool(response).await;\n\n        let tools = agent.list_tools(None).await;\n        let final_output_tool = tools\n            .iter()\n            .find(|tool| tool.name == FINAL_OUTPUT_TOOL_NAME);\n\n        assert!(\n            final_output_tool.is_some(),\n            \"Final output tool should be present after adding\"\n        );\n\n        let prompt_manager = agent.prompt_manager.lock().await;\n        let system_prompt = prompt_manager.builder().build();\n\n        let final_output_tool_ref = agent.final_output_tool.lock().await;\n        let final_output_tool_system_prompt =\n            final_output_tool_ref.as_ref().unwrap().system_prompt();\n        assert!(system_prompt.contains(&final_output_tool_system_prompt));\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_tool_inspection_manager_has_all_inspectors() -> Result<()> {\n        let agent = Agent::new();\n\n        // Verify that the tool inspection manager has all expected inspectors\n        let inspector_names = agent.tool_inspection_manager.inspector_names();\n\n        assert!(\n            inspector_names.contains(&\"repetition\"),\n            \"Tool inspection manager should contain repetition inspector\"\n        );\n        assert!(\n            inspector_names.contains(&\"permission\"),\n            \"Tool inspection manager should contain permission inspector\"\n        );\n        assert!(\n            inspector_names.contains(&\"security\"),\n            \"Tool inspection manager should contain security inspector\"\n        );\n\n        Ok(())\n    }\n}\n"
                  },
                  "annotations": {
                    "audience": [
                      "assistant"
                    ]
                  }
                },
                {
                  "type": "text",
                  "text": "### /Users/baxen/Development/goose/crates/goose/src/agents/agent.rs\n```rust\n1: use std::collections::HashMap;\n2: use std::future::Future;\n3: use std::pin::Pin;\n4: use std::sync::Arc;\n5: \n6: use anyhow::{anyhow, Context, Result};\n7: use futures::stream::BoxStream;\n8: use futures::{stream, FutureExt, Stream, StreamExt, TryStreamExt};\n9: use uuid::Uuid;\n10: \n11: use super::final_output_tool::FinalOutputTool;\n12: use super::platform_tools;\n13: use super::tool_execution::{ToolCallResult, CHAT_MODE_TOOL_SKIPPED_RESPONSE, DECLINED_RESPONSE};\n14: use crate::action_required_manager::ActionRequiredManager;\n15: use crate::agents::extension::{ExtensionConfig, ExtensionResult, ToolInfo};\n16: use crate::agents::extension_manager::{get_parameter_names, ExtensionManager};\n17: use crate::agents::extension_manager_extension::MANAGE_EXTENSIONS_TOOL_NAME_COMPLETE;\n18: use crate::agents::final_output_tool::{FINAL_OUTPUT_CONTINUATION_MESSAGE, FINAL_OUTPUT_TOOL_NAME};\n19: use crate::agents::platform_tools::PLATFORM_MANAGE_SCHEDULE_TOOL_NAME;\n20: use crate::agents::prompt_manager::PromptManager;\n21: use crate::agents::retry::{RetryManager, RetryResult};\n22: use crate::agents::subagent_task_config::TaskConfig;\n23: use crate::agents::subagent_tool::{\n24:     create_subagent_tool, handle_subagent_tool, SUBAGENT_TOOL_NAME,\n25: };\n26: use crate::agents::types::SessionConfig;\n27: use crate::agents::types::{FrontendTool, SharedProvider, ToolResultReceiver};\n28: use crate::config::{get_enabled_extensions, Config, GooseMode};\n29: use crate::context_mgmt::{\n30:     check_if_compaction_needed, compact_messages, DEFAULT_COMPACTION_THRESHOLD,\n31: };\n32: use crate::conversation::message::{\n33:     ActionRequiredData, Message, MessageContent, ProviderMetadata, SystemNotificationType,\n34:     ToolRequest,\n35: };\n36: use crate::conversation::{debug_conversation_fix, fix_conversation, Conversation};\n37: use crate::mcp_utils::ToolResult;\n38: use crate::permission::permission_inspector::PermissionInspector;\n39: use crate::permission::permission_judge::PermissionCheckResult;\n40: use crate::permission::PermissionConfirmation;\n41: use crate::providers::base::Provider;\n42: use crate::providers::errors::ProviderError;\n43: use crate::recipe::{Author, Recipe, Response, Settings, SubRecipe};\n44: use crate::scheduler_trait::SchedulerTrait;\n45: use crate::security::security_inspector::SecurityInspector;\n46: use crate::session::extension_data::{EnabledExtensionsState, ExtensionState};\n47: use crate::session::{Session, SessionManager, SessionType};\n48: use crate::tool_inspection::ToolInspectionManager;\n49: use crate::tool_monitor::RepetitionInspector;\n50: use crate::utils::is_token_cancelled;\n51: use regex::Regex;\n52: use rmcp::model::{\n53:     CallToolRequestParam, CallToolResult, Content, ErrorCode, ErrorData, GetPromptResult, Prompt,\n54:     ServerNotification, Tool,\n55: };\n56: use serde_json::Value;\n57: use tokio::sync::{mpsc, Mutex};\n58: use tokio_util::sync::CancellationToken;\n59: use tracing::{debug, error, info, instrument, warn};\n60: \n61: const DEFAULT_MAX_TURNS: u32 = 1000;\n62: const COMPACTION_THINKING_TEXT: &str = \"goose is compacting the conversation...\";\n63: \n64: /// Context needed for the reply function\n65: pub struct ReplyContext {\n66:     pub conversation: Conversation,\n67:     pub tools: Vec<Tool>,\n68:     pub toolshim_tools: Vec<Tool>,\n69:     pub system_prompt: String,\n70:     pub goose_mode: GooseMode,\n71:     pub initial_messages: Vec<Message>,\n72: }\n73: \n74: pub struct ToolCategorizeResult {\n75:     pub frontend_requests: Vec<ToolRequest>,\n76:     pub remaining_requests: Vec<ToolRequest>,\n77:     pub filtered_response: Message,\n78: }\n79: \n80: /// The main goose Agent\n81: pub struct Agent {\n82:     pub(super) provider: SharedProvider,\n83: \n84:     pub extension_manager: Arc<ExtensionManager>,\n85:     pub(super) sub_recipes: Mutex<HashMap<String, SubRecipe>>,\n86:     pub(super) final_output_tool: Arc<Mutex<Option<FinalOutputTool>>>,\n87:     pub(super) frontend_tools: Mutex<HashMap<String, FrontendTool>>,\n88:     pub(super) frontend_instructions: Mutex<Option<String>>,\n89:     pub(super) prompt_manager: Mutex<PromptManager>,\n90:     pub(super) confirmation_tx: mpsc::Sender<(String, PermissionConfirmation)>,\n91:     pub(super) confirmation_rx: Mutex<mpsc::Receiver<(String, PermissionConfirmation)>>,\n92:     pub(super) tool_result_tx: mpsc::Sender<(String, ToolResult<CallToolResult>)>,\n93:     pub(super) tool_result_rx: ToolResultReceiver,\n94: \n95:     pub(super) scheduler_service: Mutex<Option<Arc<dyn SchedulerTrait>>>,\n96:     pub(super) retry_manager: RetryManager,\n97:     pub(super) tool_inspection_manager: ToolInspectionManager,\n98: }\n99: \n100: #[derive(Clone, Debug)]\n101: pub enum AgentEvent {\n102:     Message(Message),\n103:     McpNotification((String, ServerNotification)),\n104:     ModelChange { model: String, mode: String },\n105:     HistoryReplaced(Conversation),\n106: }\n107: \n108: impl Default for Agent {\n109:     fn default() -> Self {\n110:         Self::new()\n111:     }\n112: }\n113: \n114: pub enum ToolStreamItem<T> {\n115:     Message(ServerNotification),\n116:     Result(T),\n117: }\n118: \n119: pub type ToolStream =\n120:     Pin<Box<dyn Stream<Item = ToolStreamItem<ToolResult<CallToolResult>>> + Send>>;\n121: \n122: // tool_stream combines a stream of ServerNotifications with a future representing the\n123: // final result of the tool call. MCP notifications are not request-scoped, but\n124: // this lets us capture all notifications emitted during the tool call for\n125: // simpler consumption\n126: pub fn tool_stream<S, F>(rx: S, done: F) -> ToolStream\n127: where\n128:     S: Stream<Item = ServerNotification> + Send + Unpin + 'static,\n129:     F: Future<Output = ToolResult<CallToolResult>> + Send + 'static,\n130: {\n131:     Box::pin(async_stream::stream! {\n132:         tokio::pin!(done);\n133:         let mut rx = rx;\n134: \n135:         loop {\n136:             tokio::select! {\n137:                 Some(msg) = rx.next() => {\n138:                     yield ToolStreamItem::Message(msg);\n139:                 }\n140:                 r = &mut done => {\n141:                     yield ToolStreamItem::Result(r);\n142:                     break;\n143:                 }\n144:             }\n145:         }\n146:     })\n147: }\n148: \n149: impl Agent {\n150:     pub fn new() -> Self {\n151:         // Create channels with buffer size 32 (adjust if needed)\n152:         let (confirm_tx, confirm_rx) = mpsc::channel(32);\n153:         let (tool_tx, tool_rx) = mpsc::channel(32);\n154:         let provider = Arc::new(Mutex::new(None));\n155: \n156:         Self {\n157:             provider: provider.clone(),\n158:             extension_manager: Arc::new(ExtensionManager::new(provider.clone())),\n159:             sub_recipes: Mutex::new(HashMap::new()),\n160:             final_output_tool: Arc::new(Mutex::new(None)),\n161:             frontend_tools: Mutex::new(HashMap::new()),\n162:             frontend_instructions: Mutex::new(None),\n163:             prompt_manager: Mutex::new(PromptManager::new()),\n164:             confirmation_tx: confirm_tx,\n165:             confirmation_rx: Mutex::new(confirm_rx),\n166:             tool_result_tx: tool_tx,\n167:             tool_result_rx: Arc::new(Mutex::new(tool_rx)),\n168:             scheduler_service: Mutex::new(None),\n169:             retry_manager: RetryManager::new(),\n170:             tool_inspection_manager: Self::create_default_tool_inspection_manager(),\n171:         }\n172:     }\n173: \n174:     /// Create a tool inspection manager with default inspectors\n175:     fn create_default_tool_inspection_manager() -> ToolInspectionManager {\n176:         let mut tool_inspection_manager = ToolInspectionManager::new();\n177: \n178:         // Add security inspector (highest priority - runs first)\n179:         tool_inspection_manager.add_inspector(Box::new(SecurityInspector::new()));\n180: \n181:         // Add permission inspector (medium-high priority)\n182:         // Note: mode will be updated dynamically based on session config\n183:         tool_inspection_manager.add_inspector(Box::new(PermissionInspector::new(\n184:             GooseMode::SmartApprove,\n185:             std::collections::HashSet::new(), // readonly tools - will be populated from extension manager\n186:             std::collections::HashSet::new(), // regular tools - will be populated from extension manager\n187:         )));\n188: \n189:         // Add repetition inspector (lower priority - basic repetition checking)\n190:         tool_inspection_manager.add_inspector(Box::new(RepetitionInspector::new(None)));\n191: \n192:         tool_inspection_manager\n193:     }\n194: \n195:     /// Reset the retry attempts counter to 0\n196:     pub async fn reset_retry_attempts(&self) {\n197:         self.retry_manager.reset_attempts().await;\n198:     }\n199: \n200:     /// Increment the retry attempts counter and return the new value\n201:     pub async fn increment_retry_attempts(&self) -> u32 {\n202:         self.retry_manager.increment_attempts().await\n203:     }\n204: \n205:     /// Get the current retry attempts count\n206:     pub async fn get_retry_attempts(&self) -> u32 {\n207:         self.retry_manager.get_attempts().await\n208:     }\n209: \n210:     async fn handle_retry_logic(\n211:         &self,\n212:         messages: &mut Conversation,\n213:         session_config: &SessionConfig,\n214:         initial_messages: &[Message],\n215:     ) -> Result<bool> {\n216:         let result = self\n217:             .retry_manager\n218:             .handle_retry_logic(\n219:                 messages,\n220:                 session_config,\n221:                 initial_messages,\n222:                 &self.final_output_tool,\n223:             )\n224:             .await?;\n225: \n226:         match result {\n227:             RetryResult::Retried => Ok(true),\n228:             RetryResult::Skipped\n229:             | RetryResult::MaxAttemptsReached\n230:             | RetryResult::SuccessChecksPassed => Ok(false),\n231:         }\n232:     }\n233:     async fn drain_elicitation_messages(session_id: &str) -> Vec<Message> {\n234:         let mut messages = Vec::new();\n235:         let mut elicitation_rx = ActionRequiredManager::global().request_rx.lock().await;\n236:         while let Ok(elicitation_message) = elicitation_rx.try_recv() {\n237:             if let Err(e) = SessionManager::add_message(session_id, &elicitation_message).await {\n238:                 warn!(\"Failed to save elicitation message to session: {}\", e);\n239:             }\n240:             messages.push(elicitation_message);\n241:         }\n242:         messages\n243:     }\n244: \n245:     async fn prepare_reply_context(\n246:         &self,\n247:         unfixed_conversation: Conversation,\n248:         working_dir: &std::path::Path,\n249:     ) -> Result<ReplyContext> {\n250:         let unfixed_messages = unfixed_conversation.messages().clone();\n251:         let (conversation, issues) = fix_conversation(unfixed_conversation.clone());\n252:         if !issues.is_empty() {\n253:             debug!(\n254:                 \"Conversation issue fixed: {}\",\n255:                 debug_conversation_fix(\n256:                     unfixed_messages.as_slice(),\n257:                     conversation.messages(),\n258:                     &issues\n259:                 )\n260:             );\n261:         }\n262:         let initial_messages = conversation.messages().clone();\n263:         let config = Config::global();\n264: \n265:         let (tools, toolshim_tools, system_prompt) =\n266:             self.prepare_tools_and_prompt(working_dir).await?;\n267:         let goose_mode = config.get_goose_mode().unwrap_or(GooseMode::Auto);\n268: \n269:         self.tool_inspection_manager\n270:             .update_permission_inspector_mode(goose_mode)\n271:             .await;\n272: \n273:         Ok(ReplyContext {\n274:             conversation,\n275:             tools,\n276:             toolshim_tools,\n277:             system_prompt,\n278:             goose_mode,\n279:             initial_messages,\n280:         })\n281:     }\n282: \n283:     async fn categorize_tools(\n284:         &self,\n285:         response: &Message,\n286:         tools: &[rmcp::model::Tool],\n287:     ) -> ToolCategorizeResult {\n288:         // Categorize tool requests\n289:         let (frontend_requests, remaining_requests, filtered_response) =\n290:             self.categorize_tool_requests(response, tools).await;\n291: \n292:         ToolCategorizeResult {\n293:             frontend_requests,\n294:             remaining_requests,\n295:             filtered_response,\n296:         }\n297:     }\n298: \n299:     async fn handle_approved_and_denied_tools(\n300:         &self,\n301:         permission_check_result: &PermissionCheckResult,\n302:         request_to_response_map: &HashMap<String, Arc<Mutex<Message>>>,\n303:         cancel_token: Option<tokio_util::sync::CancellationToken>,\n304:         session: &Session,\n305:     ) -> Result<Vec<(String, ToolStream)>> {\n306:         let mut tool_futures: Vec<(String, ToolStream)> = Vec::new();\n307: \n308:         // Handle pre-approved and read-only tools\n309:         for request in &permission_check_result.approved {\n310:             if let Ok(tool_call) = request.tool_call.clone() {\n311:                 let (req_id, tool_result) = self\n312:                     .dispatch_tool_call(\n313:                         tool_call,\n314:                         request.id.clone(),\n315:                         cancel_token.clone(),\n316:                         session,\n317:                     )\n318:                     .await;\n319: \n320:                 tool_futures.push((\n321:                     req_id,\n322:                     match tool_result {\n323:                         Ok(result) => tool_stream(\n324:                             result\n325:                                 .notification_stream\n326:                                 .unwrap_or_else(|| Box::new(stream::empty())),\n327:                             result.result,\n328:                         ),\n329:                         Err(e) => {\n330:                             tool_stream(Box::new(stream::empty()), futures::future::ready(Err(e)))\n331:                         }\n332:                     },\n333:                 ));\n334:             }\n335:         }\n336: \n337:         Self::handle_denied_tools(permission_check_result, request_to_response_map).await;\n338:         Ok(tool_futures)\n339:     }\n340: \n341:     async fn handle_denied_tools(\n342:         permission_check_result: &PermissionCheckResult,\n343:         request_to_response_map: &HashMap<String, Arc<Mutex<Message>>>,\n344:     ) {\n345:         for request in &permission_check_result.denied {\n346:             if let Some(response_msg) = request_to_response_map.get(&request.id) {\n347:                 let mut response = response_msg.lock().await;\n348:                 *response = response.clone().with_tool_response_with_metadata(\n349:                     request.id.clone(),\n350:                     Ok(CallToolResult {\n351:                         content: vec![rmcp::model::Content::text(DECLINED_RESPONSE)],\n352:                         structured_content: None,\n353:                         is_error: Some(true),\n354:                         meta: None,\n355:                     }),\n356:                     request.metadata.as_ref(),\n357:                 );\n358:             }\n359:         }\n360:     }\n361: \n362:     pub async fn set_scheduler(&self, scheduler: Arc<dyn SchedulerTrait>) {\n363:         let mut scheduler_service = self.scheduler_service.lock().await;\n364:         *scheduler_service = Some(scheduler);\n365:     }\n366: \n367:     /// Get a reference count clone to the provider\n368:     pub async fn provider(&self) -> Result<Arc<dyn Provider>, anyhow::Error> {\n369:         match &*self.provider.lock().await {\n370:             Some(provider) => Ok(Arc::clone(provider)),\n371:             None => Err(anyhow!(\"Provider not set\")),\n372:         }\n373:     }\n374: \n375:     /// Check if a tool is a frontend tool\n376:     pub async fn is_frontend_tool(&self, name: &str) -> bool {\n377:         self.frontend_tools.lock().await.contains_key(name)\n378:     }\n379: \n380:     /// Get a reference to a frontend tool\n381:     pub async fn get_frontend_tool(&self, name: &str) -> Option<FrontendTool> {\n382:         self.frontend_tools.lock().await.get(name).cloned()\n383:     }\n384: \n385:     pub async fn add_final_output_tool(&self, response: Response) {\n386:         let mut final_output_tool = self.final_output_tool.lock().await;\n387:         let created_final_output_tool = FinalOutputTool::new(response);\n388:         let final_output_system_prompt = created_final_output_tool.system_prompt();\n389:         *final_output_tool = Some(created_final_output_tool);\n390:         self.extend_system_prompt(final_output_system_prompt).await;\n391:     }\n392: \n393:     pub async fn add_sub_recipes(&self, sub_recipes_to_add: Vec<SubRecipe>) {\n394:         let mut sub_recipes = self.sub_recipes.lock().await;\n395:         for sr in sub_recipes_to_add {\n396:             sub_recipes.insert(sr.name.clone(), sr);\n397:         }\n398:     }\n399: \n400:     pub async fn apply_recipe_components(\n401:         &self,\n402:         sub_recipes: Option<Vec<SubRecipe>>,\n403:         response: Option<Response>,\n404:         include_final_output: bool,\n405:     ) {\n406:         if let Some(sub_recipes) = sub_recipes {\n407:             self.add_sub_recipes(sub_recipes).await;\n408:         }\n409: \n410:         if include_final_output {\n411:             if let Some(response) = response {\n412:                 self.add_final_output_tool(response).await;\n413:             }\n414:         }\n415:     }\n416: \n417:     /// Dispatch a single tool call to the appropriate client\n418:     #[instrument(skip(self, tool_call, request_id), fields(input, output))]\n419:     pub async fn dispatch_tool_call(\n420:         &self,\n421:         tool_call: CallToolRequestParam,\n422:         request_id: String,\n423:         cancellation_token: Option<CancellationToken>,\n424:         session: &Session,\n425:     ) -> (String, Result<ToolCallResult, ErrorData>) {\n426:         // Prevent subagents from creating other subagents\n427:         if session.session_type == SessionType::SubAgent && tool_call.name == SUBAGENT_TOOL_NAME {\n428:             return (\n429:                 request_id,\n430:                 Err(ErrorData::new(\n431:                     ErrorCode::INVALID_REQUEST,\n432:                     \"Subagents cannot create other subagents\".to_string(),\n433:                     None,\n434:                 )),\n435:             );\n436:         }\n437: \n438:         if tool_call.name == PLATFORM_MANAGE_SCHEDULE_TOOL_NAME {\n439:             let arguments = tool_call\n440:                 .arguments\n441:                 .map(Value::Object)\n442:                 .unwrap_or(Value::Object(serde_json::Map::new()));\n443:             let result = self\n444:                 .handle_schedule_management(arguments, request_id.clone())\n445:                 .await;\n446:             let wrapped_result = result.map(|content| CallToolResult {\n447:                 content,\n448:                 structured_content: None,\n449:                 is_error: Some(false),\n450:                 meta: None,\n451:             });\n452:             return (request_id, Ok(ToolCallResult::from(wrapped_result)));\n453:         }\n454: \n455:         if tool_call.name == FINAL_OUTPUT_TOOL_NAME {\n456:             return if let Some(final_output_tool) = self.final_output_tool.lock().await.as_mut() {\n457:                 let result = final_output_tool.execute_tool_call(tool_call.clone()).await;\n458:                 (request_id, Ok(result))\n459:             } else {\n460:                 (\n461:                     request_id,\n462:                     Err(ErrorData::new(\n463:                         ErrorCode::INTERNAL_ERROR,\n464:                         \"Final output tool not defined\".to_string(),\n465:                         None,\n466:                     )),\n467:                 )\n468:             };\n469:         }\n470: \n471:         debug!(\"WAITING_TOOL_START: {}\", tool_call.name);\n472:         let result: ToolCallResult = if tool_call.name == SUBAGENT_TOOL_NAME {\n473:             let provider = match self.provider().await {\n474:                 Ok(p) => p,\n475:                 Err(_) => {\n476:                     return (\n477:                         request_id,\n478:                         Err(ErrorData::new(\n479:                             ErrorCode::INTERNAL_ERROR,\n480:                             \"Provider is required\".to_string(),\n481:                             None,\n482:                         )),\n483:                     );\n484:                 }\n485:             };\n486: \n487:             let extensions = self.get_extension_configs().await;\n488:             let task_config =\n489:                 TaskConfig::new(provider, &session.id, &session.working_dir, extensions);\n490:             let sub_recipes = self.sub_recipes.lock().await.clone();\n491: \n492:             let arguments = tool_call\n493:                 .arguments\n494:                 .clone()\n495:                 .map(Value::Object)\n496:                 .unwrap_or(Value::Object(serde_json::Map::new()));\n497: \n498:             handle_subagent_tool(\n499:                 arguments,\n500:                 task_config,\n501:                 sub_recipes,\n502:                 session.working_dir.clone(),\n503:                 cancellation_token,\n504:             )\n505:         } else if self.is_frontend_tool(&tool_call.name).await {\n506:             // For frontend tools, return an error indicating we need frontend execution\n507:             ToolCallResult::from(Err(ErrorData::new(\n508:                 ErrorCode::INTERNAL_ERROR,\n509:                 \"Frontend tool execution required\".to_string(),\n510:                 None,\n511:             )))\n512:         } else {\n513:             // Clone the result to ensure no references to extension_manager are returned\n514:             let result = self\n515:                 .extension_manager\n516:                 .dispatch_tool_call(tool_call.clone(), cancellation_token.unwrap_or_default())\n517:                 .await;\n518:             result.unwrap_or_else(|e| {\n519:                 crate::posthog::emit_error(\n520:                     \"tool_execution_failed\",\n521:                     &format!(\"{}: {}\", tool_call.name, e),\n522:                 );\n523:                 ToolCallResult::from(Err(ErrorData::new(\n524:                     ErrorCode::INTERNAL_ERROR,\n525:                     e.to_string(),\n526:                     None,\n527:                 )))\n528:             })\n529:         };\n530: \n531:         debug!(\"WAITING_TOOL_END: {}\", tool_call.name);\n532: \n533:         (\n534:             request_id,\n535:             Ok(ToolCallResult {\n536:                 notification_stream: result.notification_stream,\n537:                 result: Box::new(\n538:                     result\n539:                         .result\n540:                         .map(super::large_response_handler::process_tool_response),\n541:                 ),\n542:             }),\n543:         )\n544:     }\n545: \n546:     /// Save current extension state to session metadata\n547:     /// Should be called after any extension add/remove operation\n548:     pub async fn save_extension_state(&self, session: &SessionConfig) -> Result<()> {\n549:         let extension_configs = self.extension_manager.get_extension_configs().await;\n550: \n551:         let extensions_state = EnabledExtensionsState::new(extension_configs);\n552: \n553:         let mut session_data = SessionManager::get_session(&session.id, false).await?;\n554: \n555:         if let Err(e) = extensions_state.to_extension_data(&mut session_data.extension_data) {\n556:             warn!(\"Failed to serialize extension state: {}\", e);\n557:             return Err(anyhow!(\"Extension state serialization failed: {}\", e));\n558:         }\n559: \n560:         SessionManager::update_session(&session.id)\n561:             .extension_data(session_data.extension_data)\n562:             .apply()\n563:             .await?;\n564: \n565:         Ok(())\n566:     }\n567: \n568:     pub async fn add_extension(&self, extension: ExtensionConfig) -> ExtensionResult<()> {\n569:         match &extension {\n570:             ExtensionConfig::Frontend {\n571:                 tools,\n572:                 instructions,\n573:                 ..\n574:             } => {\n575:                 // For frontend tools, just store them in the frontend_tools map\n576:                 let mut frontend_tools = self.frontend_tools.lock().await;\n577:                 for tool in tools {\n578:                     let frontend_tool = FrontendTool {\n579:                         name: tool.name.to_string(),\n580:                         tool: tool.clone(),\n581:                     };\n582:                     frontend_tools.insert(tool.name.to_string(), frontend_tool);\n583:                 }\n584:                 // Store instructions if provided, using \"frontend\" as the key\n585:                 let mut frontend_instructions = self.frontend_instructions.lock().await;\n586:                 if let Some(instructions) = instructions {\n587:                     *frontend_instructions = Some(instructions.clone());\n588:                 } else {\n589:                     // Default frontend instructions if none provided\n590:                     *frontend_instructions = Some(\n591:                         \"The following tools are provided directly by the frontend and will be executed by the frontend when called.\".to_string(),\n592:                     );\n593:                 }\n594:             }\n595:             _ => {\n596:                 self.extension_manager\n597:                     .add_extension(extension.clone())\n598:                     .await?;\n599:             }\n600:         }\n601: \n602:         Ok(())\n603:     }\n604: \n605:     pub async fn subagents_enabled(&self) -> bool {\n606:         let config = crate::config::Config::global();\n607:         let is_autonomous = config.get_goose_mode().unwrap_or(GooseMode::Auto) == GooseMode::Auto;\n608:         if !is_autonomous {\n609:             return false;\n610:         }\n611:         if self\n612:             .provider()\n613:             .await\n614:             .map(|provider| provider.get_active_model_name().starts_with(\"gemini\"))\n615:             .unwrap_or(false)\n616:         {\n617:             return false;\n618:         }\n619:         if let Some(ref session_id) = self.extension_manager.get_context().await.session_id {\n620:             if matches!(\n621:                 SessionManager::get_session(session_id, false)\n622:                     .await\n623:                     .ok()\n624:                     .map(|session| session.session_type),\n625:                 Some(SessionType::SubAgent)\n626:             ) {\n627:                 return false;\n628:             }\n629:         }\n630:         !self\n631:             .extension_manager\n632:             .list_extensions()\n633:             .await\n634:             .map(|ext| ext.is_empty())\n635:             .unwrap_or(true)\n636:     }\n637: \n638:     pub async fn list_tools(&self, extension_name: Option<String>) -> Vec<Tool> {\n639:         let mut prefixed_tools = self\n640:             .extension_manager\n641:             .get_prefixed_tools(extension_name.clone())\n642:             .await\n643:             .unwrap_or_default();\n644: \n645:         let subagents_enabled = self.subagents_enabled().await;\n646:         if extension_name.is_none() || extension_name.as_deref() == Some(\"platform\") {\n647:             prefixed_tools.push(platform_tools::manage_schedule_tool());\n648:         }\n649: \n650:         if extension_name.is_none() {\n651:             if let Some(final_output_tool) = self.final_output_tool.lock().await.as_ref() {\n652:                 prefixed_tools.push(final_output_tool.tool());\n653:             }\n654: \n655:             if subagents_enabled {\n656:                 let sub_recipes = self.sub_recipes.lock().await;\n657:                 let sub_recipes_vec: Vec<_> = sub_recipes.values().cloned().collect();\n658:                 prefixed_tools.push(create_subagent_tool(&sub_recipes_vec));\n659:             }\n660:         }\n661: \n662:         prefixed_tools\n663:     }\n664: \n665:     pub async fn remove_extension(&self, name: &str) -> Result<()> {\n666:         self.extension_manager.remove_extension(name).await?;\n667:         Ok(())\n668:     }\n669: \n670:     pub async fn list_extensions(&self) -> Vec<String> {\n671:         self.extension_manager\n672:             .list_extensions()\n673:             .await\n674:             .expect(\"Failed to list extensions\")\n675:     }\n676: \n677:     pub async fn get_extension_configs(&self) -> Vec<ExtensionConfig> {\n678:         self.extension_manager.get_extension_configs().await\n679:     }\n680: \n681:     /// Handle a confirmation response for a tool request\n682:     pub async fn handle_confirmation(\n683:         &self,\n684:         request_id: String,\n685:         confirmation: PermissionConfirmation,\n686:     ) {\n687:         if let Err(e) = self.confirmation_tx.send((request_id, confirmation)).await {\n688:             error!(\"Failed to send confirmation: {}\", e);\n689:         }\n690:     }\n691: \n692:     #[instrument(skip(self, user_message, session_config), fields(user_message))]\n693:     pub async fn reply(\n694:         &self,\n695:         user_message: Message,\n696:         session_config: SessionConfig,\n697:         cancel_token: Option<CancellationToken>,\n698:     ) -> Result<BoxStream<'_, Result<AgentEvent>>> {\n699:         for content in &user_message.content {\n700:             if let MessageContent::ActionRequired(action_required) = content {\n701:                 if let ActionRequiredData::ElicitationResponse { id, user_data } =\n702:                     &action_required.data\n703:                 {\n704:                     if let Err(e) = ActionRequiredManager::global()\n705:                         .submit_response(id.clone(), user_data.clone())\n706:                         .await\n707:                     {\n708:                         let error_text = format!(\"Failed to submit elicitation response: {}\", e);\n709:                         error!(error_text);\n710:                         return Ok(Box::pin(stream::once(async {\n711:                             Ok(AgentEvent::Message(\n712:                                 Message::assistant().with_text(error_text),\n713:                             ))\n714:                         })));\n715:                     }\n716:                     SessionManager::add_message(&session_config.id, &user_message).await?;\n717:                     return Ok(Box::pin(futures::stream::empty()));\n718:                 }\n719:             }\n720:         }\n721: \n722:         let message_text = user_message.as_concat_text();\n723: \n724:         // Track custom slash command usage (don't track command name for privacy)\n725:         if message_text.trim().starts_with('/') {\n726:             let command = message_text.split_whitespace().next();\n727:             if let Some(cmd) = command {\n728:                 if crate::slash_commands::get_recipe_for_command(cmd).is_some() {\n729:                     crate::posthog::emit_custom_slash_command_used();\n730:                 }\n731:             }\n732:         }\n733: \n734:         let command_result = self\n735:             .execute_command(&message_text, &session_config.id)\n736:             .await;\n737: \n738:         match command_result {\n739:             Err(e) => {\n740:                 let error_message = Message::assistant()\n741:                     .with_text(e.to_string())\n742:                     .with_visibility(true, false);\n743:                 return Ok(Box::pin(stream::once(async move {\n744:                     Ok(AgentEvent::Message(error_message))\n745:                 })));\n746:             }\n747:             Ok(Some(response)) if response.role == rmcp::model::Role::Assistant => {\n748:                 SessionManager::add_message(\n749:                     &session_config.id,\n750:                     &user_message.clone().with_visibility(true, false),\n751:                 )\n752:                 .await?;\n753:                 SessionManager::add_message(\n754:                     &session_config.id,\n755:                     &response.clone().with_visibility(true, false),\n756:                 )\n757:                 .await?;\n758: \n759:                 // Check if this was a command that modifies conversation history\n760:                 let modifies_history = crate::agents::execute_commands::COMPACT_TRIGGERS\n761:                     .contains(&message_text.trim())\n762:                     || message_text.trim() == \"/clear\";\n763: \n764:                 return Ok(Box::pin(async_stream::try_stream! {\n765:                     yield AgentEvent::Message(user_message);\n766:                     yield AgentEvent::Message(response);\n767: \n768:                     // After commands that modify history, notify UI that history was replaced\n769:                     if modifies_history {\n770:                         let updated_session = SessionManager::get_session(&session_config.id, true)\n771:                             .await\n772:                             .map_err(|e| anyhow!(\"Failed to fetch updated session: {}\", e))?;\n773:                         let updated_conversation = updated_session\n774:                             .conversation\n775:                             .ok_or_else(|| anyhow!(\"Session has no conversation after history modification\"))?;\n776:                         yield AgentEvent::HistoryReplaced(updated_conversation);\n777:                     }\n778:                 }));\n779:             }\n780:             Ok(Some(resolved_message)) => {\n781:                 SessionManager::add_message(\n782:                     &session_config.id,\n783:                     &user_message.clone().with_visibility(true, false),\n784:                 )\n785:                 .await?;\n786:                 SessionManager::add_message(\n787:                     &session_config.id,\n788:                     &resolved_message.clone().with_visibility(false, true),\n789:                 )\n790:                 .await?;\n791:             }\n792:             Ok(None) => {\n793:                 SessionManager::add_message(&session_config.id, &user_message).await?;\n794:             }\n795:         }\n796:         let session = SessionManager::get_session(&session_config.id, true).await?;\n797:         let conversation = session\n798:             .conversation\n799:             .clone()\n800:             .ok_or_else(|| anyhow::anyhow!(\"Session {} has no conversation\", session_config.id))?;\n801: \n802:         let needs_auto_compact = check_if_compaction_needed(\n803:             self.provider().await?.as_ref(),\n804:             &conversation,\n805:             None,\n806:             &session,\n807:         )\n808:         .await?;\n809: \n810:         let conversation_to_compact = conversation.clone();\n811: \n812:         Ok(Box::pin(async_stream::try_stream! {\n813:             let final_conversation = if !needs_auto_compact {\n814:                 conversation\n815:             } else {\n816:                 let config = Config::global();\n817:                 let threshold = config\n818:                     .get_param::<f64>(\"GOOSE_AUTO_COMPACT_THRESHOLD\")\n819:                     .unwrap_or(DEFAULT_COMPACTION_THRESHOLD);\n820:                 let threshold_percentage = (threshold * 100.0) as u32;\n821: \n822:                 let inline_msg = format!(\n823:                     \"Exceeded auto-compact threshold of {}%. Performing auto-compaction...\",\n824:                     threshold_percentage\n825:                 );\n826: \n827:                 yield AgentEvent::Message(\n828:                     Message::assistant().with_system_notification(\n829:                         SystemNotificationType::InlineMessage,\n830:                         inline_msg,\n831:                     )\n832:                 );\n833: \n834:                 yield AgentEvent::Message(\n835:                     Message::assistant().with_system_notification(\n836:                         SystemNotificationType::ThinkingMessage,\n837:                         COMPACTION_THINKING_TEXT,\n838:                     )\n839:                 );\n840: \n841:                 match compact_messages(self.provider().await?.as_ref(), &conversation_to_compact, false).await {\n842:                     Ok((compacted_conversation, summarization_usage)) => {\n843:                         SessionManager::replace_conversation(&session_config.id, &compacted_conversation).await?;\n844:                         Self::update_session_metrics(&session_config, &summarization_usage, true).await?;\n845: \n846:                         yield AgentEvent::HistoryReplaced(compacted_conversation.clone());\n847: \n848:                         yield AgentEvent::Message(\n849:                             Message::assistant().with_system_notification(\n850:                                 SystemNotificationType::InlineMessage,\n851:                                 \"Compaction complete\",\n852:                             )\n853:                         );\n854: \n855:                         compacted_conversation\n856:                     }\n857:                     Err(e) => {\n858:                         yield AgentEvent::Message(\n859:                             Message::assistant().with_text(\n860:                                 format!(\"Ran into this error trying to compact: {e}.\\n\\nPlease try again or create a new session\")\n861:                             )\n862:                         );\n863:                         return;\n864:                     }\n865:                 }\n866:             };\n867: \n868:             let mut reply_stream = self.reply_internal(final_conversation, session_config, session, cancel_token).await?;\n869:             while let Some(event) = reply_stream.next().await {\n870:                 yield event?;\n871:             }\n872:         }))\n873:     }\n874: \n875:     async fn reply_internal(\n876:         &self,\n877:         conversation: Conversation,\n878:         session_config: SessionConfig,\n879:         session: Session,\n880:         cancel_token: Option<CancellationToken>,\n881:     ) -> Result<BoxStream<'_, Result<AgentEvent>>> {\n882:         let context = self\n883:             .prepare_reply_context(conversation, &session.working_dir)\n884:             .await?;\n885:         let ReplyContext {\n886:             mut conversation,\n887:             mut tools,\n888:             mut toolshim_tools,\n889:             mut system_prompt,\n890:             goose_mode,\n891:             initial_messages,\n892:         } = context;\n893:         let reply_span = tracing::Span::current();\n894:         self.reset_retry_attempts().await;\n895: \n896:         let provider = self.provider().await?;\n897:         let session_id = session_config.id.clone();\n898:         let working_dir = session.working_dir.clone();\n899:         tokio::spawn(async move {\n900:             if let Err(e) = SessionManager::maybe_update_name(&session_id, provider).await {\n901:                 warn!(\"Failed to generate session description: {}\", e);\n902:             }\n903:         });\n904: \n905:         Ok(Box::pin(async_stream::try_stream! {\n906:             let _ = reply_span.enter();\n907:             let mut turns_taken = 0u32;\n908:             let max_turns = session_config.max_turns.unwrap_or(DEFAULT_MAX_TURNS);\n909:             let mut compaction_attempts = 0;\n910: \n911:             loop {\n912:                 if is_token_cancelled(&cancel_token) {\n913:                     break;\n914:                 }\n915: \n916:                 if let Some(final_output_tool) = self.final_output_tool.lock().await.as_ref() {\n917:                     if final_output_tool.final_output.is_some() {\n918:                         let final_event = AgentEvent::Message(\n919:                             Message::assistant().with_text(final_output_tool.final_output.clone().unwrap())\n920:                         );\n921:                         yield final_event;\n922:                         break;\n923:                     }\n924:                 }\n925: \n926:                 turns_taken += 1;\n927:                 if turns_taken > max_turns {\n928:                     yield AgentEvent::Message(\n929:                         Message::assistant().with_text(\n930:                             \"I've reached the maximum number of actions I can do without user input. Would you like me to continue?\"\n931:                         )\n932:                     );\n933:                     break;\n934:                 }\n935: \n936:                 let conversation_with_moim = super::moim::inject_moim(\n937:                     conversation.clone(),\n938:                     &self.extension_manager,\n939:                 ).await;\n940: \n941:                 let mut stream = Self::stream_response_from_provider(\n942:                     self.provider().await?,\n943:                     &system_prompt,\n944:                     conversation_with_moim.messages(),\n945:                     &tools,\n946:                     &toolshim_tools,\n947:                 ).await?;\n948: \n949:                 let mut no_tools_called = true;\n950:                 let mut messages_to_add = Conversation::default();\n951:                 let mut tools_updated = false;\n952:                 let mut did_recovery_compact_this_iteration = false;\n953: \n954:                 while let Some(next) = stream.next().await {\n955:                     if is_token_cancelled(&cancel_token) {\n956:                         break;\n957:                     }\n958: \n959:                     match next {\n960:                         Ok((response, usage)) => {\n961:                             compaction_attempts = 0;\n962: \n963:                             // Emit model change event if provider is lead-worker\n964:                             let provider = self.provider().await?;\n965:                             if let Some(lead_worker) = provider.as_lead_worker() {\n966:                                 if let Some(ref usage) = usage {\n967:                                     let active_model = usage.model.clone();\n968:                                     let (lead_model, worker_model) = lead_worker.get_model_info();\n969:                                     let mode = if active_model == lead_model {\n970:                                         \"lead\"\n971:                                     } else if active_model == worker_model {\n972:                                         \"worker\"\n973:                                     } else {\n974:                                         \"unknown\"\n975:                                     };\n976: \n977:                                     yield AgentEvent::ModelChange {\n978:                                         model: active_model,\n979:                                         mode: mode.to_string(),\n980:                                     };\n981:                                 }\n982:                             }\n983: \n984:                             if let Some(ref usage) = usage {\n985:                                 Self::update_session_metrics(&session_config, usage, false).await?;\n986:                             }\n987: \n988:                             if let Some(response) = response {\n989:                                 let ToolCategorizeResult {\n990:                                     frontend_requests,\n991:                                     remaining_requests,\n992:                                     filtered_response,\n993:                                 } = self.categorize_tools(&response, &tools).await;\n994: \n995:                                 yield AgentEvent::Message(filtered_response.clone());\n996:                                 tokio::task::yield_now().await;\n997: \n998:                                 let num_tool_requests = frontend_requests.len() + remaining_requests.len();\n999:                                 if num_tool_requests == 0 {\n1000:                                     messages_to_add.push(response.clone());\n1001:                                     continue;\n1002:                                 }\n1003: \n1004:                                 let tool_response_messages: Vec<Arc<Mutex<Message>>> = (0..num_tool_requests)\n1005:                                     .map(|_| Arc::new(Mutex::new(Message::user().with_id(\n1006:                                         format!(\"msg_{}\", Uuid::new_v4())\n1007:                                     ))))\n1008:                                     .collect();\n1009: \n1010:                                 let mut request_to_response_map = HashMap::new();\n1011:                                 let mut request_metadata: HashMap<String, Option<ProviderMetadata>> = HashMap::new();\n1012:                                 for (idx, request) in frontend_requests.iter().chain(remaining_requests.iter()).enumerate() {\n1013:                                     request_to_response_map.insert(request.id.clone(), tool_response_messages[idx].clone());\n1014:                                     request_metadata.insert(request.id.clone(), request.metadata.clone());\n1015:                                 }\n1016: \n1017:                                 for (idx, request) in frontend_requests.iter().enumerate() {\n1018:                                     let mut frontend_tool_stream = self.handle_frontend_tool_request(\n1019:                                         request,\n1020:                                         tool_response_messages[idx].clone(),\n1021:                                     );\n1022: \n1023:                                     while let Some(msg) = frontend_tool_stream.try_next().await? {\n1024:                                         yield AgentEvent::Message(msg);\n1025:                                     }\n1026:                                 }\n1027:                                 if goose_mode == GooseMode::Chat {\n1028:                                     // Skip all remaining tool calls in chat mode\n1029:                                     for request in remaining_requests.iter() {\n1030:                                         if let Some(response_msg) = request_to_response_map.get(&request.id) {\n1031:                                             let mut response = response_msg.lock().await;\n1032:                                             *response = response.clone().with_tool_response_with_metadata(\n1033:                                                 request.id.clone(),\n1034:                                                 Ok(CallToolResult {\n1035:                                                     content: vec![Content::text(CHAT_MODE_TOOL_SKIPPED_RESPONSE)],\n1036:                                                     structured_content: None,\n1037:                                                     is_error: Some(false),\n1038:                                                     meta: None,\n1039:                                                 }),\n1040:                                                 request.metadata.as_ref(),\n1041:                                             );\n1042:                                         }\n1043:                                     }\n1044:                                 } else {\n1045:                                     // Run all tool inspectors\n1046:                                     let inspection_results = self.tool_inspection_manager\n1047:                                         .inspect_tools(\n1048:                                             &remaining_requests,\n1049:                                             conversation.messages(),\n1050:                                         )\n1051:                                         .await?;\n1052: \n1053:                                     let permission_check_result = self.tool_inspection_manager\n1054:                                         .process_inspection_results_with_permission_inspector(\n1055:                                             &remaining_requests,\n1056:                                             &inspection_results,\n1057:                                         )\n1058:                                         .unwrap_or_else(|| {\n1059:                                             let mut result = PermissionCheckResult {\n1060:                                                 approved: vec![],\n1061:                                                 needs_approval: vec![],\n1062:                                                 denied: vec![],\n1063:                                             };\n1064:                                             result.needs_approval.extend(remaining_requests.iter().cloned());\n1065:                                             result\n1066:                                         });\n1067: \n1068:                                     // Track extension requests\n1069:                                     let mut enable_extension_request_ids = vec![];\n1070:                                     for request in &remaining_requests {\n1071:                                         if let Ok(tool_call) = &request.tool_call {\n1072:                                             if tool_call.name == MANAGE_EXTENSIONS_TOOL_NAME_COMPLETE {\n1073:                                                 enable_extension_request_ids.push(request.id.clone());\n1074:                                             }\n1075:                                         }\n1076:                                     }\n1077: \n1078:                                     let mut tool_futures = self.handle_approved_and_denied_tools(\n1079:                                         &permission_check_result,\n1080:                                         &request_to_response_map,\n1081:                                         cancel_token.clone(),\n1082:                                         &session,\n1083:                                     ).await?;\n1084: \n1085:                                     let tool_futures_arc = Arc::new(Mutex::new(tool_futures));\n1086: \n1087:                                     let mut tool_approval_stream = self.handle_approval_tool_requests(\n1088:                                         &permission_check_result.needs_approval,\n1089:                                         tool_futures_arc.clone(),\n1090:                                         &request_to_response_map,\n1091:                                         cancel_token.clone(),\n1092:                                         &session,\n1093:                                         &inspection_results,\n1094:                                     );\n1095: \n1096:                                     while let Some(msg) = tool_approval_stream.try_next().await? {\n1097:                                         yield AgentEvent::Message(msg);\n1098:                                     }\n1099: \n1100:                                     tool_futures = {\n1101:                                         let mut futures_lock = tool_futures_arc.lock().await;\n1102:                                         futures_lock.drain(..).collect::<Vec<_>>()\n1103:                                     };\n1104: \n1105:                                     let with_id = tool_futures\n1106:                                         .into_iter()\n1107:                                         .map(|(request_id, stream)| {\n1108:                                             stream.map(move |item| (request_id.clone(), item))\n1109:                                         })\n1110:                                         .collect::<Vec<_>>();\n1111: \n1112:                                     let mut combined = stream::select_all(with_id);\n1113:                                     let mut all_install_successful = true;\n1114: \n1115:                                     while let Some((request_id, item)) = combined.next().await {\n1116:                                         if is_token_cancelled(&cancel_token) {\n1117:                                             break;\n1118:                                         }\n1119: \n1120:                                         for msg in Self::drain_elicitation_messages(&session_config.id).await {\n1121:                                             yield AgentEvent::Message(msg);\n1122:                                         }\n1123: \n1124:                                         match item {\n1125:                                             ToolStreamItem::Result(output) => {\n1126:                                                 if enable_extension_request_ids.contains(&request_id)\n1127:                                                     && output.is_err()\n1128:                                                 {\n1129:                                                     all_install_successful = false;\n1130:                                                 }\n1131:                                                 if let Some(response_msg) = request_to_response_map.get(&request_id) {\n1132:                                                     let metadata = request_metadata.get(&request_id).and_then(|m| m.as_ref());\n1133:                                                     let mut response = response_msg.lock().await;\n1134:                                                     *response = response.clone().with_tool_response_with_metadata(request_id, output, metadata);\n1135:                                                 }\n1136:                                             }\n1137:                                             ToolStreamItem::Message(msg) => {\n1138:                                                 yield AgentEvent::McpNotification((request_id, msg));\n1139:                                             }\n1140:                                         }\n1141:                                     }\n1142: \n1143:                                     // check for remaining elicitation messages after all tools complete\n1144:                                     for msg in Self::drain_elicitation_messages(&session_config.id).await {\n1145:                                         yield AgentEvent::Message(msg);\n1146:                                     }\n1147: \n1148:                                     if all_install_successful && !enable_extension_request_ids.is_empty() {\n1149:                                         if let Err(e) = self.save_extension_state(&session_config).await {\n1150:                                             warn!(\"Failed to save extension state after runtime changes: {}\", e);\n1151:                                         }\n1152:                                         tools_updated = true;\n1153:                                     }\n1154:                                 }\n1155: \n1156:                                 // Preserve thinking content from the original response\n1157:                                 // Gemini (and other thinking models) require thinking to be echoed back\n1158:                                 let thinking_content: Vec<MessageContent> = response.content.iter()\n1159:                                     .filter(|c| matches!(c, MessageContent::Thinking(_)))\n1160:                                     .cloned()\n1161:                                     .collect();\n1162:                                 if !thinking_content.is_empty() {\n1163:                                     let thinking_msg = Message::new(\n1164:                                         response.role.clone(),\n1165:                                         response.created,\n1166:                                         thinking_content,\n1167:                                     ).with_id(format!(\"msg_{}\", Uuid::new_v4()));\n1168:                                     messages_to_add.push(thinking_msg);\n1169:                                 }\n1170: \n1171:                                 for (idx, request) in frontend_requests.iter().chain(remaining_requests.iter()).enumerate() {\n1172:                                     if request.tool_call.is_ok() {\n1173:                                         let request_msg = Message::assistant()\n1174:                                             .with_id(format!(\"msg_{}\", Uuid::new_v4()))\n1175:                                             .with_tool_request_with_metadata(\n1176:                                                 request.id.clone(),\n1177:                                                 request.tool_call.clone(),\n1178:                                                 request.metadata.as_ref(),\n1179:                                             );\n1180:                                         messages_to_add.push(request_msg);\n1181:                                         let final_response = tool_response_messages[idx]\n1182:                                                                 .lock().await.clone();\n1183:                                         yield AgentEvent::Message(final_response.clone());\n1184:                                         messages_to_add.push(final_response);\n1185:                                     }\n1186:                                 }\n1187: \n1188:                                 no_tools_called = false;\n1189:                             }\n1190:                         }\n1191:                         Err(ref provider_err @ ProviderError::ContextLengthExceeded(_)) => {\n1192:                             crate::posthog::emit_error(provider_err.telemetry_type(), &provider_err.to_string());\n1193:                             compaction_attempts += 1;\n1194: \n1195:                             if compaction_attempts >= 2 {\n1196:                                 error!(\"Context limit exceeded after compaction - prompt too large\");\n1197:                                 yield AgentEvent::Message(\n1198:                                     Message::assistant().with_system_notification(\n1199:                                         SystemNotificationType::InlineMessage,\n1200:                                         \"Unable to continue: Context limit still exceeded after compaction. Try using a shorter message, a model with a larger context window, or start a new session.\"\n1201:                                     )\n1202:                                 );\n1203:                                 break;\n1204:                             }\n1205: \n1206:                             yield AgentEvent::Message(\n1207:                                 Message::assistant().with_system_notification(\n1208:                                     SystemNotificationType::InlineMessage,\n1209:                                     \"Context limit reached. Compacting to continue conversation...\",\n1210:                                 )\n1211:                             );\n1212:                             yield AgentEvent::Message(\n1213:                                 Message::assistant().with_system_notification(\n1214:                                     SystemNotificationType::ThinkingMessage,\n1215:                                     COMPACTION_THINKING_TEXT,\n1216:                                 )\n1217:                             );\n1218: \n1219:                             match compact_messages(self.provider().await?.as_ref(), &conversation, false).await {\n1220:                                 Ok((compacted_conversation, usage)) => {\n1221:                                     SessionManager::replace_conversation(&session_config.id, &compacted_conversation).await?;\n1222:                                     Self::update_session_metrics(&session_config, &usage, true).await?;\n1223:                                     conversation = compacted_conversation;\n1224:                                     did_recovery_compact_this_iteration = true;\n1225:                                     yield AgentEvent::HistoryReplaced(conversation.clone());\n1226:                                     break;\n1227:                                 }\n1228:                                 Err(e) => {\n1229:                                     crate::posthog::emit_error(\"compaction_failed\", &e.to_string());\n1230:                                     error!(\"Compaction failed: {}\", e);\n1231:                                     break;\n1232:                                 }\n1233:                             }\n1234:                         }\n1235:                         Err(ref provider_err) => {\n1236:                             crate::posthog::emit_error(provider_err.telemetry_type(), &provider_err.to_string());\n1237:                             error!(\"Error: {}\", provider_err);\n1238:                             yield AgentEvent::Message(\n1239:                                 Message::assistant().with_text(\n1240:                                     format!(\"Ran into this error: {provider_err}.\\n\\nPlease retry if you think this is a transient or recoverable error.\")\n1241:                                 )\n1242:                             );\n1243:                             break;\n1244:                         }\n1245:                     }\n1246:                 }\n1247:                 if tools_updated {\n1248:                     (tools, toolshim_tools, system_prompt) =\n1249:                         self.prepare_tools_and_prompt(&working_dir).await?;\n1250:                 }\n1251:                 let mut exit_chat = false;\n1252:                 if no_tools_called {\n1253:                     if let Some(final_output_tool) = self.final_output_tool.lock().await.as_ref() {\n1254:                         if final_output_tool.final_output.is_none() {\n1255:                             warn!(\"Final output tool has not been called yet. Continuing agent loop.\");\n1256:                             let message = Message::user().with_text(FINAL_OUTPUT_CONTINUATION_MESSAGE);\n1257:                             messages_to_add.push(message.clone());\n1258:                             yield AgentEvent::Message(message);\n1259:                         } else {\n1260:                             let message = Message::assistant().with_text(final_output_tool.final_output.clone().unwrap());\n1261:                             messages_to_add.push(message.clone());\n1262:                             yield AgentEvent::Message(message);\n1263:                             exit_chat = true;\n1264:                         }\n1265:                     } else if did_recovery_compact_this_iteration {\n1266:                         // Avoid setting exit_chat; continue from last user message in the conversation\n1267:                     } else {\n1268:                         match self.handle_retry_logic(&mut conversation, &session_config, &initial_messages).await {\n1269:                             Ok(should_retry) => {\n1270:                                 if should_retry {\n1271:                                     info!(\"Retry logic triggered, restarting agent loop\");\n1272:                                 } else {\n1273:                                     exit_chat = true;\n1274:                                 }\n1275:                             }\n1276:                             Err(e) => {\n1277:                                 error!(\"Retry logic failed: {}\", e);\n1278:                                 yield AgentEvent::Message(\n1279:                                     Message::assistant().with_text(\n1280:                                         format!(\"Retry logic encountered an error: {}\", e)\n1281:                                     )\n1282:                                 );\n1283:                                 exit_chat = true;\n1284:                             }\n1285:                         }\n1286:                     }\n1287:                 }\n1288: \n1289:                 for msg in &messages_to_add {\n1290:                     SessionManager::add_message(&session_config.id, msg).await?;\n1291:                 }\n1292:                 conversation.extend(messages_to_add);\n1293:                 if exit_chat {\n1294:                     break;\n1295:                 }\n1296: \n1297:                 tokio::task::yield_now().await;\n1298:             }\n1299:         }))\n1300:     }\n1301: \n1302:     pub async fn extend_system_prompt(&self, instruction: String) {\n1303:         let mut prompt_manager = self.prompt_manager.lock().await;\n1304:         prompt_manager.add_system_prompt_extra(instruction);\n1305:     }\n1306: \n1307:     pub async fn update_provider(\n1308:         &self,\n1309:         provider: Arc<dyn Provider>,\n1310:         session_id: &str,\n1311:     ) -> Result<()> {\n1312:         let mut current_provider = self.provider.lock().await;\n1313:         *current_provider = Some(provider.clone());\n1314: \n1315:         SessionManager::update_session(session_id)\n1316:             .provider_name(provider.get_name())\n1317:             .model_config(provider.get_model_config())\n1318:             .apply()\n1319:             .await\n1320:             .context(\"Failed to persist provider config to session\")\n1321:     }\n1322: \n1323:     /// Override the system prompt with a custom template\n1324:     pub async fn override_system_prompt(&self, template: String) {\n1325:         let mut prompt_manager = self.prompt_manager.lock().await;\n1326:         prompt_manager.set_system_prompt_override(template);\n1327:     }\n1328: \n1329:     pub async fn list_extension_prompts(&self) -> HashMap<String, Vec<Prompt>> {\n1330:         self.extension_manager\n1331:             .list_prompts(CancellationToken::default())\n1332:             .await\n1333:             .expect(\"Failed to list prompts\")\n1334:     }\n1335: \n1336:     pub async fn get_prompt(&self, name: &str, arguments: Value) -> Result<GetPromptResult> {\n1337:         // First find which extension has this prompt\n1338:         let prompts = self\n1339:             .extension_manager\n1340:             .list_prompts(CancellationToken::default())\n1341:             .await\n1342:             .map_err(|e| anyhow!(\"Failed to list prompts: {}\", e))?;\n1343: \n1344:         if let Some(extension) = prompts\n1345:             .iter()\n1346:             .find(|(_, prompt_list)| prompt_list.iter().any(|p| p.name == name))\n1347:             .map(|(extension, _)| extension)\n1348:         {\n1349:             return self\n1350:                 .extension_manager\n1351:                 .get_prompt(extension, name, arguments, CancellationToken::default())\n1352:                 .await\n1353:                 .map_err(|e| anyhow!(\"Failed to get prompt: {}\", e));\n1354:         }\n1355: \n1356:         Err(anyhow!(\"Prompt '{}' not found\", name))\n1357:     }\n1358: \n1359:     pub async fn get_plan_prompt(&self) -> Result<String> {\n1360:         let tools = self.extension_manager.get_prefixed_tools(None).await?;\n1361:         let tools_info = tools\n1362:             .into_iter()\n1363:             .map(|tool| {\n1364:                 ToolInfo::new(\n1365:                     &tool.name,\n1366:                     tool.description\n1367:                         .as_ref()\n1368:                         .map(|d| d.as_ref())\n1369:                         .unwrap_or_default(),\n1370:                     get_parameter_names(&tool),\n1371:                     None,\n1372:                 )\n1373:             })\n1374:             .collect();\n1375: \n1376:         let plan_prompt = self.extension_manager.get_planning_prompt(tools_info).await;\n1377: \n1378:         Ok(plan_prompt)\n1379:     }\n1380: \n1381:     pub async fn handle_tool_result(&self, id: String, result: ToolResult<CallToolResult>) {\n1382:         if let Err(e) = self.tool_result_tx.send((id, result)).await {\n1383:             error!(\"Failed to send tool result: {}\", e);\n1384:         }\n1385:     }\n1386: \n1387:     pub async fn create_recipe(&self, mut messages: Conversation) -> Result<Recipe> {\n1388:         tracing::info!(\"Starting recipe creation with {} messages\", messages.len());\n1389: \n1390:         let extensions_info = self.extension_manager.get_extensions_info().await;\n1391:         tracing::debug!(\"Retrieved {} extensions info\", extensions_info.len());\n1392:         let (extension_count, tool_count) =\n1393:             self.extension_manager.get_extension_and_tool_counts().await;\n1394: \n1395:         // Get model name from provider\n1396:         let provider = self.provider().await.map_err(|e| {\n1397:             tracing::error!(\"Failed to get provider for recipe creation: {}\", e);\n1398:             e\n1399:         })?;\n1400:         let model_config = provider.get_model_config();\n1401:         let model_name = &model_config.model_name;\n1402:         tracing::debug!(\"Using model: {}\", model_name);\n1403: \n1404:         let prompt_manager = self.prompt_manager.lock().await;\n1405:         let system_prompt = prompt_manager\n1406:             .builder()\n1407:             .with_extensions(extensions_info.into_iter())\n1408:             .with_frontend_instructions(self.frontend_instructions.lock().await.clone())\n1409:             .with_extension_and_tool_counts(extension_count, tool_count)\n1410:             .build();\n1411: \n1412:         let recipe_prompt = prompt_manager.get_recipe_prompt().await;\n1413:         let tools = self\n1414:             .extension_manager\n1415:             .get_prefixed_tools(None)\n1416:             .await\n1417:             .map_err(|e| {\n1418:                 tracing::error!(\"Failed to get tools for recipe creation: {}\", e);\n1419:                 e\n1420:             })?;\n1421: \n1422:         messages.push(Message::user().with_text(recipe_prompt));\n1423: \n1424:         let (messages, issues) = fix_conversation(messages);\n1425:         if !issues.is_empty() {\n1426:             issues\n1427:                 .iter()\n1428:                 .for_each(|issue| tracing::warn!(recipe.conversation.issue = issue));\n1429:         }\n1430: \n1431:         tracing::debug!(\n1432:             \"Added recipe prompt to messages, total messages: {}\",\n1433:             messages.len()\n1434:         );\n1435: \n1436:         tracing::info!(\"Calling provider to generate recipe content\");\n1437:         let (result, _usage) = self\n1438:             .provider\n1439:             .lock()\n1440:             .await\n1441:             .as_ref()\n1442:             .ok_or_else(|| {\n1443:                 let error = anyhow!(\"Provider not available during recipe creation\");\n1444:                 tracing::error!(\"{}\", error);\n1445:                 error\n1446:             })?\n1447:             .complete(&system_prompt, messages.messages(), &tools)\n1448:             .await\n1449:             .map_err(|e| {\n1450:                 tracing::error!(\"Provider completion failed during recipe creation: {}\", e);\n1451:                 e\n1452:             })?;\n1453: \n1454:         let content = result.as_concat_text();\n1455:         tracing::debug!(\n1456:             \"Provider returned content with {} characters\",\n1457:             content.len()\n1458:         );\n1459: \n1460:         // the response may be contained in ```json ```, strip that before parsing json\n1461:         let re = Regex::new(r\"(?s)```[^\\n]*\\n(.*?)\\n```\").unwrap();\n1462:         let clean_content = re\n1463:             .captures(&content)\n1464:             .and_then(|caps| caps.get(1).map(|m| m.as_str()))\n1465:             .unwrap_or(&content)\n1466:             .trim()\n1467:             .to_string();\n1468: \n1469:         let (instructions, activities) =\n1470:             if let Ok(json_content) = serde_json::from_str::<Value>(&clean_content) {\n1471:                 let instructions = json_content\n1472:                     .get(\"instructions\")\n1473:                     .ok_or_else(|| anyhow!(\"Missing 'instructions' in json response\"))?\n1474:                     .as_str()\n1475:                     .ok_or_else(|| anyhow!(\"instructions' is not a string\"))?\n1476:                     .to_string();\n1477: \n1478:                 let activities = json_content\n1479:                     .get(\"activities\")\n1480:                     .ok_or_else(|| anyhow!(\"Missing 'activities' in json response\"))?\n1481:                     .as_array()\n1482:                     .ok_or_else(|| anyhow!(\"'activities' is not an array'\"))?\n1483:                     .iter()\n1484:                     .map(|act| {\n1485:                         act.as_str()\n1486:                             .map(|s| s.to_string())\n1487:                             .ok_or(anyhow!(\"'activities' array element is not a string\"))\n1488:                     })\n1489:                     .collect::<Result<_, _>>()?;\n1490: \n1491:                 (instructions, activities)\n1492:             } else {\n1493:                 tracing::warn!(\"Failed to parse JSON, falling back to string parsing\");\n1494:                 // If we can't get valid JSON, try string parsing\n1495:                 // Use split_once to get the content after \"Instructions:\".\n1496:                 let after_instructions = content\n1497:                     .split_once(\"instructions:\")\n1498:                     .map(|(_, rest)| rest)\n1499:                     .unwrap_or(&content);\n1500: \n1501:                 // Split once more to separate instructions from activities.\n1502:                 let (instructions_part, activities_text) = after_instructions\n1503:                     .split_once(\"activities:\")\n1504:                     .unwrap_or((after_instructions, \"\"));\n1505: \n1506:                 let instructions = instructions_part\n1507:                     .trim_end_matches(|c: char| c.is_whitespace() || c == '#')\n1508:                     .trim()\n1509:                     .to_string();\n1510:                 let activities_text = activities_text.trim();\n1511: \n1512:                 // Regex to remove bullet markers or numbers with an optional dot.\n1513:                 let bullet_re = Regex::new(r\"^[•\\-*\\d]+\\.?\\s*\").expect(\"Invalid regex\");\n1514: \n1515:                 // Process each line in the activities section.\n1516:                 let activities: Vec<String> = activities_text\n1517:                     .lines()\n1518:                     .map(|line| bullet_re.replace(line, \"\").to_string())\n1519:                     .map(|s| s.trim().to_string())\n1520:                     .filter(|line| !line.is_empty())\n1521:                     .collect();\n1522: \n1523:                 (instructions, activities)\n1524:             };\n1525: \n1526:         let extension_configs = get_enabled_extensions();\n1527: \n1528:         let author = Author {\n1529:             contact: std::env::var(\"USER\")\n1530:                 .or_else(|_| std::env::var(\"USERNAME\"))\n1531:                 .ok(),\n1532:             metadata: None,\n1533:         };\n1534: \n1535:         // Ideally we'd get the name of the provider we are using from the provider itself,\n1536:         // but it doesn't know and the plumbing looks complicated.\n1537:         let config = Config::global();\n1538:         let provider_name: String = config\n1539:             .get_goose_provider()\n1540:             .expect(\"No provider configured. Run 'goose configure' first\");\n1541: \n1542:         let settings = Settings {\n1543:             goose_provider: Some(provider_name.clone()),\n1544:             goose_model: Some(model_name.clone()),\n1545:             temperature: Some(model_config.temperature.unwrap_or(0.0)),\n1546:         };\n1547: \n1548:         tracing::debug!(\n1549:             \"Building recipe with {} activities and {} extensions\",\n1550:             activities.len(),\n1551:             extension_configs.len()\n1552:         );\n1553: \n1554:         let (title, description) =\n1555:             if let Ok(json_content) = serde_json::from_str::<Value>(&clean_content) {\n1556:                 let title = json_content\n1557:                     .get(\"title\")\n1558:                     .and_then(|t| t.as_str())\n1559:                     .unwrap_or(\"Custom recipe from chat\")\n1560:                     .to_string();\n1561: \n1562:                 let description = json_content\n1563:                     .get(\"description\")\n1564:                     .and_then(|d| d.as_str())\n1565:                     .unwrap_or(\"a custom recipe instance from this chat session\")\n1566:                     .to_string();\n1567: \n1568:                 (title, description)\n1569:             } else {\n1570:                 (\n1571:                     \"Custom recipe from chat\".to_string(),\n1572:                     \"a custom recipe instance from this chat session\".to_string(),\n1573:                 )\n1574:             };\n1575: \n1576:         let recipe = Recipe::builder()\n1577:             .title(title)\n1578:             .description(description)\n1579:             .instructions(instructions)\n1580:             .activities(activities)\n1581:             .extensions(extension_configs)\n1582:             .settings(settings)\n1583:             .author(author)\n1584:             .build()\n1585:             .map_err(|e| {\n1586:                 tracing::error!(\"Failed to build recipe: {}\", e);\n1587:                 anyhow!(\"Recipe build failed: {}\", e)\n1588:             })?;\n1589: \n1590:         tracing::info!(\"Recipe creation completed successfully\");\n1591:         Ok(recipe)\n1592:     }\n1593: }\n1594: \n1595: #[cfg(test)]\n1596: mod tests {\n1597:     use super::*;\n1598:     use crate::recipe::Response;\n1599: \n1600:     #[tokio::test]\n1601:     async fn test_add_final_output_tool() -> Result<()> {\n1602:         let agent = Agent::new();\n1603: \n1604:         let response = Response {\n1605:             json_schema: Some(serde_json::json!({\n1606:                 \"type\": \"object\",\n1607:                 \"properties\": {\n1608:                     \"result\": {\"type\": \"string\"}\n1609:                 }\n1610:             })),\n1611:         };\n1612: \n1613:         agent.add_final_output_tool(response).await;\n1614: \n1615:         let tools = agent.list_tools(None).await;\n1616:         let final_output_tool = tools\n1617:             .iter()\n1618:             .find(|tool| tool.name == FINAL_OUTPUT_TOOL_NAME);\n1619: \n1620:         assert!(\n1621:             final_output_tool.is_some(),\n1622:             \"Final output tool should be present after adding\"\n1623:         );\n1624: \n1625:         let prompt_manager = agent.prompt_manager.lock().await;\n1626:         let system_prompt = prompt_manager.builder().build();\n1627: \n1628:         let final_output_tool_ref = agent.final_output_tool.lock().await;\n1629:         let final_output_tool_system_prompt =\n1630:             final_output_tool_ref.as_ref().unwrap().system_prompt();\n1631:         assert!(system_prompt.contains(&final_output_tool_system_prompt));\n1632:         Ok(())\n1633:     }\n1634: \n1635:     #[tokio::test]\n1636:     async fn test_tool_inspection_manager_has_all_inspectors() -> Result<()> {\n1637:         let agent = Agent::new();\n1638: \n1639:         // Verify that the tool inspection manager has all expected inspectors\n1640:         let inspector_names = agent.tool_inspection_manager.inspector_names();\n1641: \n1642:         assert!(\n1643:             inspector_names.contains(&\"repetition\"),\n1644:             \"Tool inspection manager should contain repetition inspector\"\n1645:         );\n1646:         assert!(\n1647:             inspector_names.contains(&\"permission\"),\n1648:             \"Tool inspection manager should contain permission inspector\"\n1649:         );\n1650:         assert!(\n1651:             inspector_names.contains(&\"security\"),\n1652:             \"Tool inspection manager should contain security inspector\"\n1653:         );\n1654: \n1655:         Ok(())\n1656:     }\n1657: }\n```\n",
                  "annotations": {
                    "audience": [
                      "user"
                    ],
                    "priority": 0.0
                  }
                }
              ],
              "isError": false
            }
          }
        }
      ],
      "metadata": {
        "userVisible": true,
        "agentVisible": true
      }
    },
    {
      "id": "msg_01FF7EuzDzyDRJYySTz8kmK8",
      "role": "assistant",
      "created": 1766962628,
      "content": [
        {
          "type": "text",
          "text": "Now let me look at the provider interface to understand how messages are sent to the LLM:"
        },
        {
          "type": "toolRequest",
          "id": "toolu_01CEngQqr2Ho7gx5sJYe1431",
          "toolCall": {
            "status": "success",
            "value": {
              "name": "developer__text_editor",
              "arguments": {
                "command": "view",
                "path": "/Users/baxen/Development/goose/crates/goose/src/providers"
              }
            }
          }
        }
      ],
      "metadata": {
        "userVisible": true,
        "agentVisible": true
      }
    },
    {
      "id": "msg_932f5f03-8f8f-41d9-b9d4-4590fd076886",
      "role": "user",
      "created": 1766962630,
      "content": [
        {
          "type": "toolResponse",
          "id": "toolu_01CEngQqr2Ho7gx5sJYe1431",
          "toolResult": {
            "status": "success",
            "value": {
              "content": [
                {
                  "type": "text",
                  "text": "'/Users/baxen/Development/goose/crates/goose/src/providers' is a directory. Contents:\n\nDirectories:\n  canonical/\n  declarative/\n  formats/\n\nFiles:\n  anthropic.rs\n  api_client.rs\n  auto_detect.rs\n  azure.rs\n  azureauth.rs\n  base.rs\n  bedrock.rs\n  claude_code.rs\n  cursor_agent.rs\n  databricks.rs\n  embedding.rs\n  errors.rs\n  factory.rs\n  gcpauth.rs\n  gcpvertexai.rs\n  gemini_cli.rs\n  githubcopilot.rs\n  google.rs\n  lead_worker.rs\n  litellm.rs\n  mod.rs\n  oauth.rs\n  ollama.rs\n  openai.rs\n  openrouter.rs\n  provider_registry.rs\n  provider_test.rs\n  retry.rs\n  sagemaker_tgi.rs\n  snowflake.rs\n  testprovider.rs\n  tetrate.rs\n  toolshim.rs\n  usage_estimator.rs\n  utils.rs\n  utils_universal_openai_stream.rs\n  venice.rs\n  xai.rs\n"
                }
              ],
              "isError": false
            }
          }
        }
      ],
      "metadata": {
        "userVisible": true,
        "agentVisible": true
      }
    },
    {
      "id": "msg_01MM7XL12Pd2ueLBpzBon73u",
      "role": "assistant",
      "created": 1766962633,
      "content": [
        {
          "type": "toolRequest",
          "id": "toolu_01SorDoG4znPb8gbCZqT1xKF",
          "toolCall": {
            "status": "success",
            "value": {
              "name": "developer__text_editor",
              "arguments": {
                "command": "view",
                "path": "/Users/baxen/Development/goose/crates/goose/src/providers/base.rs"
              }
            }
          }
        }
      ],
      "metadata": {
        "userVisible": true,
        "agentVisible": true
      }
    },
    {
      "id": "msg_270f58c3-4182-4c38-a30a-83acb06236a6",
      "role": "user",
      "created": 1766962633,
      "content": [
        {
          "type": "toolResponse",
          "id": "toolu_01SorDoG4znPb8gbCZqT1xKF",
          "toolResult": {
            "status": "success",
            "value": {
              "content": [
                {
                  "type": "resource",
                  "resource": {
                    "uri": "file:///Users/baxen/Development/goose/crates/goose/src/providers/base.rs",
                    "mimeType": "text",
                    "text": "use anyhow::Result;\nuse futures::Stream;\nuse serde::{Deserialize, Serialize};\n\nuse super::canonical::{map_to_canonical_model, CanonicalModelRegistry};\nuse super::errors::ProviderError;\nuse super::retry::RetryConfig;\nuse crate::config::base::ConfigValue;\nuse crate::conversation::message::Message;\nuse crate::conversation::Conversation;\nuse crate::model::ModelConfig;\nuse crate::utils::safe_truncate;\nuse rmcp::model::Tool;\nuse utoipa::ToSchema;\n\nuse once_cell::sync::Lazy;\nuse std::ops::{Add, AddAssign};\nuse std::pin::Pin;\nuse std::sync::Mutex;\n\n/// A global store for the current model being used, we use this as when a provider returns, it tells us the real model, not an alias\npub static CURRENT_MODEL: Lazy<Mutex<Option<String>>> = Lazy::new(|| Mutex::new(None));\n\n/// Set the current model in the global store\npub fn set_current_model(model: &str) {\n    if let Ok(mut current_model) = CURRENT_MODEL.lock() {\n        *current_model = Some(model.to_string());\n    }\n}\n\n/// Get the current model from the global store, the real model, not an alias\npub fn get_current_model() -> Option<String> {\n    CURRENT_MODEL.lock().ok().and_then(|model| model.clone())\n}\n\npub static MSG_COUNT_FOR_SESSION_NAME_GENERATION: usize = 3;\n\n/// Information about a model's capabilities\n#[derive(Debug, Clone, Serialize, Deserialize, ToSchema, PartialEq)]\npub struct ModelInfo {\n    /// The name of the model\n    pub name: String,\n    /// The maximum context length this model supports\n    pub context_limit: usize,\n    /// Cost per token for input (optional)\n    pub input_token_cost: Option<f64>,\n    /// Cost per token for output (optional)\n    pub output_token_cost: Option<f64>,\n    /// Currency for the costs (default: \"$\")\n    pub currency: Option<String>,\n    /// Whether this model supports cache control\n    pub supports_cache_control: Option<bool>,\n}\n\nimpl ModelInfo {\n    /// Create a new ModelInfo with just name and context limit\n    pub fn new(name: impl Into<String>, context_limit: usize) -> Self {\n        Self {\n            name: name.into(),\n            context_limit,\n            input_token_cost: None,\n            output_token_cost: None,\n            currency: None,\n            supports_cache_control: None,\n        }\n    }\n\n    /// Create a new ModelInfo with cost information (per token)\n    pub fn with_cost(\n        name: impl Into<String>,\n        context_limit: usize,\n        input_cost: f64,\n        output_cost: f64,\n    ) -> Self {\n        Self {\n            name: name.into(),\n            context_limit,\n            input_token_cost: Some(input_cost),\n            output_token_cost: Some(output_cost),\n            currency: Some(\"$\".to_string()),\n            supports_cache_control: None,\n        }\n    }\n}\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize, ToSchema)]\npub enum ProviderType {\n    Preferred,\n    Builtin,\n    Declarative,\n    Custom,\n}\n\n/// Metadata about a provider's configuration requirements and capabilities\n#[derive(Debug, Clone, Serialize, Deserialize, ToSchema)]\npub struct ProviderMetadata {\n    /// The unique identifier for this provider\n    pub name: String,\n    /// Display name for the provider in UIs\n    pub display_name: String,\n    /// Description of the provider's capabilities\n    pub description: String,\n    /// The default/recommended model for this provider\n    pub default_model: String,\n    /// A list of currently known models with their capabilities\n    pub known_models: Vec<ModelInfo>,\n    /// Link to the docs where models can be found\n    pub model_doc_link: String,\n    /// Required configuration keys\n    pub config_keys: Vec<ConfigKey>,\n}\n\nimpl ProviderMetadata {\n    pub fn new(\n        name: &str,\n        display_name: &str,\n        description: &str,\n        default_model: &str,\n        model_names: Vec<&str>,\n        model_doc_link: &str,\n        config_keys: Vec<ConfigKey>,\n    ) -> Self {\n        Self {\n            name: name.to_string(),\n            display_name: display_name.to_string(),\n            description: description.to_string(),\n            default_model: default_model.to_string(),\n            known_models: model_names\n                .iter()\n                .map(|&name| ModelInfo {\n                    name: name.to_string(),\n                    context_limit: ModelConfig::new_or_fail(name).context_limit(),\n                    input_token_cost: None,\n                    output_token_cost: None,\n                    currency: None,\n                    supports_cache_control: None,\n                })\n                .collect(),\n            model_doc_link: model_doc_link.to_string(),\n            config_keys,\n        }\n    }\n\n    pub fn with_models(\n        name: &str,\n        display_name: &str,\n        description: &str,\n        default_model: &str,\n        models: Vec<ModelInfo>,\n        model_doc_link: &str,\n        config_keys: Vec<ConfigKey>,\n    ) -> Self {\n        Self {\n            name: name.to_string(),\n            display_name: display_name.to_string(),\n            description: description.to_string(),\n            default_model: default_model.to_string(),\n            known_models: models,\n            model_doc_link: model_doc_link.to_string(),\n            config_keys,\n        }\n    }\n\n    pub fn empty() -> Self {\n        Self {\n            name: \"\".to_string(),\n            display_name: \"\".to_string(),\n            description: \"\".to_string(),\n            default_model: \"\".to_string(),\n            known_models: vec![],\n            model_doc_link: \"\".to_string(),\n            config_keys: vec![],\n        }\n    }\n}\n\n/// Configuration key metadata for provider setup\n#[derive(Debug, Clone, Serialize, Deserialize, ToSchema)]\npub struct ConfigKey {\n    /// The name of the configuration key (e.g., \"API_KEY\")\n    pub name: String,\n    /// Whether this key is required for the provider to function\n    pub required: bool,\n    /// Whether this key should be stored securely (e.g., in keychain)\n    pub secret: bool,\n    /// Optional default value for the key\n    pub default: Option<String>,\n    /// Whether this key should be configured using OAuth device code flow\n    /// When true, the provider's configure_oauth() method will be called instead of prompting for manual input\n    pub oauth_flow: bool,\n}\n\nimpl ConfigKey {\n    /// Create a new ConfigKey\n    pub fn new(name: &str, required: bool, secret: bool, default: Option<&str>) -> Self {\n        Self {\n            name: name.to_string(),\n            required,\n            secret,\n            default: default.map(|s| s.to_string()),\n            oauth_flow: false,\n        }\n    }\n\n    pub fn from_value_type<T: ConfigValue>(required: bool, secret: bool) -> Self {\n        Self {\n            name: T::KEY.to_string(),\n            required,\n            secret,\n            default: Some(T::DEFAULT.to_string()),\n            oauth_flow: false,\n        }\n    }\n\n    /// Create a new ConfigKey that uses OAuth device code flow for configuration\n    ///\n    /// This is used for providers that support OAuth authentication instead of manual API key entry.\n    /// When oauth_flow is true, the configuration system will call the provider's configure_oauth() method.\n    pub fn new_oauth(name: &str, required: bool, secret: bool, default: Option<&str>) -> Self {\n        Self {\n            name: name.to_string(),\n            required,\n            secret,\n            default: default.map(|s| s.to_string()),\n            oauth_flow: true,\n        }\n    }\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ProviderUsage {\n    pub model: String,\n    pub usage: Usage,\n}\n\nimpl ProviderUsage {\n    pub fn new(model: String, usage: Usage) -> Self {\n        Self { model, usage }\n    }\n\n    /// Ensures this ProviderUsage has token counts, estimating them if necessary\n    pub async fn ensure_tokens(\n        &mut self,\n        system_prompt: &str,\n        request_messages: &[Message],\n        response: &Message,\n        tools: &[Tool],\n    ) -> Result<(), ProviderError> {\n        crate::providers::usage_estimator::ensure_usage_tokens(\n            self,\n            system_prompt,\n            request_messages,\n            response,\n            tools,\n        )\n        .await\n        .map_err(|e| ProviderError::ExecutionError(format!(\"Failed to ensure usage tokens: {}\", e)))\n    }\n\n    /// Combine this ProviderUsage with another, adding their token counts\n    /// Uses the model from this ProviderUsage\n    pub fn combine_with(&self, other: &ProviderUsage) -> ProviderUsage {\n        ProviderUsage {\n            model: self.model.clone(),\n            usage: self.usage + other.usage,\n        }\n    }\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize, Default, Copy)]\npub struct Usage {\n    pub input_tokens: Option<i32>,\n    pub output_tokens: Option<i32>,\n    pub total_tokens: Option<i32>,\n}\n\nfn sum_optionals<T>(a: Option<T>, b: Option<T>) -> Option<T>\nwhere\n    T: Add<Output = T> + Default,\n{\n    match (a, b) {\n        (Some(x), Some(y)) => Some(x + y),\n        (Some(x), None) => Some(x + T::default()),\n        (None, Some(y)) => Some(T::default() + y),\n        (None, None) => None,\n    }\n}\n\nimpl Add for Usage {\n    type Output = Self;\n\n    fn add(self, other: Self) -> Self {\n        Self::new(\n            sum_optionals(self.input_tokens, other.input_tokens),\n            sum_optionals(self.output_tokens, other.output_tokens),\n            sum_optionals(self.total_tokens, other.total_tokens),\n        )\n    }\n}\n\nimpl AddAssign for Usage {\n    fn add_assign(&mut self, rhs: Self) {\n        *self = *self + rhs;\n    }\n}\n\nimpl Usage {\n    pub fn new(\n        input_tokens: Option<i32>,\n        output_tokens: Option<i32>,\n        total_tokens: Option<i32>,\n    ) -> Self {\n        let calculated_total = if total_tokens.is_none() {\n            match (input_tokens, output_tokens) {\n                (Some(input), Some(output)) => Some(input + output),\n                (Some(input), None) => Some(input),\n                (None, Some(output)) => Some(output),\n                (None, None) => None,\n            }\n        } else {\n            total_tokens\n        };\n\n        Self {\n            input_tokens,\n            output_tokens,\n            total_tokens: calculated_total,\n        }\n    }\n}\n\nuse async_trait::async_trait;\n\n/// Trait for LeadWorkerProvider-specific functionality\npub trait LeadWorkerProviderTrait {\n    /// Get information about the lead and worker models for logging\n    fn get_model_info(&self) -> (String, String);\n\n    /// Get the currently active model name\n    fn get_active_model(&self) -> String;\n\n    /// Get (lead_turns, failure_threshold, fallback_turns)\n    fn get_settings(&self) -> (usize, usize, usize);\n}\n\n/// Base trait for AI providers (OpenAI, Anthropic, etc)\n#[async_trait]\npub trait Provider: Send + Sync {\n    /// Get the metadata for this provider type\n    fn metadata() -> ProviderMetadata\n    where\n        Self: Sized;\n\n    /// Get the name of this provider instance\n    fn get_name(&self) -> &str;\n\n    // Internal implementation of complete, used by complete_fast and complete\n    // Providers should override this to implement their actual completion logic\n    async fn complete_with_model(\n        &self,\n        model_config: &ModelConfig,\n        system: &str,\n        messages: &[Message],\n        tools: &[Tool],\n    ) -> Result<(Message, ProviderUsage), ProviderError>;\n\n    // Default implementation: use the provider's configured model\n    async fn complete(\n        &self,\n        system: &str,\n        messages: &[Message],\n        tools: &[Tool],\n    ) -> Result<(Message, ProviderUsage), ProviderError> {\n        let model_config = self.get_model_config();\n        self.complete_with_model(&model_config, system, messages, tools)\n            .await\n    }\n\n    // Check if a fast model is configured, otherwise fall back to regular model\n    async fn complete_fast(\n        &self,\n        system: &str,\n        messages: &[Message],\n        tools: &[Tool],\n    ) -> Result<(Message, ProviderUsage), ProviderError> {\n        let model_config = self.get_model_config();\n        let fast_config = model_config.use_fast_model();\n\n        match self\n            .complete_with_model(&fast_config, system, messages, tools)\n            .await\n        {\n            Ok(result) => Ok(result),\n            Err(e) => {\n                if fast_config.model_name != model_config.model_name {\n                    tracing::warn!(\n                        \"Fast model {} failed with error: {}. Falling back to regular model {}\",\n                        fast_config.model_name,\n                        e,\n                        model_config.model_name\n                    );\n                    self.complete_with_model(&model_config, system, messages, tools)\n                        .await\n                } else {\n                    Err(e)\n                }\n            }\n        }\n    }\n\n    /// Get the model config from the provider\n    fn get_model_config(&self) -> ModelConfig;\n\n    fn retry_config(&self) -> RetryConfig {\n        RetryConfig::default()\n    }\n\n    async fn fetch_supported_models(&self) -> Result<Option<Vec<String>>, ProviderError> {\n        Ok(None)\n    }\n\n    /// Fetch models filtered by canonical registry and usability\n    async fn fetch_recommended_models(&self) -> Result<Option<Vec<String>>, ProviderError> {\n        let all_models = match self.fetch_supported_models().await? {\n            Some(models) => models,\n            None => return Ok(None),\n        };\n\n        let registry = CanonicalModelRegistry::bundled().map_err(|e| {\n            ProviderError::ExecutionError(format!(\"Failed to load canonical registry: {}\", e))\n        })?;\n\n        let provider_name = self.get_name();\n\n        let recommended_models: Vec<String> = all_models\n            .iter()\n            .filter(|model| {\n                map_to_canonical_model(provider_name, model, registry)\n                    .and_then(|canonical_id| registry.get(&canonical_id))\n                    .map(|m| m.input_modalities.contains(&\"text\".to_string()))\n                    .unwrap_or(false)\n            })\n            .cloned()\n            .collect();\n\n        if recommended_models.is_empty() {\n            Ok(Some(all_models))\n        } else {\n            Ok(Some(recommended_models))\n        }\n    }\n\n    async fn map_to_canonical_model(\n        &self,\n        provider_model: &str,\n    ) -> Result<Option<String>, ProviderError> {\n        let registry = CanonicalModelRegistry::bundled().map_err(|e| {\n            ProviderError::ExecutionError(format!(\"Failed to load canonical registry: {}\", e))\n        })?;\n\n        Ok(map_to_canonical_model(\n            self.get_name(),\n            provider_model,\n            registry,\n        ))\n    }\n\n    fn supports_embeddings(&self) -> bool {\n        false\n    }\n\n    async fn supports_cache_control(&self) -> bool {\n        false\n    }\n\n    /// Create embeddings if supported. Default implementation returns an error.\n    async fn create_embeddings(&self, _texts: Vec<String>) -> Result<Vec<Vec<f32>>, ProviderError> {\n        Err(ProviderError::ExecutionError(\n            \"This provider does not support embeddings\".to_string(),\n        ))\n    }\n\n    /// Check if this provider is a LeadWorkerProvider\n    /// This is used for logging model information at startup\n    fn as_lead_worker(&self) -> Option<&dyn LeadWorkerProviderTrait> {\n        None\n    }\n\n    async fn stream(\n        &self,\n        _system: &str,\n        _messages: &[Message],\n        _tools: &[Tool],\n    ) -> Result<MessageStream, ProviderError> {\n        Err(ProviderError::NotImplemented(\n            \"streaming not implemented\".to_string(),\n        ))\n    }\n\n    fn supports_streaming(&self) -> bool {\n        false\n    }\n\n    /// Get the currently active model name\n    /// For regular providers, this returns the configured model\n    /// For LeadWorkerProvider, this returns the currently active model (lead or worker)\n    fn get_active_model_name(&self) -> String {\n        if let Some(lead_worker) = self.as_lead_worker() {\n            lead_worker.get_active_model()\n        } else {\n            self.get_model_config().model_name\n        }\n    }\n\n    /// Returns the first 3 user messages as strings for session naming\n    fn get_initial_user_messages(&self, messages: &Conversation) -> Vec<String> {\n        messages\n            .iter()\n            .filter(|m| m.role == rmcp::model::Role::User)\n            .take(MSG_COUNT_FOR_SESSION_NAME_GENERATION)\n            .map(|m| m.as_concat_text())\n            .collect()\n    }\n\n    /// Generate a session name/description based on the conversation history\n    /// Creates a prompt asking for a concise description in 4 words or less.\n    async fn generate_session_name(\n        &self,\n        messages: &Conversation,\n    ) -> Result<String, ProviderError> {\n        let context = self.get_initial_user_messages(messages);\n        let prompt = self.create_session_name_prompt(&context);\n        let message = Message::user().with_text(&prompt);\n        let result = self\n            .complete_fast(\n                \"Reply with only a description in four words or less\",\n                &[message],\n                &[],\n            )\n            .await?;\n\n        let description = result\n            .0\n            .as_concat_text()\n            .split_whitespace()\n            .collect::<Vec<_>>()\n            .join(\" \");\n\n        Ok(safe_truncate(&description, 100))\n    }\n\n    // Generate a prompt for a session name based on the conversation history\n    fn create_session_name_prompt(&self, context: &[String]) -> String {\n        // Create a prompt for a concise description\n        let mut prompt = \"Based on the conversation so far, provide a concise description of this session in 4 words or less. This will be used for finding the session later in a UI with limited space - reply *ONLY* with the description\".to_string();\n\n        if !context.is_empty() {\n            prompt = format!(\n                \"Here are the first few user messages:\\n{}\\n\\n{}\",\n                context.join(\"\\n\"),\n                prompt\n            );\n        }\n        prompt\n    }\n\n    /// Configure OAuth authentication for this provider\n    ///\n    /// This method is called when a provider has configuration keys marked with oauth_flow = true.\n    /// Providers that support OAuth should override this method to implement their specific OAuth flow.\n    ///\n    /// # Returns\n    /// * `Ok(())` if OAuth configuration succeeds and credentials are saved\n    /// * `Err(ProviderError)` if OAuth fails or is not supported by this provider\n    ///\n    /// # Default Implementation\n    /// The default implementation returns an error indicating OAuth is not supported.\n    async fn configure_oauth(&self) -> Result<(), ProviderError> {\n        Err(ProviderError::ExecutionError(\n            \"OAuth configuration not supported by this provider\".to_string(),\n        ))\n    }\n}\n\n/// A message stream yields partial text content but complete tool calls, all within the Message object\n/// So a message with text will contain potentially just a word of a longer response, but tool calls\n/// messages will only be yielded once concatenated.\npub type MessageStream = Pin<\n    Box<dyn Stream<Item = Result<(Option<Message>, Option<ProviderUsage>), ProviderError>> + Send>,\n>;\n\npub fn stream_from_single_message(message: Message, usage: ProviderUsage) -> MessageStream {\n    let stream = futures::stream::once(async move { Ok((Some(message), Some(usage))) });\n    Box::pin(stream)\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::collections::HashMap;\n\n    use serde_json::json;\n    #[test]\n    fn test_usage_creation() {\n        let usage = Usage::new(Some(10), Some(20), Some(30));\n        assert_eq!(usage.input_tokens, Some(10));\n        assert_eq!(usage.output_tokens, Some(20));\n        assert_eq!(usage.total_tokens, Some(30));\n    }\n\n    #[test]\n    fn test_usage_serialization() -> Result<()> {\n        let usage = Usage::new(Some(10), Some(20), Some(30));\n        let serialized = serde_json::to_string(&usage)?;\n        let deserialized: Usage = serde_json::from_str(&serialized)?;\n\n        assert_eq!(usage.input_tokens, deserialized.input_tokens);\n        assert_eq!(usage.output_tokens, deserialized.output_tokens);\n        assert_eq!(usage.total_tokens, deserialized.total_tokens);\n\n        // Test JSON structure\n        let json_value: serde_json::Value = serde_json::from_str(&serialized)?;\n        assert_eq!(json_value[\"input_tokens\"], json!(10));\n        assert_eq!(json_value[\"output_tokens\"], json!(20));\n        assert_eq!(json_value[\"total_tokens\"], json!(30));\n\n        Ok(())\n    }\n\n    #[test]\n    fn test_set_and_get_current_model() {\n        // Set the model\n        set_current_model(\"gpt-4o\");\n\n        // Get the model and verify\n        let model = get_current_model();\n        assert_eq!(model, Some(\"gpt-4o\".to_string()));\n\n        // Change the model\n        set_current_model(\"claude-sonnet-4-20250514\");\n\n        // Get the updated model and verify\n        let model = get_current_model();\n        assert_eq!(model, Some(\"claude-sonnet-4-20250514\".to_string()));\n    }\n\n    #[test]\n    fn test_provider_metadata_context_limits() {\n        // Test that ProviderMetadata::new correctly sets context limits\n        let test_models = vec![\"gpt-4o\", \"claude-sonnet-4-20250514\", \"unknown-model\"];\n        let metadata = ProviderMetadata::new(\n            \"test\",\n            \"Test Provider\",\n            \"Test Description\",\n            \"gpt-4o\",\n            test_models,\n            \"https://example.com\",\n            vec![],\n        );\n\n        let model_info: HashMap<String, usize> = metadata\n            .known_models\n            .into_iter()\n            .map(|m| (m.name, m.context_limit))\n            .collect();\n\n        // gpt-4o should have 128k limit\n        assert_eq!(*model_info.get(\"gpt-4o\").unwrap(), 128_000);\n\n        // claude-sonnet-4-20250514 should have 200k limit\n        assert_eq!(\n            *model_info.get(\"claude-sonnet-4-20250514\").unwrap(),\n            200_000\n        );\n\n        // unknown model should have default limit (128k)\n        assert_eq!(*model_info.get(\"unknown-model\").unwrap(), 128_000);\n    }\n\n    #[test]\n    fn test_model_info_creation() {\n        // Test direct ModelInfo creation\n        let info = ModelInfo {\n            name: \"test-model\".to_string(),\n            context_limit: 1000,\n            input_token_cost: None,\n            output_token_cost: None,\n            currency: None,\n            supports_cache_control: None,\n        };\n        assert_eq!(info.context_limit, 1000);\n\n        // Test equality\n        let info2 = ModelInfo {\n            name: \"test-model\".to_string(),\n            context_limit: 1000,\n            input_token_cost: None,\n            output_token_cost: None,\n            currency: None,\n            supports_cache_control: None,\n        };\n        assert_eq!(info, info2);\n\n        // Test inequality\n        let info3 = ModelInfo {\n            name: \"test-model\".to_string(),\n            context_limit: 2000,\n            input_token_cost: None,\n            output_token_cost: None,\n            currency: None,\n            supports_cache_control: None,\n        };\n        assert_ne!(info, info3);\n    }\n\n    #[test]\n    fn test_model_info_with_cost() {\n        let info = ModelInfo::with_cost(\"gpt-4o\", 128000, 0.0000025, 0.00001);\n        assert_eq!(info.name, \"gpt-4o\");\n        assert_eq!(info.context_limit, 128000);\n        assert_eq!(info.input_token_cost, Some(0.0000025));\n        assert_eq!(info.output_token_cost, Some(0.00001));\n        assert_eq!(info.currency, Some(\"$\".to_string()));\n    }\n}\n"
                  },
                  "annotations": {
                    "audience": [
                      "assistant"
                    ]
                  }
                },
                {
                  "type": "text",
                  "text": "### /Users/baxen/Development/goose/crates/goose/src/providers/base.rs\n```rust\n1: use anyhow::Result;\n2: use futures::Stream;\n3: use serde::{Deserialize, Serialize};\n4: \n5: use super::canonical::{map_to_canonical_model, CanonicalModelRegistry};\n6: use super::errors::ProviderError;\n7: use super::retry::RetryConfig;\n8: use crate::config::base::ConfigValue;\n9: use crate::conversation::message::Message;\n10: use crate::conversation::Conversation;\n11: use crate::model::ModelConfig;\n12: use crate::utils::safe_truncate;\n13: use rmcp::model::Tool;\n14: use utoipa::ToSchema;\n15: \n16: use once_cell::sync::Lazy;\n17: use std::ops::{Add, AddAssign};\n18: use std::pin::Pin;\n19: use std::sync::Mutex;\n20: \n21: /// A global store for the current model being used, we use this as when a provider returns, it tells us the real model, not an alias\n22: pub static CURRENT_MODEL: Lazy<Mutex<Option<String>>> = Lazy::new(|| Mutex::new(None));\n23: \n24: /// Set the current model in the global store\n25: pub fn set_current_model(model: &str) {\n26:     if let Ok(mut current_model) = CURRENT_MODEL.lock() {\n27:         *current_model = Some(model.to_string());\n28:     }\n29: }\n30: \n31: /// Get the current model from the global store, the real model, not an alias\n32: pub fn get_current_model() -> Option<String> {\n33:     CURRENT_MODEL.lock().ok().and_then(|model| model.clone())\n34: }\n35: \n36: pub static MSG_COUNT_FOR_SESSION_NAME_GENERATION: usize = 3;\n37: \n38: /// Information about a model's capabilities\n39: #[derive(Debug, Clone, Serialize, Deserialize, ToSchema, PartialEq)]\n40: pub struct ModelInfo {\n41:     /// The name of the model\n42:     pub name: String,\n43:     /// The maximum context length this model supports\n44:     pub context_limit: usize,\n45:     /// Cost per token for input (optional)\n46:     pub input_token_cost: Option<f64>,\n47:     /// Cost per token for output (optional)\n48:     pub output_token_cost: Option<f64>,\n49:     /// Currency for the costs (default: \"$\")\n50:     pub currency: Option<String>,\n51:     /// Whether this model supports cache control\n52:     pub supports_cache_control: Option<bool>,\n53: }\n54: \n55: impl ModelInfo {\n56:     /// Create a new ModelInfo with just name and context limit\n57:     pub fn new(name: impl Into<String>, context_limit: usize) -> Self {\n58:         Self {\n59:             name: name.into(),\n60:             context_limit,\n61:             input_token_cost: None,\n62:             output_token_cost: None,\n63:             currency: None,\n64:             supports_cache_control: None,\n65:         }\n66:     }\n67: \n68:     /// Create a new ModelInfo with cost information (per token)\n69:     pub fn with_cost(\n70:         name: impl Into<String>,\n71:         context_limit: usize,\n72:         input_cost: f64,\n73:         output_cost: f64,\n74:     ) -> Self {\n75:         Self {\n76:             name: name.into(),\n77:             context_limit,\n78:             input_token_cost: Some(input_cost),\n79:             output_token_cost: Some(output_cost),\n80:             currency: Some(\"$\".to_string()),\n81:             supports_cache_control: None,\n82:         }\n83:     }\n84: }\n85: \n86: #[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize, ToSchema)]\n87: pub enum ProviderType {\n88:     Preferred,\n89:     Builtin,\n90:     Declarative,\n91:     Custom,\n92: }\n93: \n94: /// Metadata about a provider's configuration requirements and capabilities\n95: #[derive(Debug, Clone, Serialize, Deserialize, ToSchema)]\n96: pub struct ProviderMetadata {\n97:     /// The unique identifier for this provider\n98:     pub name: String,\n99:     /// Display name for the provider in UIs\n100:     pub display_name: String,\n101:     /// Description of the provider's capabilities\n102:     pub description: String,\n103:     /// The default/recommended model for this provider\n104:     pub default_model: String,\n105:     /// A list of currently known models with their capabilities\n106:     pub known_models: Vec<ModelInfo>,\n107:     /// Link to the docs where models can be found\n108:     pub model_doc_link: String,\n109:     /// Required configuration keys\n110:     pub config_keys: Vec<ConfigKey>,\n111: }\n112: \n113: impl ProviderMetadata {\n114:     pub fn new(\n115:         name: &str,\n116:         display_name: &str,\n117:         description: &str,\n118:         default_model: &str,\n119:         model_names: Vec<&str>,\n120:         model_doc_link: &str,\n121:         config_keys: Vec<ConfigKey>,\n122:     ) -> Self {\n123:         Self {\n124:             name: name.to_string(),\n125:             display_name: display_name.to_string(),\n126:             description: description.to_string(),\n127:             default_model: default_model.to_string(),\n128:             known_models: model_names\n129:                 .iter()\n130:                 .map(|&name| ModelInfo {\n131:                     name: name.to_string(),\n132:                     context_limit: ModelConfig::new_or_fail(name).context_limit(),\n133:                     input_token_cost: None,\n134:                     output_token_cost: None,\n135:                     currency: None,\n136:                     supports_cache_control: None,\n137:                 })\n138:                 .collect(),\n139:             model_doc_link: model_doc_link.to_string(),\n140:             config_keys,\n141:         }\n142:     }\n143: \n144:     pub fn with_models(\n145:         name: &str,\n146:         display_name: &str,\n147:         description: &str,\n148:         default_model: &str,\n149:         models: Vec<ModelInfo>,\n150:         model_doc_link: &str,\n151:         config_keys: Vec<ConfigKey>,\n152:     ) -> Self {\n153:         Self {\n154:             name: name.to_string(),\n155:             display_name: display_name.to_string(),\n156:             description: description.to_string(),\n157:             default_model: default_model.to_string(),\n158:             known_models: models,\n159:             model_doc_link: model_doc_link.to_string(),\n160:             config_keys,\n161:         }\n162:     }\n163: \n164:     pub fn empty() -> Self {\n165:         Self {\n166:             name: \"\".to_string(),\n167:             display_name: \"\".to_string(),\n168:             description: \"\".to_string(),\n169:             default_model: \"\".to_string(),\n170:             known_models: vec![],\n171:             model_doc_link: \"\".to_string(),\n172:             config_keys: vec![],\n173:         }\n174:     }\n175: }\n176: \n177: /// Configuration key metadata for provider setup\n178: #[derive(Debug, Clone, Serialize, Deserialize, ToSchema)]\n179: pub struct ConfigKey {\n180:     /// The name of the configuration key (e.g., \"API_KEY\")\n181:     pub name: String,\n182:     /// Whether this key is required for the provider to function\n183:     pub required: bool,\n184:     /// Whether this key should be stored securely (e.g., in keychain)\n185:     pub secret: bool,\n186:     /// Optional default value for the key\n187:     pub default: Option<String>,\n188:     /// Whether this key should be configured using OAuth device code flow\n189:     /// When true, the provider's configure_oauth() method will be called instead of prompting for manual input\n190:     pub oauth_flow: bool,\n191: }\n192: \n193: impl ConfigKey {\n194:     /// Create a new ConfigKey\n195:     pub fn new(name: &str, required: bool, secret: bool, default: Option<&str>) -> Self {\n196:         Self {\n197:             name: name.to_string(),\n198:             required,\n199:             secret,\n200:             default: default.map(|s| s.to_string()),\n201:             oauth_flow: false,\n202:         }\n203:     }\n204: \n205:     pub fn from_value_type<T: ConfigValue>(required: bool, secret: bool) -> Self {\n206:         Self {\n207:             name: T::KEY.to_string(),\n208:             required,\n209:             secret,\n210:             default: Some(T::DEFAULT.to_string()),\n211:             oauth_flow: false,\n212:         }\n213:     }\n214: \n215:     /// Create a new ConfigKey that uses OAuth device code flow for configuration\n216:     ///\n217:     /// This is used for providers that support OAuth authentication instead of manual API key entry.\n218:     /// When oauth_flow is true, the configuration system will call the provider's configure_oauth() method.\n219:     pub fn new_oauth(name: &str, required: bool, secret: bool, default: Option<&str>) -> Self {\n220:         Self {\n221:             name: name.to_string(),\n222:             required,\n223:             secret,\n224:             default: default.map(|s| s.to_string()),\n225:             oauth_flow: true,\n226:         }\n227:     }\n228: }\n229: \n230: #[derive(Debug, Clone, Serialize, Deserialize)]\n231: pub struct ProviderUsage {\n232:     pub model: String,\n233:     pub usage: Usage,\n234: }\n235: \n236: impl ProviderUsage {\n237:     pub fn new(model: String, usage: Usage) -> Self {\n238:         Self { model, usage }\n239:     }\n240: \n241:     /// Ensures this ProviderUsage has token counts, estimating them if necessary\n242:     pub async fn ensure_tokens(\n243:         &mut self,\n244:         system_prompt: &str,\n245:         request_messages: &[Message],\n246:         response: &Message,\n247:         tools: &[Tool],\n248:     ) -> Result<(), ProviderError> {\n249:         crate::providers::usage_estimator::ensure_usage_tokens(\n250:             self,\n251:             system_prompt,\n252:             request_messages,\n253:             response,\n254:             tools,\n255:         )\n256:         .await\n257:         .map_err(|e| ProviderError::ExecutionError(format!(\"Failed to ensure usage tokens: {}\", e)))\n258:     }\n259: \n260:     /// Combine this ProviderUsage with another, adding their token counts\n261:     /// Uses the model from this ProviderUsage\n262:     pub fn combine_with(&self, other: &ProviderUsage) -> ProviderUsage {\n263:         ProviderUsage {\n264:             model: self.model.clone(),\n265:             usage: self.usage + other.usage,\n266:         }\n267:     }\n268: }\n269: \n270: #[derive(Debug, Clone, Serialize, Deserialize, Default, Copy)]\n271: pub struct Usage {\n272:     pub input_tokens: Option<i32>,\n273:     pub output_tokens: Option<i32>,\n274:     pub total_tokens: Option<i32>,\n275: }\n276: \n277: fn sum_optionals<T>(a: Option<T>, b: Option<T>) -> Option<T>\n278: where\n279:     T: Add<Output = T> + Default,\n280: {\n281:     match (a, b) {\n282:         (Some(x), Some(y)) => Some(x + y),\n283:         (Some(x), None) => Some(x + T::default()),\n284:         (None, Some(y)) => Some(T::default() + y),\n285:         (None, None) => None,\n286:     }\n287: }\n288: \n289: impl Add for Usage {\n290:     type Output = Self;\n291: \n292:     fn add(self, other: Self) -> Self {\n293:         Self::new(\n294:             sum_optionals(self.input_tokens, other.input_tokens),\n295:             sum_optionals(self.output_tokens, other.output_tokens),\n296:             sum_optionals(self.total_tokens, other.total_tokens),\n297:         )\n298:     }\n299: }\n300: \n301: impl AddAssign for Usage {\n302:     fn add_assign(&mut self, rhs: Self) {\n303:         *self = *self + rhs;\n304:     }\n305: }\n306: \n307: impl Usage {\n308:     pub fn new(\n309:         input_tokens: Option<i32>,\n310:         output_tokens: Option<i32>,\n311:         total_tokens: Option<i32>,\n312:     ) -> Self {\n313:         let calculated_total = if total_tokens.is_none() {\n314:             match (input_tokens, output_tokens) {\n315:                 (Some(input), Some(output)) => Some(input + output),\n316:                 (Some(input), None) => Some(input),\n317:                 (None, Some(output)) => Some(output),\n318:                 (None, None) => None,\n319:             }\n320:         } else {\n321:             total_tokens\n322:         };\n323: \n324:         Self {\n325:             input_tokens,\n326:             output_tokens,\n327:             total_tokens: calculated_total,\n328:         }\n329:     }\n330: }\n331: \n332: use async_trait::async_trait;\n333: \n334: /// Trait for LeadWorkerProvider-specific functionality\n335: pub trait LeadWorkerProviderTrait {\n336:     /// Get information about the lead and worker models for logging\n337:     fn get_model_info(&self) -> (String, String);\n338: \n339:     /// Get the currently active model name\n340:     fn get_active_model(&self) -> String;\n341: \n342:     /// Get (lead_turns, failure_threshold, fallback_turns)\n343:     fn get_settings(&self) -> (usize, usize, usize);\n344: }\n345: \n346: /// Base trait for AI providers (OpenAI, Anthropic, etc)\n347: #[async_trait]\n348: pub trait Provider: Send + Sync {\n349:     /// Get the metadata for this provider type\n350:     fn metadata() -> ProviderMetadata\n351:     where\n352:         Self: Sized;\n353: \n354:     /// Get the name of this provider instance\n355:     fn get_name(&self) -> &str;\n356: \n357:     // Internal implementation of complete, used by complete_fast and complete\n358:     // Providers should override this to implement their actual completion logic\n359:     async fn complete_with_model(\n360:         &self,\n361:         model_config: &ModelConfig,\n362:         system: &str,\n363:         messages: &[Message],\n364:         tools: &[Tool],\n365:     ) -> Result<(Message, ProviderUsage), ProviderError>;\n366: \n367:     // Default implementation: use the provider's configured model\n368:     async fn complete(\n369:         &self,\n370:         system: &str,\n371:         messages: &[Message],\n372:         tools: &[Tool],\n373:     ) -> Result<(Message, ProviderUsage), ProviderError> {\n374:         let model_config = self.get_model_config();\n375:         self.complete_with_model(&model_config, system, messages, tools)\n376:             .await\n377:     }\n378: \n379:     // Check if a fast model is configured, otherwise fall back to regular model\n380:     async fn complete_fast(\n381:         &self,\n382:         system: &str,\n383:         messages: &[Message],\n384:         tools: &[Tool],\n385:     ) -> Result<(Message, ProviderUsage), ProviderError> {\n386:         let model_config = self.get_model_config();\n387:         let fast_config = model_config.use_fast_model();\n388: \n389:         match self\n390:             .complete_with_model(&fast_config, system, messages, tools)\n391:             .await\n392:         {\n393:             Ok(result) => Ok(result),\n394:             Err(e) => {\n395:                 if fast_config.model_name != model_config.model_name {\n396:                     tracing::warn!(\n397:                         \"Fast model {} failed with error: {}. Falling back to regular model {}\",\n398:                         fast_config.model_name,\n399:                         e,\n400:                         model_config.model_name\n401:                     );\n402:                     self.complete_with_model(&model_config, system, messages, tools)\n403:                         .await\n404:                 } else {\n405:                     Err(e)\n406:                 }\n407:             }\n408:         }\n409:     }\n410: \n411:     /// Get the model config from the provider\n412:     fn get_model_config(&self) -> ModelConfig;\n413: \n414:     fn retry_config(&self) -> RetryConfig {\n415:         RetryConfig::default()\n416:     }\n417: \n418:     async fn fetch_supported_models(&self) -> Result<Option<Vec<String>>, ProviderError> {\n419:         Ok(None)\n420:     }\n421: \n422:     /// Fetch models filtered by canonical registry and usability\n423:     async fn fetch_recommended_models(&self) -> Result<Option<Vec<String>>, ProviderError> {\n424:         let all_models = match self.fetch_supported_models().await? {\n425:             Some(models) => models,\n426:             None => return Ok(None),\n427:         };\n428: \n429:         let registry = CanonicalModelRegistry::bundled().map_err(|e| {\n430:             ProviderError::ExecutionError(format!(\"Failed to load canonical registry: {}\", e))\n431:         })?;\n432: \n433:         let provider_name = self.get_name();\n434: \n435:         let recommended_models: Vec<String> = all_models\n436:             .iter()\n437:             .filter(|model| {\n438:                 map_to_canonical_model(provider_name, model, registry)\n439:                     .and_then(|canonical_id| registry.get(&canonical_id))\n440:                     .map(|m| m.input_modalities.contains(&\"text\".to_string()))\n441:                     .unwrap_or(false)\n442:             })\n443:             .cloned()\n444:             .collect();\n445: \n446:         if recommended_models.is_empty() {\n447:             Ok(Some(all_models))\n448:         } else {\n449:             Ok(Some(recommended_models))\n450:         }\n451:     }\n452: \n453:     async fn map_to_canonical_model(\n454:         &self,\n455:         provider_model: &str,\n456:     ) -> Result<Option<String>, ProviderError> {\n457:         let registry = CanonicalModelRegistry::bundled().map_err(|e| {\n458:             ProviderError::ExecutionError(format!(\"Failed to load canonical registry: {}\", e))\n459:         })?;\n460: \n461:         Ok(map_to_canonical_model(\n462:             self.get_name(),\n463:             provider_model,\n464:             registry,\n465:         ))\n466:     }\n467: \n468:     fn supports_embeddings(&self) -> bool {\n469:         false\n470:     }\n471: \n472:     async fn supports_cache_control(&self) -> bool {\n473:         false\n474:     }\n475: \n476:     /// Create embeddings if supported. Default implementation returns an error.\n477:     async fn create_embeddings(&self, _texts: Vec<String>) -> Result<Vec<Vec<f32>>, ProviderError> {\n478:         Err(ProviderError::ExecutionError(\n479:             \"This provider does not support embeddings\".to_string(),\n480:         ))\n481:     }\n482: \n483:     /// Check if this provider is a LeadWorkerProvider\n484:     /// This is used for logging model information at startup\n485:     fn as_lead_worker(&self) -> Option<&dyn LeadWorkerProviderTrait> {\n486:         None\n487:     }\n488: \n489:     async fn stream(\n490:         &self,\n491:         _system: &str,\n492:         _messages: &[Message],\n493:         _tools: &[Tool],\n494:     ) -> Result<MessageStream, ProviderError> {\n495:         Err(ProviderError::NotImplemented(\n496:             \"streaming not implemented\".to_string(),\n497:         ))\n498:     }\n499: \n500:     fn supports_streaming(&self) -> bool {\n501:         false\n502:     }\n503: \n504:     /// Get the currently active model name\n505:     /// For regular providers, this returns the configured model\n506:     /// For LeadWorkerProvider, this returns the currently active model (lead or worker)\n507:     fn get_active_model_name(&self) -> String {\n508:         if let Some(lead_worker) = self.as_lead_worker() {\n509:             lead_worker.get_active_model()\n510:         } else {\n511:             self.get_model_config().model_name\n512:         }\n513:     }\n514: \n515:     /// Returns the first 3 user messages as strings for session naming\n516:     fn get_initial_user_messages(&self, messages: &Conversation) -> Vec<String> {\n517:         messages\n518:             .iter()\n519:             .filter(|m| m.role == rmcp::model::Role::User)\n520:             .take(MSG_COUNT_FOR_SESSION_NAME_GENERATION)\n521:             .map(|m| m.as_concat_text())\n522:             .collect()\n523:     }\n524: \n525:     /// Generate a session name/description based on the conversation history\n526:     /// Creates a prompt asking for a concise description in 4 words or less.\n527:     async fn generate_session_name(\n528:         &self,\n529:         messages: &Conversation,\n530:     ) -> Result<String, ProviderError> {\n531:         let context = self.get_initial_user_messages(messages);\n532:         let prompt = self.create_session_name_prompt(&context);\n533:         let message = Message::user().with_text(&prompt);\n534:         let result = self\n535:             .complete_fast(\n536:                 \"Reply with only a description in four words or less\",\n537:                 &[message],\n538:                 &[],\n539:             )\n540:             .await?;\n541: \n542:         let description = result\n543:             .0\n544:             .as_concat_text()\n545:             .split_whitespace()\n546:             .collect::<Vec<_>>()\n547:             .join(\" \");\n548: \n549:         Ok(safe_truncate(&description, 100))\n550:     }\n551: \n552:     // Generate a prompt for a session name based on the conversation history\n553:     fn create_session_name_prompt(&self, context: &[String]) -> String {\n554:         // Create a prompt for a concise description\n555:         let mut prompt = \"Based on the conversation so far, provide a concise description of this session in 4 words or less. This will be used for finding the session later in a UI with limited space - reply *ONLY* with the description\".to_string();\n556: \n557:         if !context.is_empty() {\n558:             prompt = format!(\n559:                 \"Here are the first few user messages:\\n{}\\n\\n{}\",\n560:                 context.join(\"\\n\"),\n561:                 prompt\n562:             );\n563:         }\n564:         prompt\n565:     }\n566: \n567:     /// Configure OAuth authentication for this provider\n568:     ///\n569:     /// This method is called when a provider has configuration keys marked with oauth_flow = true.\n570:     /// Providers that support OAuth should override this method to implement their specific OAuth flow.\n571:     ///\n572:     /// # Returns\n573:     /// * `Ok(())` if OAuth configuration succeeds and credentials are saved\n574:     /// * `Err(ProviderError)` if OAuth fails or is not supported by this provider\n575:     ///\n576:     /// # Default Implementation\n577:     /// The default implementation returns an error indicating OAuth is not supported.\n578:     async fn configure_oauth(&self) -> Result<(), ProviderError> {\n579:         Err(ProviderError::ExecutionError(\n580:             \"OAuth configuration not supported by this provider\".to_string(),\n581:         ))\n582:     }\n583: }\n584: \n585: /// A message stream yields partial text content but complete tool calls, all within the Message object\n586: /// So a message with text will contain potentially just a word of a longer response, but tool calls\n587: /// messages will only be yielded once concatenated.\n588: pub type MessageStream = Pin<\n589:     Box<dyn Stream<Item = Result<(Option<Message>, Option<ProviderUsage>), ProviderError>> + Send>,\n590: >;\n591: \n592: pub fn stream_from_single_message(message: Message, usage: ProviderUsage) -> MessageStream {\n593:     let stream = futures::stream::once(async move { Ok((Some(message), Some(usage))) });\n594:     Box::pin(stream)\n595: }\n596: \n597: #[cfg(test)]\n598: mod tests {\n599:     use super::*;\n600:     use std::collections::HashMap;\n601: \n602:     use serde_json::json;\n603:     #[test]\n604:     fn test_usage_creation() {\n605:         let usage = Usage::new(Some(10), Some(20), Some(30));\n606:         assert_eq!(usage.input_tokens, Some(10));\n607:         assert_eq!(usage.output_tokens, Some(20));\n608:         assert_eq!(usage.total_tokens, Some(30));\n609:     }\n610: \n611:     #[test]\n612:     fn test_usage_serialization() -> Result<()> {\n613:         let usage = Usage::new(Some(10), Some(20), Some(30));\n614:         let serialized = serde_json::to_string(&usage)?;\n615:         let deserialized: Usage = serde_json::from_str(&serialized)?;\n616: \n617:         assert_eq!(usage.input_tokens, deserialized.input_tokens);\n618:         assert_eq!(usage.output_tokens, deserialized.output_tokens);\n619:         assert_eq!(usage.total_tokens, deserialized.total_tokens);\n620: \n621:         // Test JSON structure\n622:         let json_value: serde_json::Value = serde_json::from_str(&serialized)?;\n623:         assert_eq!(json_value[\"input_tokens\"], json!(10));\n624:         assert_eq!(json_value[\"output_tokens\"], json!(20));\n625:         assert_eq!(json_value[\"total_tokens\"], json!(30));\n626: \n627:         Ok(())\n628:     }\n629: \n630:     #[test]\n631:     fn test_set_and_get_current_model() {\n632:         // Set the model\n633:         set_current_model(\"gpt-4o\");\n634: \n635:         // Get the model and verify\n636:         let model = get_current_model();\n637:         assert_eq!(model, Some(\"gpt-4o\".to_string()));\n638: \n639:         // Change the model\n640:         set_current_model(\"claude-sonnet-4-20250514\");\n641: \n642:         // Get the updated model and verify\n643:         let model = get_current_model();\n644:         assert_eq!(model, Some(\"claude-sonnet-4-20250514\".to_string()));\n645:     }\n646: \n647:     #[test]\n648:     fn test_provider_metadata_context_limits() {\n649:         // Test that ProviderMetadata::new correctly sets context limits\n650:         let test_models = vec![\"gpt-4o\", \"claude-sonnet-4-20250514\", \"unknown-model\"];\n651:         let metadata = ProviderMetadata::new(\n652:             \"test\",\n653:             \"Test Provider\",\n654:             \"Test Description\",\n655:             \"gpt-4o\",\n656:             test_models,\n657:             \"https://example.com\",\n658:             vec![],\n659:         );\n660: \n661:         let model_info: HashMap<String, usize> = metadata\n662:             .known_models\n663:             .into_iter()\n664:             .map(|m| (m.name, m.context_limit))\n665:             .collect();\n666: \n667:         // gpt-4o should have 128k limit\n668:         assert_eq!(*model_info.get(\"gpt-4o\").unwrap(), 128_000);\n669: \n670:         // claude-sonnet-4-20250514 should have 200k limit\n671:         assert_eq!(\n672:             *model_info.get(\"claude-sonnet-4-20250514\").unwrap(),\n673:             200_000\n674:         );\n675: \n676:         // unknown model should have default limit (128k)\n677:         assert_eq!(*model_info.get(\"unknown-model\").unwrap(), 128_000);\n678:     }\n679: \n680:     #[test]\n681:     fn test_model_info_creation() {\n682:         // Test direct ModelInfo creation\n683:         let info = ModelInfo {\n684:             name: \"test-model\".to_string(),\n685:             context_limit: 1000,\n686:             input_token_cost: None,\n687:             output_token_cost: None,\n688:             currency: None,\n689:             supports_cache_control: None,\n690:         };\n691:         assert_eq!(info.context_limit, 1000);\n692: \n693:         // Test equality\n694:         let info2 = ModelInfo {\n695:             name: \"test-model\".to_string(),\n696:             context_limit: 1000,\n697:             input_token_cost: None,\n698:             output_token_cost: None,\n699:             currency: None,\n700:             supports_cache_control: None,\n701:         };\n702:         assert_eq!(info, info2);\n703: \n704:         // Test inequality\n705:         let info3 = ModelInfo {\n706:             name: \"test-model\".to_string(),\n707:             context_limit: 2000,\n708:             input_token_cost: None,\n709:             output_token_cost: None,\n710:             currency: None,\n711:             supports_cache_control: None,\n712:         };\n713:         assert_ne!(info, info3);\n714:     }\n715: \n716:     #[test]\n717:     fn test_model_info_with_cost() {\n718:         let info = ModelInfo::with_cost(\"gpt-4o\", 128000, 0.0000025, 0.00001);\n719:         assert_eq!(info.name, \"gpt-4o\");\n720:         assert_eq!(info.context_limit, 128000);\n721:         assert_eq!(info.input_token_cost, Some(0.0000025));\n722:         assert_eq!(info.output_token_cost, Some(0.00001));\n723:         assert_eq!(info.currency, Some(\"$\".to_string()));\n724:     }\n725: }\n```\n",
                  "annotations": {
                    "audience": [
                      "user"
                    ],
                    "priority": 0.0
                  }
                }
              ],
              "isError": false
            }
          }
        }
      ],
      "metadata": {
        "userVisible": true,
        "agentVisible": true
      }
    },
    {
      "id": "msg_01DVs7hXSmkFweEkL9rG8NZ6",
      "role": "assistant",
      "created": 1766962637,
      "content": [
        {
          "type": "text",
          "text": "Now let me look at the session builder to understand how the CLI session is created:"
        },
        {
          "type": "toolRequest",
          "id": "toolu_01NXSiWHAL9bg5CZuupxnwAK",
          "toolCall": {
            "status": "success",
            "value": {
              "name": "developer__text_editor",
              "arguments": {
                "command": "view",
                "path": "/Users/baxen/Development/goose/crates/goose-cli/src/session/builder.rs"
              }
            }
          }
        }
      ],
      "metadata": {
        "userVisible": true,
        "agentVisible": true
      }
    },
    {
      "id": "msg_9befb7db-fa9e-454d-8812-c4334d0284b8",
      "role": "user",
      "created": 1766962638,
      "content": [
        {
          "type": "toolResponse",
          "id": "toolu_01NXSiWHAL9bg5CZuupxnwAK",
          "toolResult": {
            "status": "success",
            "value": {
              "content": [
                {
                  "type": "resource",
                  "resource": {
                    "uri": "file:///Users/baxen/Development/goose/crates/goose-cli/src/session/builder.rs",
                    "mimeType": "text",
                    "text": "use super::output;\nuse super::CliSession;\nuse console::style;\nuse goose::agents::types::{RetryConfig, SessionConfig};\nuse goose::agents::Agent;\nuse goose::config::{\n    extensions::get_extension_by_name, get_all_extensions, get_enabled_extensions, Config,\n    ExtensionConfig,\n};\nuse goose::providers::create;\nuse goose::recipe::{Response, SubRecipe};\n\nuse goose::agents::extension::PlatformExtensionContext;\nuse goose::session::session_manager::SessionType;\nuse goose::session::SessionManager;\nuse goose::session::{EnabledExtensionsState, ExtensionState};\nuse rustyline::EditMode;\nuse std::collections::HashSet;\nuse std::process;\nuse std::sync::Arc;\nuse tokio::task::JoinSet;\n\n/// Configuration for building a new Goose session\n///\n/// This struct contains all the parameters needed to create a new session,\n/// including session identification, extension configuration, and debug settings.\n#[derive(Clone, Debug)]\npub struct SessionBuilderConfig {\n    /// Session id, optional need to deduce from context\n    pub session_id: Option<String>,\n    /// Whether to resume an existing session\n    pub resume: bool,\n    /// Whether to run without a session file\n    pub no_session: bool,\n    /// List of stdio extension commands to add\n    pub extensions: Vec<String>,\n    /// List of remote extension commands to add\n    pub remote_extensions: Vec<String>,\n    /// List of streamable HTTP extension commands to add\n    pub streamable_http_extensions: Vec<String>,\n    /// List of builtin extension commands to add\n    pub builtins: Vec<String>,\n    /// List of extensions to enable, enable only this set and ignore configured ones\n    pub extensions_override: Option<Vec<ExtensionConfig>>,\n    /// Any additional system prompt to append to the default\n    pub additional_system_prompt: Option<String>,\n    /// Settings to override the global Goose settings\n    pub settings: Option<SessionSettings>,\n    /// Provider override from CLI arguments\n    pub provider: Option<String>,\n    /// Model override from CLI arguments\n    pub model: Option<String>,\n    /// Enable debug printing\n    pub debug: bool,\n    /// Maximum number of consecutive identical tool calls allowed\n    pub max_tool_repetitions: Option<u32>,\n    /// Maximum number of turns (iterations) allowed without user input\n    pub max_turns: Option<u32>,\n    /// ID of the scheduled job that triggered this session (if any)\n    pub scheduled_job_id: Option<String>,\n    /// Whether this session will be used interactively (affects debugging prompts)\n    pub interactive: bool,\n    /// Quiet mode - suppress non-response output\n    pub quiet: bool,\n    /// Sub-recipes to add to the session\n    pub sub_recipes: Option<Vec<SubRecipe>>,\n    /// Final output expected response\n    pub final_output_response: Option<Response>,\n    /// Retry configuration for automated validation and recovery\n    pub retry_config: Option<RetryConfig>,\n    /// Output format (text, json)\n    pub output_format: String,\n}\n\n/// Manual implementation of Default to ensure proper initialization of output_format\n/// This struct requires explicit default value for output_format field\nimpl Default for SessionBuilderConfig {\n    fn default() -> Self {\n        SessionBuilderConfig {\n            session_id: None,\n            resume: false,\n            no_session: false,\n            extensions: Vec::new(),\n            remote_extensions: Vec::new(),\n            streamable_http_extensions: Vec::new(),\n            builtins: Vec::new(),\n            extensions_override: None,\n            additional_system_prompt: None,\n            settings: None,\n            provider: None,\n            model: None,\n            debug: false,\n            max_tool_repetitions: None,\n            max_turns: None,\n            scheduled_job_id: None,\n            interactive: false,\n            quiet: false,\n            sub_recipes: None,\n            final_output_response: None,\n            retry_config: None,\n            output_format: \"text\".to_string(),\n        }\n    }\n}\n\n/// Offers to help debug an extension failure by creating a minimal debugging session\nasync fn offer_extension_debugging_help(\n    extension_name: &str,\n    error_message: &str,\n    provider: Arc<dyn goose::providers::base::Provider>,\n    interactive: bool,\n) -> Result<(), anyhow::Error> {\n    // Only offer debugging help in interactive mode\n    if !interactive {\n        return Ok(());\n    }\n\n    let help_prompt = format!(\n        \"Would you like me to help debug the '{}' extension failure?\",\n        extension_name\n    );\n\n    let should_help = match cliclack::confirm(help_prompt)\n        .initial_value(false)\n        .interact()\n    {\n        Ok(choice) => choice,\n        Err(e) => {\n            if e.kind() == std::io::ErrorKind::Interrupted {\n                return Ok(());\n            } else {\n                return Err(e.into());\n            }\n        }\n    };\n\n    if !should_help {\n        return Ok(());\n    }\n\n    println!(\"{}\", style(\"🔧 Starting debugging session...\").cyan());\n\n    // Create a debugging prompt with context about the extension failure\n    let debug_prompt = format!(\n        \"I'm having trouble starting an extension called '{}'. Here's the error I encountered:\\n\\n{}\\n\\nCan you help me diagnose what might be wrong and suggest how to fix it? Please consider common issues like:\\n- Missing dependencies or tools\\n- Configuration problems\\n- Network connectivity (for remote extensions)\\n- Permission issues\\n- Path or environment variable problems\",\n        extension_name,\n        error_message\n    );\n\n    // Create a minimal agent for debugging\n    let debug_agent = Agent::new();\n\n    let session = SessionManager::create_session(\n        std::env::current_dir()?,\n        \"CLI Session\".to_string(),\n        SessionType::Hidden,\n    )\n    .await?;\n\n    debug_agent.update_provider(provider, &session.id).await?;\n\n    // Add the developer extension if available to help with debugging\n    let extensions = get_all_extensions();\n    for ext_wrapper in extensions {\n        if ext_wrapper.enabled && ext_wrapper.config.name() == \"developer\" {\n            if let Err(e) = debug_agent.add_extension(ext_wrapper.config).await {\n                // If we can't add developer extension, continue without it\n                eprintln!(\n                    \"Note: Could not load developer extension for debugging: {}\",\n                    e\n                );\n            }\n            break;\n        }\n    }\n\n    let mut debug_session = CliSession::new(\n        debug_agent,\n        session.id,\n        false,\n        None,\n        None,\n        None,\n        None,\n        \"text\".to_string(),\n    )\n    .await;\n\n    // Process the debugging request\n    println!(\"{}\", style(\"Analyzing the extension failure...\").yellow());\n    match debug_session.headless(debug_prompt).await {\n        Ok(_) => {\n            println!(\n                \"{}\",\n                style(\"✅ Debugging session completed. Check the suggestions above.\").green()\n            );\n        }\n        Err(e) => {\n            eprintln!(\n                \"{}\",\n                style(format!(\"❌ Debugging session failed: {}\", e)).red()\n            );\n        }\n    }\n    Ok(())\n}\n\nfn check_missing_extensions_or_exit(saved_extensions: &[ExtensionConfig]) {\n    let missing: Vec<_> = saved_extensions\n        .iter()\n        .filter(|ext| get_extension_by_name(&ext.name()).is_none())\n        .cloned()\n        .collect();\n\n    if !missing.is_empty() {\n        let names = missing\n            .iter()\n            .map(|e| e.name())\n            .collect::<Vec<_>>()\n            .join(\", \");\n\n        if !cliclack::confirm(format!(\n            \"Extension(s) {} from previous session are no longer available. Restore for this session?\",\n            names\n        ))\n        .initial_value(true)\n        .interact()\n        .unwrap_or(false)\n        {\n            println!(\"{}\", style(\"Resume cancelled.\").yellow());\n            process::exit(0);\n        }\n    }\n}\n\n#[derive(Clone, Debug, Default)]\npub struct SessionSettings {\n    pub goose_model: Option<String>,\n    pub goose_provider: Option<String>,\n    pub temperature: Option<f32>,\n}\n\npub async fn build_session(session_config: SessionBuilderConfig) -> CliSession {\n    goose::posthog::set_session_context(\"cli\", session_config.resume);\n\n    let config = Config::global();\n\n    let (saved_provider, saved_model_config) = if session_config.resume {\n        if let Some(ref session_id) = session_config.session_id {\n            match SessionManager::get_session(session_id, false).await {\n                Ok(session_data) => (session_data.provider_name, session_data.model_config),\n                Err(_) => (None, None),\n            }\n        } else {\n            (None, None)\n        }\n    } else {\n        (None, None)\n    };\n\n    let provider_name = session_config\n        .provider\n        .or(saved_provider)\n        .or_else(|| {\n            session_config\n                .settings\n                .as_ref()\n                .and_then(|s| s.goose_provider.clone())\n        })\n        .or_else(|| config.get_goose_provider().ok())\n        .expect(\"No provider configured. Run 'goose configure' first\");\n\n    let model_name = session_config\n        .model\n        .or_else(|| saved_model_config.as_ref().map(|mc| mc.model_name.clone()))\n        .or_else(|| {\n            session_config\n                .settings\n                .as_ref()\n                .and_then(|s| s.goose_model.clone())\n        })\n        .or_else(|| config.get_goose_model().ok())\n        .expect(\"No model configured. Run 'goose configure' first\");\n\n    let model_config = if session_config.resume\n        && saved_model_config\n            .as_ref()\n            .is_some_and(|mc| mc.model_name == model_name)\n    {\n        let mut config = saved_model_config.unwrap();\n        if let Some(temp) = session_config.settings.as_ref().and_then(|s| s.temperature) {\n            config = config.with_temperature(Some(temp));\n        }\n        config\n    } else {\n        let temperature = session_config.settings.as_ref().and_then(|s| s.temperature);\n        goose::model::ModelConfig::new(&model_name)\n            .unwrap_or_else(|e| {\n                output::render_error(&format!(\"Failed to create model configuration: {}\", e));\n                process::exit(1);\n            })\n            .with_temperature(temperature)\n    };\n\n    let agent: Agent = Agent::new();\n\n    agent\n        .apply_recipe_components(\n            session_config.sub_recipes,\n            session_config.final_output_response,\n            true,\n        )\n        .await;\n\n    let new_provider = match create(&provider_name, model_config).await {\n        Ok(provider) => provider,\n        Err(e) => {\n            output::render_error(&format!(\n                \"Error {}.\\n\\\n                Please check your system keychain and run 'goose configure' again.\\n\\\n                If your system is unable to use the keyring, please try setting secret key(s) via environment variables.\\n\\\n                For more info, see: https://block.github.io/goose/docs/troubleshooting/#keychainkeyring-errors\",\n                e\n            ));\n            process::exit(1);\n        }\n    };\n    let provider_for_display = Arc::clone(&new_provider);\n\n    if let Some(lead_worker) = new_provider.as_lead_worker() {\n        let (lead_model, worker_model) = lead_worker.get_model_info();\n        tracing::info!(\n            \"🤖 Lead/Worker Mode Enabled: Lead model (first 3 turns): {}, Worker model (turn 4+): {}, Auto-fallback on failures: Enabled\",\n            lead_model,\n            worker_model\n        );\n    } else {\n        tracing::info!(\"🤖 Using model: {}\", model_name);\n    }\n\n    let session_id: String = if session_config.no_session {\n        let working_dir = std::env::current_dir().expect(\"Could not get working directory\");\n        let session = SessionManager::create_session(\n            working_dir,\n            \"CLI Session\".to_string(),\n            SessionType::Hidden,\n        )\n        .await\n        .expect(\"Could not create session\");\n        session.id\n    } else if session_config.resume {\n        if let Some(session_id) = session_config.session_id {\n            match SessionManager::get_session(&session_id, false).await {\n                Ok(_) => session_id,\n                Err(_) => {\n                    output::render_error(&format!(\n                        \"Cannot resume session {} - no such session exists\",\n                        style(&session_id).cyan()\n                    ));\n                    process::exit(1);\n                }\n            }\n        } else {\n            match SessionManager::list_sessions().await {\n                Ok(sessions) if !sessions.is_empty() => sessions[0].id.clone(),\n                _ => {\n                    output::render_error(\"Cannot resume - no previous sessions found\");\n                    process::exit(1);\n                }\n            }\n        }\n    } else {\n        session_config.session_id.unwrap()\n    };\n\n    agent\n        .update_provider(new_provider, &session_id)\n        .await\n        .unwrap_or_else(|e| {\n            output::render_error(&format!(\"Failed to initialize agent: {}\", e));\n            process::exit(1);\n        });\n\n    agent\n        .extension_manager\n        .set_context(PlatformExtensionContext {\n            session_id: Some(session_id.clone()),\n            extension_manager: Some(Arc::downgrade(&agent.extension_manager)),\n        })\n        .await;\n\n    if session_config.resume {\n        let session = SessionManager::get_session(&session_id, false)\n            .await\n            .unwrap_or_else(|e| {\n                output::render_error(&format!(\"Failed to read session metadata: {}\", e));\n                process::exit(1);\n            });\n\n        let current_workdir =\n            std::env::current_dir().expect(\"Failed to get current working directory\");\n        if current_workdir != session.working_dir {\n            let change_workdir = cliclack::confirm(format!(\"{} The original working directory of this session was set to {}. Your current directory is {}. Do you want to switch back to the original working directory?\", style(\"WARNING:\").yellow(), style(session.working_dir.display()).cyan(), style(current_workdir.display()).cyan()))\n                    .initial_value(true)\n                    .interact().expect(\"Failed to get user input\");\n\n            if change_workdir {\n                if !session.working_dir.exists() {\n                    output::render_error(&format!(\n                        \"Cannot switch to original working directory - {} no longer exists\",\n                        style(session.working_dir.display()).cyan()\n                    ));\n                } else if let Err(e) = std::env::set_current_dir(&session.working_dir) {\n                    output::render_error(&format!(\n                        \"Failed to switch to original working directory: {}\",\n                        e\n                    ));\n                }\n            }\n        }\n    }\n\n    // Setup extensions for the agent\n    // Extensions need to be added after the session is created because we change directory when resuming a session\n    // If we get extensions_override, only run those extensions and none other\n    let extensions_to_run: Vec<_> = if let Some(extensions) = session_config.extensions_override {\n        extensions.into_iter().collect()\n    } else if session_config.resume {\n        match SessionManager::get_session(&session_id, false).await {\n            Ok(session_data) => {\n                if let Some(saved_state) =\n                    EnabledExtensionsState::from_extension_data(&session_data.extension_data)\n                {\n                    check_missing_extensions_or_exit(&saved_state.extensions);\n                    saved_state.extensions\n                } else {\n                    get_enabled_extensions()\n                }\n            }\n            _ => get_enabled_extensions(),\n        }\n    } else {\n        get_enabled_extensions()\n    };\n\n    let mut set = JoinSet::new();\n    let agent_ptr = Arc::new(agent);\n\n    let mut waiting_on = HashSet::new();\n    for extension in extensions_to_run {\n        waiting_on.insert(extension.name());\n        let agent_ptr = agent_ptr.clone();\n        set.spawn(async move {\n            (\n                extension.name(),\n                agent_ptr.add_extension(extension.clone()).await,\n            )\n        });\n    }\n\n    let get_message = |waiting_on: &HashSet<String>| {\n        let mut names: Vec<_> = waiting_on.iter().cloned().collect();\n        names.sort();\n        format!(\"starting {} extensions: {}\", names.len(), names.join(\", \"))\n    };\n\n    let spinner = cliclack::spinner();\n    spinner.start(get_message(&waiting_on));\n\n    let mut offer_debug = Vec::new();\n    while let Some(result) = set.join_next().await {\n        match result {\n            Ok((name, Ok(_))) => {\n                waiting_on.remove(&name);\n                spinner.set_message(get_message(&waiting_on));\n            }\n            Ok((name, Err(e))) => offer_debug.push((name, e)),\n            Err(e) => tracing::error!(\"failed to add extension: {}\", e),\n        }\n    }\n\n    spinner.clear();\n\n    for (name, err) in offer_debug {\n        if let Err(debug_err) = offer_extension_debugging_help(\n            &name,\n            &err.to_string(),\n            Arc::clone(&provider_for_display),\n            session_config.interactive,\n        )\n        .await\n        {\n            eprintln!(\"Note: Could not start debugging session: {}\", debug_err);\n        }\n    }\n\n    // Determine editor mode\n    let edit_mode = config\n        .get_param::<String>(\"EDIT_MODE\")\n        .ok()\n        .and_then(|edit_mode| match edit_mode.to_lowercase().as_str() {\n            \"emacs\" => Some(EditMode::Emacs),\n            \"vi\" => Some(EditMode::Vi),\n            _ => {\n                eprintln!(\"Invalid EDIT_MODE specified, defaulting to Emacs\");\n                None\n            }\n        });\n\n    let debug_mode = session_config.debug || config.get_param(\"GOOSE_DEBUG\").unwrap_or(false);\n\n    // Create new session\n    let mut session = CliSession::new(\n        Arc::try_unwrap(agent_ptr).unwrap_or_else(|_| panic!(\"There should be no more references\")),\n        session_id.clone(),\n        debug_mode,\n        session_config.scheduled_job_id.clone(),\n        session_config.max_turns,\n        edit_mode,\n        session_config.retry_config.clone(),\n        session_config.output_format.clone(),\n    )\n    .await;\n\n    // Add stdio extensions if provided\n    for extension_str in session_config.extensions {\n        if let Err(e) = session.add_extension(extension_str.clone()).await {\n            eprintln!(\n                \"{}\",\n                style(format!(\n                    \"Warning: Failed to start stdio extension '{}' ({}), continuing without it\",\n                    extension_str, e\n                ))\n                .yellow()\n            );\n\n            // Offer debugging help\n            if let Err(debug_err) = offer_extension_debugging_help(\n                &extension_str,\n                &e.to_string(),\n                Arc::clone(&provider_for_display),\n                session_config.interactive,\n            )\n            .await\n            {\n                eprintln!(\"Note: Could not start debugging session: {}\", debug_err);\n            }\n        }\n    }\n\n    // Add remote extensions if provided\n    for extension_str in session_config.remote_extensions {\n        if let Err(e) = session.add_remote_extension(extension_str.clone()).await {\n            eprintln!(\n                \"{}\",\n                style(format!(\n                    \"Warning: Failed to start remote extension '{}' ({}), continuing without it\",\n                    extension_str, e\n                ))\n                .yellow()\n            );\n\n            // Offer debugging help\n            if let Err(debug_err) = offer_extension_debugging_help(\n                &extension_str,\n                &e.to_string(),\n                Arc::clone(&provider_for_display),\n                session_config.interactive,\n            )\n            .await\n            {\n                eprintln!(\"Note: Could not start debugging session: {}\", debug_err);\n            }\n        }\n    }\n\n    // Add streamable HTTP extensions if provided\n    for extension_str in session_config.streamable_http_extensions {\n        if let Err(e) = session\n            .add_streamable_http_extension(extension_str.clone())\n            .await\n        {\n            eprintln!(\n                \"{}\",\n                style(format!(\n                    \"Warning: Failed to start streamable HTTP extension '{}' ({}), continuing without it\",\n                    extension_str, e\n                ))\n                .yellow()\n            );\n\n            // Offer debugging help\n            if let Err(debug_err) = offer_extension_debugging_help(\n                &extension_str,\n                &e.to_string(),\n                Arc::clone(&provider_for_display),\n                session_config.interactive,\n            )\n            .await\n            {\n                eprintln!(\"Note: Could not start debugging session: {}\", debug_err);\n            }\n        }\n    }\n\n    // Add builtin extensions\n    for builtin in session_config.builtins {\n        if let Err(e) = session.add_builtin(builtin.clone()).await {\n            eprintln!(\n                \"{}\",\n                style(format!(\n                    \"Warning: Failed to start builtin extension '{}' ({}), continuing without it\",\n                    builtin, e\n                ))\n                .yellow()\n            );\n\n            // Offer debugging help\n            if let Err(debug_err) = offer_extension_debugging_help(\n                &builtin,\n                &e.to_string(),\n                Arc::clone(&provider_for_display),\n                session_config.interactive,\n            )\n            .await\n            {\n                eprintln!(\"Note: Could not start debugging session: {}\", debug_err);\n            }\n        }\n    }\n\n    let session_config_for_save = SessionConfig {\n        id: session_id.clone(),\n        schedule_id: None,\n        max_turns: None,\n        retry_config: None,\n    };\n\n    if let Err(e) = session\n        .agent\n        .save_extension_state(&session_config_for_save)\n        .await\n    {\n        tracing::warn!(\"Failed to save initial extension state: {}\", e);\n    }\n\n    // Add CLI-specific system prompt extension\n    session\n        .agent\n        .extend_system_prompt(super::prompt::get_cli_prompt())\n        .await;\n\n    if let Some(additional_prompt) = session_config.additional_system_prompt {\n        session.agent.extend_system_prompt(additional_prompt).await;\n    }\n\n    // Only override system prompt if a system override exists\n    let system_prompt_file: Option<String> = config.get_param(\"GOOSE_SYSTEM_PROMPT_FILE_PATH\").ok();\n    if let Some(ref path) = system_prompt_file {\n        let override_prompt =\n            std::fs::read_to_string(path).expect(\"Failed to read system prompt file\");\n        session.agent.override_system_prompt(override_prompt).await;\n    }\n\n    // Display session information unless in quiet mode\n    if !session_config.quiet {\n        output::display_session_info(\n            session_config.resume,\n            &provider_name,\n            &model_name,\n            &Some(session_id),\n            Some(&provider_for_display),\n        );\n    }\n    session\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_session_builder_config_creation() {\n        let config = SessionBuilderConfig {\n            session_id: None,\n            resume: false,\n            no_session: false,\n            extensions: vec![\"echo test\".to_string()],\n            remote_extensions: vec![\"http://example.com\".to_string()],\n            streamable_http_extensions: vec![\"http://example.com/streamable\".to_string()],\n            builtins: vec![\"developer\".to_string()],\n            extensions_override: None,\n            additional_system_prompt: Some(\"Test prompt\".to_string()),\n            settings: None,\n            provider: None,\n            model: None,\n            debug: true,\n            max_tool_repetitions: Some(5),\n            max_turns: None,\n            scheduled_job_id: None,\n            interactive: true,\n            quiet: false,\n            sub_recipes: None,\n            final_output_response: None,\n            retry_config: None,\n            output_format: \"text\".to_string(),\n        };\n\n        assert_eq!(config.extensions.len(), 1);\n        assert_eq!(config.remote_extensions.len(), 1);\n        assert_eq!(config.streamable_http_extensions.len(), 1);\n        assert_eq!(config.builtins.len(), 1);\n        assert!(config.debug);\n        assert_eq!(config.max_tool_repetitions, Some(5));\n        assert!(config.max_turns.is_none());\n        assert!(config.scheduled_job_id.is_none());\n        assert!(config.interactive);\n        assert!(!config.quiet);\n    }\n\n    #[test]\n    fn test_session_builder_config_default() {\n        let config = SessionBuilderConfig::default();\n\n        assert!(config.session_id.is_none());\n        assert!(!config.resume);\n        assert!(!config.no_session);\n        assert!(config.extensions.is_empty());\n        assert!(config.remote_extensions.is_empty());\n        assert!(config.streamable_http_extensions.is_empty());\n        assert!(config.builtins.is_empty());\n        assert!(config.extensions_override.is_none());\n        assert!(config.additional_system_prompt.is_none());\n        assert!(!config.debug);\n        assert!(config.max_tool_repetitions.is_none());\n        assert!(config.max_turns.is_none());\n        assert!(config.scheduled_job_id.is_none());\n        assert!(!config.interactive);\n        assert!(!config.quiet);\n        assert!(config.final_output_response.is_none());\n    }\n\n    #[tokio::test]\n    async fn test_offer_extension_debugging_help_function_exists() {\n        // This test just verifies the function compiles and can be called\n        // We can't easily test the interactive parts without mocking\n\n        // We can't actually test the full function without a real provider and user interaction\n        // But we can at least verify it compiles and the function signature is correct\n        let extension_name = \"test-extension\";\n        let error_message = \"test error\";\n\n        // This test mainly serves as a compilation check\n        assert_eq!(extension_name, \"test-extension\");\n        assert_eq!(error_message, \"test error\");\n    }\n}\n"
                  },
                  "annotations": {
                    "audience": [
                      "assistant"
                    ]
                  }
                },
                {
                  "type": "text",
                  "text": "### /Users/baxen/Development/goose/crates/goose-cli/src/session/builder.rs\n```rust\n1: use super::output;\n2: use super::CliSession;\n3: use console::style;\n4: use goose::agents::types::{RetryConfig, SessionConfig};\n5: use goose::agents::Agent;\n6: use goose::config::{\n7:     extensions::get_extension_by_name, get_all_extensions, get_enabled_extensions, Config,\n8:     ExtensionConfig,\n9: };\n10: use goose::providers::create;\n11: use goose::recipe::{Response, SubRecipe};\n12: \n13: use goose::agents::extension::PlatformExtensionContext;\n14: use goose::session::session_manager::SessionType;\n15: use goose::session::SessionManager;\n16: use goose::session::{EnabledExtensionsState, ExtensionState};\n17: use rustyline::EditMode;\n18: use std::collections::HashSet;\n19: use std::process;\n20: use std::sync::Arc;\n21: use tokio::task::JoinSet;\n22: \n23: /// Configuration for building a new Goose session\n24: ///\n25: /// This struct contains all the parameters needed to create a new session,\n26: /// including session identification, extension configuration, and debug settings.\n27: #[derive(Clone, Debug)]\n28: pub struct SessionBuilderConfig {\n29:     /// Session id, optional need to deduce from context\n30:     pub session_id: Option<String>,\n31:     /// Whether to resume an existing session\n32:     pub resume: bool,\n33:     /// Whether to run without a session file\n34:     pub no_session: bool,\n35:     /// List of stdio extension commands to add\n36:     pub extensions: Vec<String>,\n37:     /// List of remote extension commands to add\n38:     pub remote_extensions: Vec<String>,\n39:     /// List of streamable HTTP extension commands to add\n40:     pub streamable_http_extensions: Vec<String>,\n41:     /// List of builtin extension commands to add\n42:     pub builtins: Vec<String>,\n43:     /// List of extensions to enable, enable only this set and ignore configured ones\n44:     pub extensions_override: Option<Vec<ExtensionConfig>>,\n45:     /// Any additional system prompt to append to the default\n46:     pub additional_system_prompt: Option<String>,\n47:     /// Settings to override the global Goose settings\n48:     pub settings: Option<SessionSettings>,\n49:     /// Provider override from CLI arguments\n50:     pub provider: Option<String>,\n51:     /// Model override from CLI arguments\n52:     pub model: Option<String>,\n53:     /// Enable debug printing\n54:     pub debug: bool,\n55:     /// Maximum number of consecutive identical tool calls allowed\n56:     pub max_tool_repetitions: Option<u32>,\n57:     /// Maximum number of turns (iterations) allowed without user input\n58:     pub max_turns: Option<u32>,\n59:     /// ID of the scheduled job that triggered this session (if any)\n60:     pub scheduled_job_id: Option<String>,\n61:     /// Whether this session will be used interactively (affects debugging prompts)\n62:     pub interactive: bool,\n63:     /// Quiet mode - suppress non-response output\n64:     pub quiet: bool,\n65:     /// Sub-recipes to add to the session\n66:     pub sub_recipes: Option<Vec<SubRecipe>>,\n67:     /// Final output expected response\n68:     pub final_output_response: Option<Response>,\n69:     /// Retry configuration for automated validation and recovery\n70:     pub retry_config: Option<RetryConfig>,\n71:     /// Output format (text, json)\n72:     pub output_format: String,\n73: }\n74: \n75: /// Manual implementation of Default to ensure proper initialization of output_format\n76: /// This struct requires explicit default value for output_format field\n77: impl Default for SessionBuilderConfig {\n78:     fn default() -> Self {\n79:         SessionBuilderConfig {\n80:             session_id: None,\n81:             resume: false,\n82:             no_session: false,\n83:             extensions: Vec::new(),\n84:             remote_extensions: Vec::new(),\n85:             streamable_http_extensions: Vec::new(),\n86:             builtins: Vec::new(),\n87:             extensions_override: None,\n88:             additional_system_prompt: None,\n89:             settings: None,\n90:             provider: None,\n91:             model: None,\n92:             debug: false,\n93:             max_tool_repetitions: None,\n94:             max_turns: None,\n95:             scheduled_job_id: None,\n96:             interactive: false,\n97:             quiet: false,\n98:             sub_recipes: None,\n99:             final_output_response: None,\n100:             retry_config: None,\n101:             output_format: \"text\".to_string(),\n102:         }\n103:     }\n104: }\n105: \n106: /// Offers to help debug an extension failure by creating a minimal debugging session\n107: async fn offer_extension_debugging_help(\n108:     extension_name: &str,\n109:     error_message: &str,\n110:     provider: Arc<dyn goose::providers::base::Provider>,\n111:     interactive: bool,\n112: ) -> Result<(), anyhow::Error> {\n113:     // Only offer debugging help in interactive mode\n114:     if !interactive {\n115:         return Ok(());\n116:     }\n117: \n118:     let help_prompt = format!(\n119:         \"Would you like me to help debug the '{}' extension failure?\",\n120:         extension_name\n121:     );\n122: \n123:     let should_help = match cliclack::confirm(help_prompt)\n124:         .initial_value(false)\n125:         .interact()\n126:     {\n127:         Ok(choice) => choice,\n128:         Err(e) => {\n129:             if e.kind() == std::io::ErrorKind::Interrupted {\n130:                 return Ok(());\n131:             } else {\n132:                 return Err(e.into());\n133:             }\n134:         }\n135:     };\n136: \n137:     if !should_help {\n138:         return Ok(());\n139:     }\n140: \n141:     println!(\"{}\", style(\"🔧 Starting debugging session...\").cyan());\n142: \n143:     // Create a debugging prompt with context about the extension failure\n144:     let debug_prompt = format!(\n145:         \"I'm having trouble starting an extension called '{}'. Here's the error I encountered:\\n\\n{}\\n\\nCan you help me diagnose what might be wrong and suggest how to fix it? Please consider common issues like:\\n- Missing dependencies or tools\\n- Configuration problems\\n- Network connectivity (for remote extensions)\\n- Permission issues\\n- Path or environment variable problems\",\n146:         extension_name,\n147:         error_message\n148:     );\n149: \n150:     // Create a minimal agent for debugging\n151:     let debug_agent = Agent::new();\n152: \n153:     let session = SessionManager::create_session(\n154:         std::env::current_dir()?,\n155:         \"CLI Session\".to_string(),\n156:         SessionType::Hidden,\n157:     )\n158:     .await?;\n159: \n160:     debug_agent.update_provider(provider, &session.id).await?;\n161: \n162:     // Add the developer extension if available to help with debugging\n163:     let extensions = get_all_extensions();\n164:     for ext_wrapper in extensions {\n165:         if ext_wrapper.enabled && ext_wrapper.config.name() == \"developer\" {\n166:             if let Err(e) = debug_agent.add_extension(ext_wrapper.config).await {\n167:                 // If we can't add developer extension, continue without it\n168:                 eprintln!(\n169:                     \"Note: Could not load developer extension for debugging: {}\",\n170:                     e\n171:                 );\n172:             }\n173:             break;\n174:         }\n175:     }\n176: \n177:     let mut debug_session = CliSession::new(\n178:         debug_agent,\n179:         session.id,\n180:         false,\n181:         None,\n182:         None,\n183:         None,\n184:         None,\n185:         \"text\".to_string(),\n186:     )\n187:     .await;\n188: \n189:     // Process the debugging request\n190:     println!(\"{}\", style(\"Analyzing the extension failure...\").yellow());\n191:     match debug_session.headless(debug_prompt).await {\n192:         Ok(_) => {\n193:             println!(\n194:                 \"{}\",\n195:                 style(\"✅ Debugging session completed. Check the suggestions above.\").green()\n196:             );\n197:         }\n198:         Err(e) => {\n199:             eprintln!(\n200:                 \"{}\",\n201:                 style(format!(\"❌ Debugging session failed: {}\", e)).red()\n202:             );\n203:         }\n204:     }\n205:     Ok(())\n206: }\n207: \n208: fn check_missing_extensions_or_exit(saved_extensions: &[ExtensionConfig]) {\n209:     let missing: Vec<_> = saved_extensions\n210:         .iter()\n211:         .filter(|ext| get_extension_by_name(&ext.name()).is_none())\n212:         .cloned()\n213:         .collect();\n214: \n215:     if !missing.is_empty() {\n216:         let names = missing\n217:             .iter()\n218:             .map(|e| e.name())\n219:             .collect::<Vec<_>>()\n220:             .join(\", \");\n221: \n222:         if !cliclack::confirm(format!(\n223:             \"Extension(s) {} from previous session are no longer available. Restore for this session?\",\n224:             names\n225:         ))\n226:         .initial_value(true)\n227:         .interact()\n228:         .unwrap_or(false)\n229:         {\n230:             println!(\"{}\", style(\"Resume cancelled.\").yellow());\n231:             process::exit(0);\n232:         }\n233:     }\n234: }\n235: \n236: #[derive(Clone, Debug, Default)]\n237: pub struct SessionSettings {\n238:     pub goose_model: Option<String>,\n239:     pub goose_provider: Option<String>,\n240:     pub temperature: Option<f32>,\n241: }\n242: \n243: pub async fn build_session(session_config: SessionBuilderConfig) -> CliSession {\n244:     goose::posthog::set_session_context(\"cli\", session_config.resume);\n245: \n246:     let config = Config::global();\n247: \n248:     let (saved_provider, saved_model_config) = if session_config.resume {\n249:         if let Some(ref session_id) = session_config.session_id {\n250:             match SessionManager::get_session(session_id, false).await {\n251:                 Ok(session_data) => (session_data.provider_name, session_data.model_config),\n252:                 Err(_) => (None, None),\n253:             }\n254:         } else {\n255:             (None, None)\n256:         }\n257:     } else {\n258:         (None, None)\n259:     };\n260: \n261:     let provider_name = session_config\n262:         .provider\n263:         .or(saved_provider)\n264:         .or_else(|| {\n265:             session_config\n266:                 .settings\n267:                 .as_ref()\n268:                 .and_then(|s| s.goose_provider.clone())\n269:         })\n270:         .or_else(|| config.get_goose_provider().ok())\n271:         .expect(\"No provider configured. Run 'goose configure' first\");\n272: \n273:     let model_name = session_config\n274:         .model\n275:         .or_else(|| saved_model_config.as_ref().map(|mc| mc.model_name.clone()))\n276:         .or_else(|| {\n277:             session_config\n278:                 .settings\n279:                 .as_ref()\n280:                 .and_then(|s| s.goose_model.clone())\n281:         })\n282:         .or_else(|| config.get_goose_model().ok())\n283:         .expect(\"No model configured. Run 'goose configure' first\");\n284: \n285:     let model_config = if session_config.resume\n286:         && saved_model_config\n287:             .as_ref()\n288:             .is_some_and(|mc| mc.model_name == model_name)\n289:     {\n290:         let mut config = saved_model_config.unwrap();\n291:         if let Some(temp) = session_config.settings.as_ref().and_then(|s| s.temperature) {\n292:             config = config.with_temperature(Some(temp));\n293:         }\n294:         config\n295:     } else {\n296:         let temperature = session_config.settings.as_ref().and_then(|s| s.temperature);\n297:         goose::model::ModelConfig::new(&model_name)\n298:             .unwrap_or_else(|e| {\n299:                 output::render_error(&format!(\"Failed to create model configuration: {}\", e));\n300:                 process::exit(1);\n301:             })\n302:             .with_temperature(temperature)\n303:     };\n304: \n305:     let agent: Agent = Agent::new();\n306: \n307:     agent\n308:         .apply_recipe_components(\n309:             session_config.sub_recipes,\n310:             session_config.final_output_response,\n311:             true,\n312:         )\n313:         .await;\n314: \n315:     let new_provider = match create(&provider_name, model_config).await {\n316:         Ok(provider) => provider,\n317:         Err(e) => {\n318:             output::render_error(&format!(\n319:                 \"Error {}.\\n\\\n320:                 Please check your system keychain and run 'goose configure' again.\\n\\\n321:                 If your system is unable to use the keyring, please try setting secret key(s) via environment variables.\\n\\\n322:                 For more info, see: https://block.github.io/goose/docs/troubleshooting/#keychainkeyring-errors\",\n323:                 e\n324:             ));\n325:             process::exit(1);\n326:         }\n327:     };\n328:     let provider_for_display = Arc::clone(&new_provider);\n329: \n330:     if let Some(lead_worker) = new_provider.as_lead_worker() {\n331:         let (lead_model, worker_model) = lead_worker.get_model_info();\n332:         tracing::info!(\n333:             \"🤖 Lead/Worker Mode Enabled: Lead model (first 3 turns): {}, Worker model (turn 4+): {}, Auto-fallback on failures: Enabled\",\n334:             lead_model,\n335:             worker_model\n336:         );\n337:     } else {\n338:         tracing::info!(\"🤖 Using model: {}\", model_name);\n339:     }\n340: \n341:     let session_id: String = if session_config.no_session {\n342:         let working_dir = std::env::current_dir().expect(\"Could not get working directory\");\n343:         let session = SessionManager::create_session(\n344:             working_dir,\n345:             \"CLI Session\".to_string(),\n346:             SessionType::Hidden,\n347:         )\n348:         .await\n349:         .expect(\"Could not create session\");\n350:         session.id\n351:     } else if session_config.resume {\n352:         if let Some(session_id) = session_config.session_id {\n353:             match SessionManager::get_session(&session_id, false).await {\n354:                 Ok(_) => session_id,\n355:                 Err(_) => {\n356:                     output::render_error(&format!(\n357:                         \"Cannot resume session {} - no such session exists\",\n358:                         style(&session_id).cyan()\n359:                     ));\n360:                     process::exit(1);\n361:                 }\n362:             }\n363:         } else {\n364:             match SessionManager::list_sessions().await {\n365:                 Ok(sessions) if !sessions.is_empty() => sessions[0].id.clone(),\n366:                 _ => {\n367:                     output::render_error(\"Cannot resume - no previous sessions found\");\n368:                     process::exit(1);\n369:                 }\n370:             }\n371:         }\n372:     } else {\n373:         session_config.session_id.unwrap()\n374:     };\n375: \n376:     agent\n377:         .update_provider(new_provider, &session_id)\n378:         .await\n379:         .unwrap_or_else(|e| {\n380:             output::render_error(&format!(\"Failed to initialize agent: {}\", e));\n381:             process::exit(1);\n382:         });\n383: \n384:     agent\n385:         .extension_manager\n386:         .set_context(PlatformExtensionContext {\n387:             session_id: Some(session_id.clone()),\n388:             extension_manager: Some(Arc::downgrade(&agent.extension_manager)),\n389:         })\n390:         .await;\n391: \n392:     if session_config.resume {\n393:         let session = SessionManager::get_session(&session_id, false)\n394:             .await\n395:             .unwrap_or_else(|e| {\n396:                 output::render_error(&format!(\"Failed to read session metadata: {}\", e));\n397:                 process::exit(1);\n398:             });\n399: \n400:         let current_workdir =\n401:             std::env::current_dir().expect(\"Failed to get current working directory\");\n402:         if current_workdir != session.working_dir {\n403:             let change_workdir = cliclack::confirm(format!(\"{} The original working directory of this session was set to {}. Your current directory is {}. Do you want to switch back to the original working directory?\", style(\"WARNING:\").yellow(), style(session.working_dir.display()).cyan(), style(current_workdir.display()).cyan()))\n404:                     .initial_value(true)\n405:                     .interact().expect(\"Failed to get user input\");\n406: \n407:             if change_workdir {\n408:                 if !session.working_dir.exists() {\n409:                     output::render_error(&format!(\n410:                         \"Cannot switch to original working directory - {} no longer exists\",\n411:                         style(session.working_dir.display()).cyan()\n412:                     ));\n413:                 } else if let Err(e) = std::env::set_current_dir(&session.working_dir) {\n414:                     output::render_error(&format!(\n415:                         \"Failed to switch to original working directory: {}\",\n416:                         e\n417:                     ));\n418:                 }\n419:             }\n420:         }\n421:     }\n422: \n423:     // Setup extensions for the agent\n424:     // Extensions need to be added after the session is created because we change directory when resuming a session\n425:     // If we get extensions_override, only run those extensions and none other\n426:     let extensions_to_run: Vec<_> = if let Some(extensions) = session_config.extensions_override {\n427:         extensions.into_iter().collect()\n428:     } else if session_config.resume {\n429:         match SessionManager::get_session(&session_id, false).await {\n430:             Ok(session_data) => {\n431:                 if let Some(saved_state) =\n432:                     EnabledExtensionsState::from_extension_data(&session_data.extension_data)\n433:                 {\n434:                     check_missing_extensions_or_exit(&saved_state.extensions);\n435:                     saved_state.extensions\n436:                 } else {\n437:                     get_enabled_extensions()\n438:                 }\n439:             }\n440:             _ => get_enabled_extensions(),\n441:         }\n442:     } else {\n443:         get_enabled_extensions()\n444:     };\n445: \n446:     let mut set = JoinSet::new();\n447:     let agent_ptr = Arc::new(agent);\n448: \n449:     let mut waiting_on = HashSet::new();\n450:     for extension in extensions_to_run {\n451:         waiting_on.insert(extension.name());\n452:         let agent_ptr = agent_ptr.clone();\n453:         set.spawn(async move {\n454:             (\n455:                 extension.name(),\n456:                 agent_ptr.add_extension(extension.clone()).await,\n457:             )\n458:         });\n459:     }\n460: \n461:     let get_message = |waiting_on: &HashSet<String>| {\n462:         let mut names: Vec<_> = waiting_on.iter().cloned().collect();\n463:         names.sort();\n464:         format!(\"starting {} extensions: {}\", names.len(), names.join(\", \"))\n465:     };\n466: \n467:     let spinner = cliclack::spinner();\n468:     spinner.start(get_message(&waiting_on));\n469: \n470:     let mut offer_debug = Vec::new();\n471:     while let Some(result) = set.join_next().await {\n472:         match result {\n473:             Ok((name, Ok(_))) => {\n474:                 waiting_on.remove(&name);\n475:                 spinner.set_message(get_message(&waiting_on));\n476:             }\n477:             Ok((name, Err(e))) => offer_debug.push((name, e)),\n478:             Err(e) => tracing::error!(\"failed to add extension: {}\", e),\n479:         }\n480:     }\n481: \n482:     spinner.clear();\n483: \n484:     for (name, err) in offer_debug {\n485:         if let Err(debug_err) = offer_extension_debugging_help(\n486:             &name,\n487:             &err.to_string(),\n488:             Arc::clone(&provider_for_display),\n489:             session_config.interactive,\n490:         )\n491:         .await\n492:         {\n493:             eprintln!(\"Note: Could not start debugging session: {}\", debug_err);\n494:         }\n495:     }\n496: \n497:     // Determine editor mode\n498:     let edit_mode = config\n499:         .get_param::<String>(\"EDIT_MODE\")\n500:         .ok()\n501:         .and_then(|edit_mode| match edit_mode.to_lowercase().as_str() {\n502:             \"emacs\" => Some(EditMode::Emacs),\n503:             \"vi\" => Some(EditMode::Vi),\n504:             _ => {\n505:                 eprintln!(\"Invalid EDIT_MODE specified, defaulting to Emacs\");\n506:                 None\n507:             }\n508:         });\n509: \n510:     let debug_mode = session_config.debug || config.get_param(\"GOOSE_DEBUG\").unwrap_or(false);\n511: \n512:     // Create new session\n513:     let mut session = CliSession::new(\n514:         Arc::try_unwrap(agent_ptr).unwrap_or_else(|_| panic!(\"There should be no more references\")),\n515:         session_id.clone(),\n516:         debug_mode,\n517:         session_config.scheduled_job_id.clone(),\n518:         session_config.max_turns,\n519:         edit_mode,\n520:         session_config.retry_config.clone(),\n521:         session_config.output_format.clone(),\n522:     )\n523:     .await;\n524: \n525:     // Add stdio extensions if provided\n526:     for extension_str in session_config.extensions {\n527:         if let Err(e) = session.add_extension(extension_str.clone()).await {\n528:             eprintln!(\n529:                 \"{}\",\n530:                 style(format!(\n531:                     \"Warning: Failed to start stdio extension '{}' ({}), continuing without it\",\n532:                     extension_str, e\n533:                 ))\n534:                 .yellow()\n535:             );\n536: \n537:             // Offer debugging help\n538:             if let Err(debug_err) = offer_extension_debugging_help(\n539:                 &extension_str,\n540:                 &e.to_string(),\n541:                 Arc::clone(&provider_for_display),\n542:                 session_config.interactive,\n543:             )\n544:             .await\n545:             {\n546:                 eprintln!(\"Note: Could not start debugging session: {}\", debug_err);\n547:             }\n548:         }\n549:     }\n550: \n551:     // Add remote extensions if provided\n552:     for extension_str in session_config.remote_extensions {\n553:         if let Err(e) = session.add_remote_extension(extension_str.clone()).await {\n554:             eprintln!(\n555:                 \"{}\",\n556:                 style(format!(\n557:                     \"Warning: Failed to start remote extension '{}' ({}), continuing without it\",\n558:                     extension_str, e\n559:                 ))\n560:                 .yellow()\n561:             );\n562: \n563:             // Offer debugging help\n564:             if let Err(debug_err) = offer_extension_debugging_help(\n565:                 &extension_str,\n566:                 &e.to_string(),\n567:                 Arc::clone(&provider_for_display),\n568:                 session_config.interactive,\n569:             )\n570:             .await\n571:             {\n572:                 eprintln!(\"Note: Could not start debugging session: {}\", debug_err);\n573:             }\n574:         }\n575:     }\n576: \n577:     // Add streamable HTTP extensions if provided\n578:     for extension_str in session_config.streamable_http_extensions {\n579:         if let Err(e) = session\n580:             .add_streamable_http_extension(extension_str.clone())\n581:             .await\n582:         {\n583:             eprintln!(\n584:                 \"{}\",\n585:                 style(format!(\n586:                     \"Warning: Failed to start streamable HTTP extension '{}' ({}), continuing without it\",\n587:                     extension_str, e\n588:                 ))\n589:                 .yellow()\n590:             );\n591: \n592:             // Offer debugging help\n593:             if let Err(debug_err) = offer_extension_debugging_help(\n594:                 &extension_str,\n595:                 &e.to_string(),\n596:                 Arc::clone(&provider_for_display),\n597:                 session_config.interactive,\n598:             )\n599:             .await\n600:             {\n601:                 eprintln!(\"Note: Could not start debugging session: {}\", debug_err);\n602:             }\n603:         }\n604:     }\n605: \n606:     // Add builtin extensions\n607:     for builtin in session_config.builtins {\n608:         if let Err(e) = session.add_builtin(builtin.clone()).await {\n609:             eprintln!(\n610:                 \"{}\",\n611:                 style(format!(\n612:                     \"Warning: Failed to start builtin extension '{}' ({}), continuing without it\",\n613:                     builtin, e\n614:                 ))\n615:                 .yellow()\n616:             );\n617: \n618:             // Offer debugging help\n619:             if let Err(debug_err) = offer_extension_debugging_help(\n620:                 &builtin,\n621:                 &e.to_string(),\n622:                 Arc::clone(&provider_for_display),\n623:                 session_config.interactive,\n624:             )\n625:             .await\n626:             {\n627:                 eprintln!(\"Note: Could not start debugging session: {}\", debug_err);\n628:             }\n629:         }\n630:     }\n631: \n632:     let session_config_for_save = SessionConfig {\n633:         id: session_id.clone(),\n634:         schedule_id: None,\n635:         max_turns: None,\n636:         retry_config: None,\n637:     };\n638: \n639:     if let Err(e) = session\n640:         .agent\n641:         .save_extension_state(&session_config_for_save)\n642:         .await\n643:     {\n644:         tracing::warn!(\"Failed to save initial extension state: {}\", e);\n645:     }\n646: \n647:     // Add CLI-specific system prompt extension\n648:     session\n649:         .agent\n650:         .extend_system_prompt(super::prompt::get_cli_prompt())\n651:         .await;\n652: \n653:     if let Some(additional_prompt) = session_config.additional_system_prompt {\n654:         session.agent.extend_system_prompt(additional_prompt).await;\n655:     }\n656: \n657:     // Only override system prompt if a system override exists\n658:     let system_prompt_file: Option<String> = config.get_param(\"GOOSE_SYSTEM_PROMPT_FILE_PATH\").ok();\n659:     if let Some(ref path) = system_prompt_file {\n660:         let override_prompt =\n661:             std::fs::read_to_string(path).expect(\"Failed to read system prompt file\");\n662:         session.agent.override_system_prompt(override_prompt).await;\n663:     }\n664: \n665:     // Display session information unless in quiet mode\n666:     if !session_config.quiet {\n667:         output::display_session_info(\n668:             session_config.resume,\n669:             &provider_name,\n670:             &model_name,\n671:             &Some(session_id),\n672:             Some(&provider_for_display),\n673:         );\n674:     }\n675:     session\n676: }\n677: \n678: #[cfg(test)]\n679: mod tests {\n680:     use super::*;\n681: \n682:     #[test]\n683:     fn test_session_builder_config_creation() {\n684:         let config = SessionBuilderConfig {\n685:             session_id: None,\n686:             resume: false,\n687:             no_session: false,\n688:             extensions: vec![\"echo test\".to_string()],\n689:             remote_extensions: vec![\"http://example.com\".to_string()],\n690:             streamable_http_extensions: vec![\"http://example.com/streamable\".to_string()],\n691:             builtins: vec![\"developer\".to_string()],\n692:             extensions_override: None,\n693:             additional_system_prompt: Some(\"Test prompt\".to_string()),\n694:             settings: None,\n695:             provider: None,\n696:             model: None,\n697:             debug: true,\n698:             max_tool_repetitions: Some(5),\n699:             max_turns: None,\n700:             scheduled_job_id: None,\n701:             interactive: true,\n702:             quiet: false,\n703:             sub_recipes: None,\n704:             final_output_response: None,\n705:             retry_config: None,\n706:             output_format: \"text\".to_string(),\n707:         };\n708: \n709:         assert_eq!(config.extensions.len(), 1);\n710:         assert_eq!(config.remote_extensions.len(), 1);\n711:         assert_eq!(config.streamable_http_extensions.len(), 1);\n712:         assert_eq!(config.builtins.len(), 1);\n713:         assert!(config.debug);\n714:         assert_eq!(config.max_tool_repetitions, Some(5));\n715:         assert!(config.max_turns.is_none());\n716:         assert!(config.scheduled_job_id.is_none());\n717:         assert!(config.interactive);\n718:         assert!(!config.quiet);\n719:     }\n720: \n721:     #[test]\n722:     fn test_session_builder_config_default() {\n723:         let config = SessionBuilderConfig::default();\n724: \n725:         assert!(config.session_id.is_none());\n726:         assert!(!config.resume);\n727:         assert!(!config.no_session);\n728:         assert!(config.extensions.is_empty());\n729:         assert!(config.remote_extensions.is_empty());\n730:         assert!(config.streamable_http_extensions.is_empty());\n731:         assert!(config.builtins.is_empty());\n732:         assert!(config.extensions_override.is_none());\n733:         assert!(config.additional_system_prompt.is_none());\n734:         assert!(!config.debug);\n735:         assert!(config.max_tool_repetitions.is_none());\n736:         assert!(config.max_turns.is_none());\n737:         assert!(config.scheduled_job_id.is_none());\n738:         assert!(!config.interactive);\n739:         assert!(!config.quiet);\n740:         assert!(config.final_output_response.is_none());\n741:     }\n742: \n743:     #[tokio::test]\n744:     async fn test_offer_extension_debugging_help_function_exists() {\n745:         // This test just verifies the function compiles and can be called\n746:         // We can't easily test the interactive parts without mocking\n747: \n748:         // We can't actually test the full function without a real provider and user interaction\n749:         // But we can at least verify it compiles and the function signature is correct\n750:         let extension_name = \"test-extension\";\n751:         let error_message = \"test error\";\n752: \n753:         // This test mainly serves as a compilation check\n754:         assert_eq!(extension_name, \"test-extension\");\n755:         assert_eq!(error_message, \"test error\");\n756:     }\n757: }\n```\n",
                  "annotations": {
                    "audience": [
                      "user"
                    ],
                    "priority": 0.0
                  }
                }
              ],
              "isError": false
            }
          }
        }
      ],
      "metadata": {
        "userVisible": true,
        "agentVisible": true
      }
    },
    {
      "id": "msg_01BtN6411aTb843H1rSpcDgd",
      "role": "assistant",
      "created": 1766962642,
      "content": [
        {
          "type": "text",
          "text": "Now let me look at how the agent's reply_parts work to understand the streaming response:"
        },
        {
          "type": "toolRequest",
          "id": "toolu_01Xy6uNSHM7Mi3jA8ZmPKwow",
          "toolCall": {
            "status": "success",
            "value": {
              "name": "developer__text_editor",
              "arguments": {
                "command": "view",
                "path": "/Users/baxen/Development/goose/crates/goose/src/agents/reply_parts.rs"
              }
            }
          }
        }
      ],
      "metadata": {
        "userVisible": true,
        "agentVisible": true
      }
    },
    {
      "id": "msg_255b8793-fba2-4842-973d-5020f5cb0200",
      "role": "user",
      "created": 1766962644,
      "content": [
        {
          "type": "toolResponse",
          "id": "toolu_01Xy6uNSHM7Mi3jA8ZmPKwow",
          "toolResult": {
            "status": "success",
            "value": {
              "content": [
                {
                  "type": "resource",
                  "resource": {
                    "uri": "file:///Users/baxen/Development/goose/crates/goose/src/agents/reply_parts.rs",
                    "mimeType": "text",
                    "text": "use anyhow::Result;\nuse std::sync::Arc;\n\nuse async_stream::try_stream;\nuse futures::stream::StreamExt;\nuse serde_json::{json, Value};\nuse tracing::debug;\n\nuse super::super::agents::Agent;\nuse crate::conversation::message::{Message, MessageContent, ToolRequest};\nuse crate::conversation::Conversation;\nuse crate::providers::base::{stream_from_single_message, MessageStream, Provider, ProviderUsage};\nuse crate::providers::errors::ProviderError;\nuse crate::providers::toolshim::{\n    augment_message_with_tool_calls, convert_tool_messages_to_text,\n    modify_system_prompt_for_tool_json, OllamaInterpreter,\n};\n\nuse crate::agents::code_execution_extension::EXTENSION_NAME as CODE_EXECUTION_EXTENSION;\nuse crate::session::SessionManager;\n#[cfg(test)]\nuse crate::session::SessionType;\nuse rmcp::model::Tool;\n\nfn coerce_value(s: &str, schema: &Value) -> Value {\n    let type_str = schema.get(\"type\");\n\n    match type_str {\n        Some(Value::String(t)) => match t.as_str() {\n            \"number\" | \"integer\" => try_coerce_number(s),\n            \"boolean\" => try_coerce_boolean(s),\n            _ => Value::String(s.to_string()),\n        },\n        Some(Value::Array(types)) => {\n            // Try each type in order\n            for t in types {\n                if let Value::String(type_name) = t {\n                    match type_name.as_str() {\n                        \"number\" | \"integer\" if s.parse::<f64>().is_ok() => {\n                            return try_coerce_number(s)\n                        }\n                        \"boolean\" if matches!(s.to_lowercase().as_str(), \"true\" | \"false\") => {\n                            return try_coerce_boolean(s)\n                        }\n                        _ => continue,\n                    }\n                }\n            }\n            Value::String(s.to_string())\n        }\n        _ => Value::String(s.to_string()),\n    }\n}\n\nfn try_coerce_number(s: &str) -> Value {\n    if let Ok(n) = s.parse::<f64>() {\n        if n.fract() == 0.0 && n >= i64::MIN as f64 && n <= i64::MAX as f64 {\n            json!(n as i64)\n        } else {\n            json!(n)\n        }\n    } else {\n        Value::String(s.to_string())\n    }\n}\n\nfn try_coerce_boolean(s: &str) -> Value {\n    match s.to_lowercase().as_str() {\n        \"true\" => json!(true),\n        \"false\" => json!(false),\n        _ => Value::String(s.to_string()),\n    }\n}\n\nfn coerce_tool_arguments(\n    arguments: Option<serde_json::Map<String, Value>>,\n    tool_schema: &Value,\n) -> Option<serde_json::Map<String, Value>> {\n    let args = arguments?;\n\n    let properties = tool_schema.get(\"properties\").and_then(|p| p.as_object())?;\n\n    let mut coerced = serde_json::Map::new();\n\n    for (key, value) in args.iter() {\n        let coerced_value =\n            if let (Value::String(s), Some(prop_schema)) = (value, properties.get(key)) {\n                coerce_value(s, prop_schema)\n            } else {\n                value.clone()\n            };\n        coerced.insert(key.clone(), coerced_value);\n    }\n\n    Some(coerced)\n}\n\nasync fn toolshim_postprocess(\n    response: Message,\n    toolshim_tools: &[Tool],\n) -> Result<Message, ProviderError> {\n    let interpreter = OllamaInterpreter::new().map_err(|e| {\n        ProviderError::ExecutionError(format!(\"Failed to create OllamaInterpreter: {}\", e))\n    })?;\n\n    augment_message_with_tool_calls(&interpreter, response, toolshim_tools)\n        .await\n        .map_err(|e| ProviderError::ExecutionError(format!(\"Failed to augment message: {}\", e)))\n}\n\nimpl Agent {\n    pub async fn prepare_tools_and_prompt(\n        &self,\n        working_dir: &std::path::Path,\n    ) -> Result<(Vec<Tool>, Vec<Tool>, String)> {\n        // Get tools from extension manager\n        let mut tools = self.list_tools(None).await;\n\n        // Add frontend tools\n        let frontend_tools = self.frontend_tools.lock().await;\n        for frontend_tool in frontend_tools.values() {\n            tools.push(frontend_tool.tool.clone());\n        }\n\n        let code_execution_active = self\n            .extension_manager\n            .is_extension_enabled(CODE_EXECUTION_EXTENSION)\n            .await;\n        if code_execution_active {\n            let code_exec_prefix = format!(\"{CODE_EXECUTION_EXTENSION}__\");\n            tools.retain(|tool| tool.name.starts_with(&code_exec_prefix));\n        }\n\n        // Stable tool ordering is important for multi session prompt caching.\n        tools.sort_by(|a, b| a.name.cmp(&b.name));\n\n        // Prepare system prompt\n        let extensions_info = self.extension_manager.get_extensions_info().await;\n        let (extension_count, tool_count) =\n            self.extension_manager.get_extension_and_tool_counts().await;\n\n        // Get model name from provider\n        let provider = self.provider().await?;\n        let model_config = provider.get_model_config();\n\n        let prompt_manager = self.prompt_manager.lock().await;\n        let mut system_prompt = prompt_manager\n            .builder()\n            .with_extensions(extensions_info.into_iter())\n            .with_frontend_instructions(self.frontend_instructions.lock().await.clone())\n            .with_extension_and_tool_counts(extension_count, tool_count)\n            .with_code_execution_mode(code_execution_active)\n            .with_hints(working_dir)\n            .with_enable_subagents(self.subagents_enabled().await)\n            .build();\n\n        // Handle toolshim if enabled\n        let mut toolshim_tools = vec![];\n        if model_config.toolshim {\n            // If tool interpretation is enabled, modify the system prompt\n            system_prompt = modify_system_prompt_for_tool_json(&system_prompt, &tools);\n            // Make a copy of tools before emptying\n            toolshim_tools = tools.clone();\n            // Empty the tools vector for provider completion\n            tools = vec![];\n        }\n\n        Ok((tools, toolshim_tools, system_prompt))\n    }\n\n    /// Stream a response from the LLM provider.\n    /// Handles toolshim transformations if needed\n    pub(crate) async fn stream_response_from_provider(\n        provider: Arc<dyn Provider>,\n        system_prompt: &str,\n        messages: &[Message],\n        tools: &[Tool],\n        toolshim_tools: &[Tool],\n    ) -> Result<MessageStream, ProviderError> {\n        let config = provider.get_model_config();\n\n        // Convert tool messages to text if toolshim is enabled\n        let messages_for_provider = if config.toolshim {\n            convert_tool_messages_to_text(messages)\n        } else {\n            Conversation::new_unvalidated(messages.to_vec())\n        };\n\n        // Clone owned data to move into the async stream\n        let system_prompt = system_prompt.to_owned();\n        let tools = tools.to_owned();\n        let toolshim_tools = toolshim_tools.to_owned();\n        let provider = provider.clone();\n\n        // Capture errors during stream creation and return them as part of the stream\n        // so they can be handled by the existing error handling logic in the agent\n        let stream_result = if provider.supports_streaming() {\n            debug!(\"WAITING_LLM_STREAM_START\");\n            let result = provider\n                .stream(\n                    system_prompt.as_str(),\n                    messages_for_provider.messages(),\n                    &tools,\n                )\n                .await;\n            debug!(\"WAITING_LLM_STREAM_END\");\n            result\n        } else {\n            debug!(\"WAITING_LLM_START\");\n            let complete_result = provider\n                .complete(\n                    system_prompt.as_str(),\n                    messages_for_provider.messages(),\n                    &tools,\n                )\n                .await;\n            debug!(\"WAITING_LLM_END\");\n\n            match complete_result {\n                Ok((message, usage)) => Ok(stream_from_single_message(message, usage)),\n                Err(e) => Err(e),\n            }\n        };\n\n        // If there was an error creating the stream, return a stream that yields that error\n        let mut stream = match stream_result {\n            Ok(s) => s,\n            Err(e) => {\n                // Return a stream that immediately yields the error\n                // This allows the error to be caught by existing error handling in agent.rs\n                return Ok(Box::pin(try_stream! {\n                    yield Err(e)?;\n                }));\n            }\n        };\n\n        Ok(Box::pin(try_stream! {\n            while let Some(Ok((mut message, usage))) = stream.next().await {\n                // Store the model information in the global store\n                if let Some(usage) = usage.as_ref() {\n                    crate::providers::base::set_current_model(&usage.model);\n                }\n\n                // Post-process / structure the response only if tool interpretation is enabled\n                if message.is_some() && config.toolshim {\n                    message = Some(toolshim_postprocess(message.unwrap(), &toolshim_tools).await?);\n                }\n\n                yield (message, usage);\n            }\n        }))\n    }\n\n    /// Categorize tool requests from the response into different types\n    /// Returns:\n    /// - frontend_requests: Tool requests that should be handled by the frontend\n    /// - other_requests: All other tool requests (including requests to enable extensions)\n    /// - filtered_message: The original message with frontend tool requests removed\n    pub(crate) async fn categorize_tool_requests(\n        &self,\n        response: &Message,\n        tools: &[Tool],\n    ) -> (Vec<ToolRequest>, Vec<ToolRequest>, Message) {\n        // First collect all tool requests with coercion applied\n        let tool_requests: Vec<ToolRequest> = response\n            .content\n            .iter()\n            .filter_map(|content| {\n                if let MessageContent::ToolRequest(req) = content {\n                    let mut coerced_req = req.clone();\n\n                    if let Ok(ref mut tool_call) = coerced_req.tool_call {\n                        if let Some(tool) = tools.iter().find(|t| t.name == tool_call.name) {\n                            let schema_value = Value::Object(tool.input_schema.as_ref().clone());\n                            tool_call.arguments =\n                                coerce_tool_arguments(tool_call.arguments.clone(), &schema_value);\n                        }\n                    }\n\n                    Some(coerced_req)\n                } else {\n                    None\n                }\n            })\n            .collect();\n\n        // Create a filtered message with frontend tool requests removed\n        let mut filtered_content = Vec::new();\n\n        // Process each content item one by one\n        for content in &response.content {\n            let should_include = match content {\n                MessageContent::ToolRequest(req) => {\n                    if let Ok(tool_call) = &req.tool_call {\n                        !self.is_frontend_tool(&tool_call.name).await\n                    } else {\n                        true\n                    }\n                }\n                _ => true,\n            };\n\n            if should_include {\n                filtered_content.push(content.clone());\n            }\n        }\n\n        let mut filtered_message =\n            Message::new(response.role.clone(), response.created, filtered_content);\n\n        // Preserve the ID if it exists\n        if let Some(id) = response.id.clone() {\n            filtered_message = filtered_message.with_id(id);\n        }\n\n        // Categorize tool requests\n        let mut frontend_requests = Vec::new();\n        let mut other_requests = Vec::new();\n\n        for request in tool_requests {\n            if let Ok(tool_call) = &request.tool_call {\n                if self.is_frontend_tool(&tool_call.name).await {\n                    frontend_requests.push(request);\n                } else {\n                    other_requests.push(request);\n                }\n            } else {\n                // If there's an error in the tool call, add it to other_requests\n                other_requests.push(request);\n            }\n        }\n\n        (frontend_requests, other_requests, filtered_message)\n    }\n\n    pub(crate) async fn update_session_metrics(\n        session_config: &crate::agents::types::SessionConfig,\n        usage: &ProviderUsage,\n        is_compaction_usage: bool,\n    ) -> Result<()> {\n        let session_id = session_config.id.as_str();\n        let session = SessionManager::get_session(session_id, false).await?;\n\n        let accumulate = |a: Option<i32>, b: Option<i32>| -> Option<i32> {\n            match (a, b) {\n                (Some(x), Some(y)) => Some(x + y),\n                _ => a.or(b),\n            }\n        };\n\n        let accumulated_total =\n            accumulate(session.accumulated_total_tokens, usage.usage.total_tokens);\n        let accumulated_input =\n            accumulate(session.accumulated_input_tokens, usage.usage.input_tokens);\n        let accumulated_output =\n            accumulate(session.accumulated_output_tokens, usage.usage.output_tokens);\n\n        let (current_total, current_input, current_output) = if is_compaction_usage {\n            // After compaction: summary output becomes new input context\n            let new_input = usage.usage.output_tokens;\n            (new_input, new_input, None)\n        } else {\n            (\n                usage.usage.total_tokens,\n                usage.usage.input_tokens,\n                usage.usage.output_tokens,\n            )\n        };\n\n        SessionManager::update_session(session_id)\n            .schedule_id(session_config.schedule_id.clone())\n            .total_tokens(current_total)\n            .input_tokens(current_input)\n            .output_tokens(current_output)\n            .accumulated_total_tokens(accumulated_total)\n            .accumulated_input_tokens(accumulated_input)\n            .accumulated_output_tokens(accumulated_output)\n            .apply()\n            .await?;\n\n        Ok(())\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use crate::conversation::message::Message;\n    use crate::model::ModelConfig;\n    use crate::providers::base::{Provider, ProviderUsage, Usage};\n    use crate::providers::errors::ProviderError;\n    use async_trait::async_trait;\n    use rmcp::object;\n\n    #[derive(Clone)]\n    struct MockProvider {\n        model_config: ModelConfig,\n    }\n\n    #[async_trait]\n    impl Provider for MockProvider {\n        fn metadata() -> crate::providers::base::ProviderMetadata {\n            crate::providers::base::ProviderMetadata::empty()\n        }\n\n        fn get_name(&self) -> &str {\n            \"mock\"\n        }\n\n        fn get_model_config(&self) -> ModelConfig {\n            self.model_config.clone()\n        }\n\n        async fn complete_with_model(\n            &self,\n            _model_config: &ModelConfig,\n            _system: &str,\n            _messages: &[Message],\n            _tools: &[Tool],\n        ) -> anyhow::Result<(Message, ProviderUsage), ProviderError> {\n            Ok((\n                Message::assistant().with_text(\"ok\"),\n                ProviderUsage::new(\"mock\".to_string(), Usage::default()),\n            ))\n        }\n    }\n\n    #[tokio::test]\n    async fn prepare_tools_sorts_and_includes_frontend_and_list_tools() -> anyhow::Result<()> {\n        let agent = crate::agents::Agent::new();\n\n        let session = SessionManager::create_session(\n            std::path::PathBuf::default(),\n            \"test-prepare-tools\".to_string(),\n            SessionType::Hidden,\n        )\n        .await?;\n\n        let model_config = ModelConfig::new(\"test-model\").unwrap();\n        let provider = std::sync::Arc::new(MockProvider { model_config });\n        agent.update_provider(provider, &session.id).await?;\n\n        // Add unsorted frontend tools\n        let frontend_tools = vec![\n            Tool::new(\n                \"frontend__z_tool\".to_string(),\n                \"Z tool\".to_string(),\n                object!({ \"type\": \"object\", \"properties\": { } }),\n            ),\n            Tool::new(\n                \"frontend__a_tool\".to_string(),\n                \"A tool\".to_string(),\n                object!({ \"type\": \"object\", \"properties\": { } }),\n            ),\n        ];\n\n        agent\n            .add_extension(crate::agents::extension::ExtensionConfig::Frontend {\n                name: \"frontend\".to_string(),\n                description: \"desc\".to_string(),\n                tools: frontend_tools,\n                instructions: None,\n                bundled: None,\n                available_tools: vec![],\n            })\n            .await\n            .unwrap();\n\n        let working_dir = std::env::current_dir()?;\n        let (tools, _toolshim_tools, _system_prompt) =\n            agent.prepare_tools_and_prompt(&working_dir).await?;\n\n        // Ensure both platform and frontend tools are present\n        let names: Vec<String> = tools.iter().map(|t| t.name.clone().into_owned()).collect();\n        assert!(names.iter().any(|n| n.starts_with(\"platform__\")));\n        assert!(names.iter().any(|n| n == \"frontend__a_tool\"));\n        assert!(names.iter().any(|n| n == \"frontend__z_tool\"));\n\n        // Verify the names are sorted ascending\n        let mut sorted = names.clone();\n        sorted.sort();\n        assert_eq!(names, sorted);\n\n        Ok(())\n    }\n}\n"
                  },
                  "annotations": {
                    "audience": [
                      "assistant"
                    ]
                  }
                },
                {
                  "type": "text",
                  "text": "### /Users/baxen/Development/goose/crates/goose/src/agents/reply_parts.rs\n```rust\n1: use anyhow::Result;\n2: use std::sync::Arc;\n3: \n4: use async_stream::try_stream;\n5: use futures::stream::StreamExt;\n6: use serde_json::{json, Value};\n7: use tracing::debug;\n8: \n9: use super::super::agents::Agent;\n10: use crate::conversation::message::{Message, MessageContent, ToolRequest};\n11: use crate::conversation::Conversation;\n12: use crate::providers::base::{stream_from_single_message, MessageStream, Provider, ProviderUsage};\n13: use crate::providers::errors::ProviderError;\n14: use crate::providers::toolshim::{\n15:     augment_message_with_tool_calls, convert_tool_messages_to_text,\n16:     modify_system_prompt_for_tool_json, OllamaInterpreter,\n17: };\n18: \n19: use crate::agents::code_execution_extension::EXTENSION_NAME as CODE_EXECUTION_EXTENSION;\n20: use crate::session::SessionManager;\n21: #[cfg(test)]\n22: use crate::session::SessionType;\n23: use rmcp::model::Tool;\n24: \n25: fn coerce_value(s: &str, schema: &Value) -> Value {\n26:     let type_str = schema.get(\"type\");\n27: \n28:     match type_str {\n29:         Some(Value::String(t)) => match t.as_str() {\n30:             \"number\" | \"integer\" => try_coerce_number(s),\n31:             \"boolean\" => try_coerce_boolean(s),\n32:             _ => Value::String(s.to_string()),\n33:         },\n34:         Some(Value::Array(types)) => {\n35:             // Try each type in order\n36:             for t in types {\n37:                 if let Value::String(type_name) = t {\n38:                     match type_name.as_str() {\n39:                         \"number\" | \"integer\" if s.parse::<f64>().is_ok() => {\n40:                             return try_coerce_number(s)\n41:                         }\n42:                         \"boolean\" if matches!(s.to_lowercase().as_str(), \"true\" | \"false\") => {\n43:                             return try_coerce_boolean(s)\n44:                         }\n45:                         _ => continue,\n46:                     }\n47:                 }\n48:             }\n49:             Value::String(s.to_string())\n50:         }\n51:         _ => Value::String(s.to_string()),\n52:     }\n53: }\n54: \n55: fn try_coerce_number(s: &str) -> Value {\n56:     if let Ok(n) = s.parse::<f64>() {\n57:         if n.fract() == 0.0 && n >= i64::MIN as f64 && n <= i64::MAX as f64 {\n58:             json!(n as i64)\n59:         } else {\n60:             json!(n)\n61:         }\n62:     } else {\n63:         Value::String(s.to_string())\n64:     }\n65: }\n66: \n67: fn try_coerce_boolean(s: &str) -> Value {\n68:     match s.to_lowercase().as_str() {\n69:         \"true\" => json!(true),\n70:         \"false\" => json!(false),\n71:         _ => Value::String(s.to_string()),\n72:     }\n73: }\n74: \n75: fn coerce_tool_arguments(\n76:     arguments: Option<serde_json::Map<String, Value>>,\n77:     tool_schema: &Value,\n78: ) -> Option<serde_json::Map<String, Value>> {\n79:     let args = arguments?;\n80: \n81:     let properties = tool_schema.get(\"properties\").and_then(|p| p.as_object())?;\n82: \n83:     let mut coerced = serde_json::Map::new();\n84: \n85:     for (key, value) in args.iter() {\n86:         let coerced_value =\n87:             if let (Value::String(s), Some(prop_schema)) = (value, properties.get(key)) {\n88:                 coerce_value(s, prop_schema)\n89:             } else {\n90:                 value.clone()\n91:             };\n92:         coerced.insert(key.clone(), coerced_value);\n93:     }\n94: \n95:     Some(coerced)\n96: }\n97: \n98: async fn toolshim_postprocess(\n99:     response: Message,\n100:     toolshim_tools: &[Tool],\n101: ) -> Result<Message, ProviderError> {\n102:     let interpreter = OllamaInterpreter::new().map_err(|e| {\n103:         ProviderError::ExecutionError(format!(\"Failed to create OllamaInterpreter: {}\", e))\n104:     })?;\n105: \n106:     augment_message_with_tool_calls(&interpreter, response, toolshim_tools)\n107:         .await\n108:         .map_err(|e| ProviderError::ExecutionError(format!(\"Failed to augment message: {}\", e)))\n109: }\n110: \n111: impl Agent {\n112:     pub async fn prepare_tools_and_prompt(\n113:         &self,\n114:         working_dir: &std::path::Path,\n115:     ) -> Result<(Vec<Tool>, Vec<Tool>, String)> {\n116:         // Get tools from extension manager\n117:         let mut tools = self.list_tools(None).await;\n118: \n119:         // Add frontend tools\n120:         let frontend_tools = self.frontend_tools.lock().await;\n121:         for frontend_tool in frontend_tools.values() {\n122:             tools.push(frontend_tool.tool.clone());\n123:         }\n124: \n125:         let code_execution_active = self\n126:             .extension_manager\n127:             .is_extension_enabled(CODE_EXECUTION_EXTENSION)\n128:             .await;\n129:         if code_execution_active {\n130:             let code_exec_prefix = format!(\"{CODE_EXECUTION_EXTENSION}__\");\n131:             tools.retain(|tool| tool.name.starts_with(&code_exec_prefix));\n132:         }\n133: \n134:         // Stable tool ordering is important for multi session prompt caching.\n135:         tools.sort_by(|a, b| a.name.cmp(&b.name));\n136: \n137:         // Prepare system prompt\n138:         let extensions_info = self.extension_manager.get_extensions_info().await;\n139:         let (extension_count, tool_count) =\n140:             self.extension_manager.get_extension_and_tool_counts().await;\n141: \n142:         // Get model name from provider\n143:         let provider = self.provider().await?;\n144:         let model_config = provider.get_model_config();\n145: \n146:         let prompt_manager = self.prompt_manager.lock().await;\n147:         let mut system_prompt = prompt_manager\n148:             .builder()\n149:             .with_extensions(extensions_info.into_iter())\n150:             .with_frontend_instructions(self.frontend_instructions.lock().await.clone())\n151:             .with_extension_and_tool_counts(extension_count, tool_count)\n152:             .with_code_execution_mode(code_execution_active)\n153:             .with_hints(working_dir)\n154:             .with_enable_subagents(self.subagents_enabled().await)\n155:             .build();\n156: \n157:         // Handle toolshim if enabled\n158:         let mut toolshim_tools = vec![];\n159:         if model_config.toolshim {\n160:             // If tool interpretation is enabled, modify the system prompt\n161:             system_prompt = modify_system_prompt_for_tool_json(&system_prompt, &tools);\n162:             // Make a copy of tools before emptying\n163:             toolshim_tools = tools.clone();\n164:             // Empty the tools vector for provider completion\n165:             tools = vec![];\n166:         }\n167: \n168:         Ok((tools, toolshim_tools, system_prompt))\n169:     }\n170: \n171:     /// Stream a response from the LLM provider.\n172:     /// Handles toolshim transformations if needed\n173:     pub(crate) async fn stream_response_from_provider(\n174:         provider: Arc<dyn Provider>,\n175:         system_prompt: &str,\n176:         messages: &[Message],\n177:         tools: &[Tool],\n178:         toolshim_tools: &[Tool],\n179:     ) -> Result<MessageStream, ProviderError> {\n180:         let config = provider.get_model_config();\n181: \n182:         // Convert tool messages to text if toolshim is enabled\n183:         let messages_for_provider = if config.toolshim {\n184:             convert_tool_messages_to_text(messages)\n185:         } else {\n186:             Conversation::new_unvalidated(messages.to_vec())\n187:         };\n188: \n189:         // Clone owned data to move into the async stream\n190:         let system_prompt = system_prompt.to_owned();\n191:         let tools = tools.to_owned();\n192:         let toolshim_tools = toolshim_tools.to_owned();\n193:         let provider = provider.clone();\n194: \n195:         // Capture errors during stream creation and return them as part of the stream\n196:         // so they can be handled by the existing error handling logic in the agent\n197:         let stream_result = if provider.supports_streaming() {\n198:             debug!(\"WAITING_LLM_STREAM_START\");\n199:             let result = provider\n200:                 .stream(\n201:                     system_prompt.as_str(),\n202:                     messages_for_provider.messages(),\n203:                     &tools,\n204:                 )\n205:                 .await;\n206:             debug!(\"WAITING_LLM_STREAM_END\");\n207:             result\n208:         } else {\n209:             debug!(\"WAITING_LLM_START\");\n210:             let complete_result = provider\n211:                 .complete(\n212:                     system_prompt.as_str(),\n213:                     messages_for_provider.messages(),\n214:                     &tools,\n215:                 )\n216:                 .await;\n217:             debug!(\"WAITING_LLM_END\");\n218: \n219:             match complete_result {\n220:                 Ok((message, usage)) => Ok(stream_from_single_message(message, usage)),\n221:                 Err(e) => Err(e),\n222:             }\n223:         };\n224: \n225:         // If there was an error creating the stream, return a stream that yields that error\n226:         let mut stream = match stream_result {\n227:             Ok(s) => s,\n228:             Err(e) => {\n229:                 // Return a stream that immediately yields the error\n230:                 // This allows the error to be caught by existing error handling in agent.rs\n231:                 return Ok(Box::pin(try_stream! {\n232:                     yield Err(e)?;\n233:                 }));\n234:             }\n235:         };\n236: \n237:         Ok(Box::pin(try_stream! {\n238:             while let Some(Ok((mut message, usage))) = stream.next().await {\n239:                 // Store the model information in the global store\n240:                 if let Some(usage) = usage.as_ref() {\n241:                     crate::providers::base::set_current_model(&usage.model);\n242:                 }\n243: \n244:                 // Post-process / structure the response only if tool interpretation is enabled\n245:                 if message.is_some() && config.toolshim {\n246:                     message = Some(toolshim_postprocess(message.unwrap(), &toolshim_tools).await?);\n247:                 }\n248: \n249:                 yield (message, usage);\n250:             }\n251:         }))\n252:     }\n253: \n254:     /// Categorize tool requests from the response into different types\n255:     /// Returns:\n256:     /// - frontend_requests: Tool requests that should be handled by the frontend\n257:     /// - other_requests: All other tool requests (including requests to enable extensions)\n258:     /// - filtered_message: The original message with frontend tool requests removed\n259:     pub(crate) async fn categorize_tool_requests(\n260:         &self,\n261:         response: &Message,\n262:         tools: &[Tool],\n263:     ) -> (Vec<ToolRequest>, Vec<ToolRequest>, Message) {\n264:         // First collect all tool requests with coercion applied\n265:         let tool_requests: Vec<ToolRequest> = response\n266:             .content\n267:             .iter()\n268:             .filter_map(|content| {\n269:                 if let MessageContent::ToolRequest(req) = content {\n270:                     let mut coerced_req = req.clone();\n271: \n272:                     if let Ok(ref mut tool_call) = coerced_req.tool_call {\n273:                         if let Some(tool) = tools.iter().find(|t| t.name == tool_call.name) {\n274:                             let schema_value = Value::Object(tool.input_schema.as_ref().clone());\n275:                             tool_call.arguments =\n276:                                 coerce_tool_arguments(tool_call.arguments.clone(), &schema_value);\n277:                         }\n278:                     }\n279: \n280:                     Some(coerced_req)\n281:                 } else {\n282:                     None\n283:                 }\n284:             })\n285:             .collect();\n286: \n287:         // Create a filtered message with frontend tool requests removed\n288:         let mut filtered_content = Vec::new();\n289: \n290:         // Process each content item one by one\n291:         for content in &response.content {\n292:             let should_include = match content {\n293:                 MessageContent::ToolRequest(req) => {\n294:                     if let Ok(tool_call) = &req.tool_call {\n295:                         !self.is_frontend_tool(&tool_call.name).await\n296:                     } else {\n297:                         true\n298:                     }\n299:                 }\n300:                 _ => true,\n301:             };\n302: \n303:             if should_include {\n304:                 filtered_content.push(content.clone());\n305:             }\n306:         }\n307: \n308:         let mut filtered_message =\n309:             Message::new(response.role.clone(), response.created, filtered_content);\n310: \n311:         // Preserve the ID if it exists\n312:         if let Some(id) = response.id.clone() {\n313:             filtered_message = filtered_message.with_id(id);\n314:         }\n315: \n316:         // Categorize tool requests\n317:         let mut frontend_requests = Vec::new();\n318:         let mut other_requests = Vec::new();\n319: \n320:         for request in tool_requests {\n321:             if let Ok(tool_call) = &request.tool_call {\n322:                 if self.is_frontend_tool(&tool_call.name).await {\n323:                     frontend_requests.push(request);\n324:                 } else {\n325:                     other_requests.push(request);\n326:                 }\n327:             } else {\n328:                 // If there's an error in the tool call, add it to other_requests\n329:                 other_requests.push(request);\n330:             }\n331:         }\n332: \n333:         (frontend_requests, other_requests, filtered_message)\n334:     }\n335: \n336:     pub(crate) async fn update_session_metrics(\n337:         session_config: &crate::agents::types::SessionConfig,\n338:         usage: &ProviderUsage,\n339:         is_compaction_usage: bool,\n340:     ) -> Result<()> {\n341:         let session_id = session_config.id.as_str();\n342:         let session = SessionManager::get_session(session_id, false).await?;\n343: \n344:         let accumulate = |a: Option<i32>, b: Option<i32>| -> Option<i32> {\n345:             match (a, b) {\n346:                 (Some(x), Some(y)) => Some(x + y),\n347:                 _ => a.or(b),\n348:             }\n349:         };\n350: \n351:         let accumulated_total =\n352:             accumulate(session.accumulated_total_tokens, usage.usage.total_tokens);\n353:         let accumulated_input =\n354:             accumulate(session.accumulated_input_tokens, usage.usage.input_tokens);\n355:         let accumulated_output =\n356:             accumulate(session.accumulated_output_tokens, usage.usage.output_tokens);\n357: \n358:         let (current_total, current_input, current_output) = if is_compaction_usage {\n359:             // After compaction: summary output becomes new input context\n360:             let new_input = usage.usage.output_tokens;\n361:             (new_input, new_input, None)\n362:         } else {\n363:             (\n364:                 usage.usage.total_tokens,\n365:                 usage.usage.input_tokens,\n366:                 usage.usage.output_tokens,\n367:             )\n368:         };\n369: \n370:         SessionManager::update_session(session_id)\n371:             .schedule_id(session_config.schedule_id.clone())\n372:             .total_tokens(current_total)\n373:             .input_tokens(current_input)\n374:             .output_tokens(current_output)\n375:             .accumulated_total_tokens(accumulated_total)\n376:             .accumulated_input_tokens(accumulated_input)\n377:             .accumulated_output_tokens(accumulated_output)\n378:             .apply()\n379:             .await?;\n380: \n381:         Ok(())\n382:     }\n383: }\n384: \n385: #[cfg(test)]\n386: mod tests {\n387:     use super::*;\n388:     use crate::conversation::message::Message;\n389:     use crate::model::ModelConfig;\n390:     use crate::providers::base::{Provider, ProviderUsage, Usage};\n391:     use crate::providers::errors::ProviderError;\n392:     use async_trait::async_trait;\n393:     use rmcp::object;\n394: \n395:     #[derive(Clone)]\n396:     struct MockProvider {\n397:         model_config: ModelConfig,\n398:     }\n399: \n400:     #[async_trait]\n401:     impl Provider for MockProvider {\n402:         fn metadata() -> crate::providers::base::ProviderMetadata {\n403:             crate::providers::base::ProviderMetadata::empty()\n404:         }\n405: \n406:         fn get_name(&self) -> &str {\n407:             \"mock\"\n408:         }\n409: \n410:         fn get_model_config(&self) -> ModelConfig {\n411:             self.model_config.clone()\n412:         }\n413: \n414:         async fn complete_with_model(\n415:             &self,\n416:             _model_config: &ModelConfig,\n417:             _system: &str,\n418:             _messages: &[Message],\n419:             _tools: &[Tool],\n420:         ) -> anyhow::Result<(Message, ProviderUsage), ProviderError> {\n421:             Ok((\n422:                 Message::assistant().with_text(\"ok\"),\n423:                 ProviderUsage::new(\"mock\".to_string(), Usage::default()),\n424:             ))\n425:         }\n426:     }\n427: \n428:     #[tokio::test]\n429:     async fn prepare_tools_sorts_and_includes_frontend_and_list_tools() -> anyhow::Result<()> {\n430:         let agent = crate::agents::Agent::new();\n431: \n432:         let session = SessionManager::create_session(\n433:             std::path::PathBuf::default(),\n434:             \"test-prepare-tools\".to_string(),\n435:             SessionType::Hidden,\n436:         )\n437:         .await?;\n438: \n439:         let model_config = ModelConfig::new(\"test-model\").unwrap();\n440:         let provider = std::sync::Arc::new(MockProvider { model_config });\n441:         agent.update_provider(provider, &session.id).await?;\n442: \n443:         // Add unsorted frontend tools\n444:         let frontend_tools = vec![\n445:             Tool::new(\n446:                 \"frontend__z_tool\".to_string(),\n447:                 \"Z tool\".to_string(),\n448:                 object!({ \"type\": \"object\", \"properties\": { } }),\n449:             ),\n450:             Tool::new(\n451:                 \"frontend__a_tool\".to_string(),\n452:                 \"A tool\".to_string(),\n453:                 object!({ \"type\": \"object\", \"properties\": { } }),\n454:             ),\n455:         ];\n456: \n457:         agent\n458:             .add_extension(crate::agents::extension::ExtensionConfig::Frontend {\n459:                 name: \"frontend\".to_string(),\n460:                 description: \"desc\".to_string(),\n461:                 tools: frontend_tools,\n462:                 instructions: None,\n463:                 bundled: None,\n464:                 available_tools: vec![],\n465:             })\n466:             .await\n467:             .unwrap();\n468: \n469:         let working_dir = std::env::current_dir()?;\n470:         let (tools, _toolshim_tools, _system_prompt) =\n471:             agent.prepare_tools_and_prompt(&working_dir).await?;\n472: \n473:         // Ensure both platform and frontend tools are present\n474:         let names: Vec<String> = tools.iter().map(|t| t.name.clone().into_owned()).collect();\n475:         assert!(names.iter().any(|n| n.starts_with(\"platform__\")));\n476:         assert!(names.iter().any(|n| n == \"frontend__a_tool\"));\n477:         assert!(names.iter().any(|n| n == \"frontend__z_tool\"));\n478: \n479:         // Verify the names are sorted ascending\n480:         let mut sorted = names.clone();\n481:         sorted.sort();\n482:         assert_eq!(names, sorted);\n483: \n484:         Ok(())\n485:     }\n486: }\n```\n",
                  "annotations": {
                    "audience": [
                      "user"
                    ],
                    "priority": 0.0
                  }
                }
              ],
              "isError": false
            }
          }
        }
      ],
      "metadata": {
        "userVisible": true,
        "agentVisible": true
      }
    },
    {
      "id": "msg_01UfovAgMWQqWzgBgTHAro2T",
      "role": "assistant",
      "created": 1766962646,
      "content": [
        {
          "type": "text",
          "text": "Now let me look at the conversation and message structures to understand the data flow better:"
        },
        {
          "type": "toolRequest",
          "id": "toolu_01EPJpy9RgKrV9CZz5qDyC1U",
          "toolCall": {
            "status": "success",
            "value": {
              "name": "developer__text_editor",
              "arguments": {
                "command": "view",
                "path": "/Users/baxen/Development/goose/crates/goose/src/conversation"
              }
            }
          }
        }
      ],
      "metadata": {
        "userVisible": true,
        "agentVisible": true
      }
    },
    {
      "id": "msg_37965999-af26-4e1d-879f-e6f3d329f84a",
      "role": "user",
      "created": 1766962648,
      "content": [
        {
          "type": "toolResponse",
          "id": "toolu_01EPJpy9RgKrV9CZz5qDyC1U",
          "toolResult": {
            "status": "success",
            "value": {
              "content": [
                {
                  "type": "text",
                  "text": "'/Users/baxen/Development/goose/crates/goose/src/conversation' is a directory. Contents:\n\nFiles:\n  message.rs\n  mod.rs\n  tool_result_serde.rs\n"
                }
              ],
              "isError": false
            }
          }
        }
      ],
      "metadata": {
        "userVisible": true,
        "agentVisible": true
      }
    },
    {
      "id": "msg_01YUdzaBV753NGzFxqVHyi3U",
      "role": "assistant",
      "created": 1766962652,
      "content": [
        {
          "type": "toolRequest",
          "id": "toolu_01GYJR3diaycfS777wy3e3fR",
          "toolCall": {
            "status": "success",
            "value": {
              "name": "developer__text_editor",
              "arguments": {
                "command": "view",
                "path": "/Users/baxen/Development/goose/crates/goose/src/conversation/message.rs",
                "view_range": [
                  1,
                  150
                ]
              }
            }
          }
        }
      ],
      "metadata": {
        "userVisible": true,
        "agentVisible": true
      }
    },
    {
      "id": "msg_f4cbacc5-1fdf-472e-8edb-cc98f6b15cbb",
      "role": "user",
      "created": 1766962652,
      "content": [
        {
          "type": "toolResponse",
          "id": "toolu_01GYJR3diaycfS777wy3e3fR",
          "toolResult": {
            "status": "success",
            "value": {
              "content": [
                {
                  "type": "resource",
                  "resource": {
                    "uri": "file:///Users/baxen/Development/goose/crates/goose/src/conversation/message.rs",
                    "mimeType": "text",
                    "text": "use crate::mcp_utils::ToolResult;\nuse chrono::Utc;\nuse rmcp::model::{\n    AnnotateAble, CallToolRequestParam, CallToolResult, Content, ImageContent, JsonObject,\n    PromptMessage, PromptMessageContent, PromptMessageRole, RawContent, RawImageContent,\n    RawTextContent, ResourceContents, Role, TextContent,\n};\nuse serde::{Deserialize, Deserializer, Serialize};\nuse std::collections::HashSet;\nuse std::fmt;\nuse utoipa::ToSchema;\n\nuse crate::conversation::tool_result_serde;\nuse crate::utils::sanitize_unicode_tags;\n\n#[derive(ToSchema)]\npub enum ToolCallResult<T> {\n    Success { value: T },\n    Error { error: String },\n}\n\n/// Custom deserializer for MessageContent that sanitizes Unicode Tags in text content\nfn deserialize_sanitized_content<'de, D>(deserializer: D) -> Result<Vec<MessageContent>, D::Error>\nwhere\n    D: Deserializer<'de>,\n{\n    use serde::de::Error;\n\n    let mut raw: Vec<serde_json::Value> = Vec::deserialize(deserializer)?;\n\n    // Filter out old \"conversationCompacted\" messages from pre-14.0\n    raw.retain(|item| item.get(\"type\").and_then(|v| v.as_str()) != Some(\"conversationCompacted\"));\n\n    let mut content: Vec<MessageContent> = serde_json::from_value(serde_json::Value::Array(raw))\n        .map_err(|e| Error::custom(format!(\"Failed to deserialize MessageContent: {}\", e)))?;\n\n    for message_content in &mut content {\n        if let MessageContent::Text(text_content) = message_content {\n            let original = &text_content.text;\n            let sanitized = sanitize_unicode_tags(original);\n            if *original != sanitized {\n                tracing::info!(\n                    original = %original,\n                    sanitized = %sanitized,\n                    removed_count = original.len() - sanitized.len(),\n                    \"Unicode Tags sanitized during Message deserialization\"\n                );\n                text_content.text = sanitized;\n            }\n        }\n    }\n\n    Ok(content)\n}\n\n/// Provider-specific metadata for tool requests/responses.\n/// Allows providers to store custom data without polluting the core model.\npub type ProviderMetadata = serde_json::Map<String, serde_json::Value>;\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]\n#[serde(rename_all = \"camelCase\")]\n#[derive(ToSchema)]\npub struct ToolRequest {\n    pub id: String,\n    #[serde(with = \"tool_result_serde\")]\n    #[schema(value_type = Object)]\n    pub tool_call: ToolResult<CallToolRequestParam>,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    #[schema(value_type = Object)]\n    pub metadata: Option<ProviderMetadata>,\n}\n\nimpl ToolRequest {\n    pub fn to_readable_string(&self) -> String {\n        match &self.tool_call {\n            Ok(tool_call) => {\n                format!(\n                    \"Tool: {}, Args: {}\",\n                    tool_call.name,\n                    serde_json::to_string_pretty(&tool_call.arguments)\n                        .unwrap_or_else(|_| \"<<invalid json>>\".to_string())\n                )\n            }\n            Err(e) => format!(\"Invalid tool call: {}\", e),\n        }\n    }\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]\n#[serde(rename_all = \"camelCase\")]\n#[derive(ToSchema)]\npub struct ToolResponse {\n    pub id: String,\n    #[serde(with = \"tool_result_serde::call_tool_result\")]\n    #[schema(value_type = Object)]\n    pub tool_result: ToolResult<CallToolResult>,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    #[schema(value_type = Object)]\n    pub metadata: Option<ProviderMetadata>,\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]\n#[serde(rename_all = \"camelCase\")]\n#[derive(ToSchema)]\npub struct ToolConfirmationRequest {\n    pub id: String,\n    pub tool_name: String,\n    pub arguments: JsonObject,\n    pub prompt: Option<String>,\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema)]\n#[serde(tag = \"actionType\", rename_all = \"camelCase\")]\npub enum ActionRequiredData {\n    #[serde(rename_all = \"camelCase\")]\n    ToolConfirmation {\n        id: String,\n        tool_name: String,\n        arguments: JsonObject,\n        prompt: Option<String>,\n    },\n    Elicitation {\n        id: String,\n        message: String,\n        requested_schema: serde_json::Value,\n    },\n    ElicitationResponse {\n        id: String,\n        user_data: serde_json::Value,\n    },\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema)]\n#[serde(rename_all = \"camelCase\")]\npub struct ActionRequired {\n    pub data: ActionRequiredData,\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema)]\npub struct ThinkingContent {\n    pub thinking: String,\n    pub signature: String,\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema)]\npub struct RedactedThinkingContent {\n    pub data: String,\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema)]\n#[serde(rename_all = \"camelCase\")]\npub struct FrontendToolRequest {\n    pub id: String,\n    #[serde(with = \"tool_result_serde\")]\n    #[schema(value_type = Object)]\n    pub tool_call: ToolResult<CallToolRequestParam>,\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema)]\n#[serde(rename_all = \"camelCase\")]\npub enum SystemNotificationType {\n    ThinkingMessage,\n    InlineMessage,\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema)]\n#[serde(rename_all = \"camelCase\")]\npub struct SystemNotificationContent {\n    pub notification_type: SystemNotificationType,\n    pub msg: String,\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema)]\n/// Content passed inside a message, which can be both simple content and tool content\n#[serde(tag = \"type\", rename_all = \"camelCase\")]\npub enum MessageContent {\n    Text(TextContent),\n    Image(ImageContent),\n    ToolRequest(ToolRequest),\n    ToolResponse(ToolResponse),\n    ToolConfirmationRequest(ToolConfirmationRequest),\n    ActionRequired(ActionRequired),\n    FrontendToolRequest(FrontendToolRequest),\n    Thinking(ThinkingContent),\n    RedactedThinking(RedactedThinkingContent),\n    SystemNotification(SystemNotificationContent),\n}\n\nimpl fmt::Display for MessageContent {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match self {\n            MessageContent::Text(t) => write!(f, \"{}\", t.text),\n            MessageContent::Image(i) => write!(f, \"[Image: {}]\", i.mime_type),\n            MessageContent::ToolRequest(r) => {\n                write!(f, \"[ToolRequest: {}]\", r.to_readable_string())\n            }\n            MessageContent::ToolResponse(r) => write!(\n                f,\n                \"[ToolResponse: {}]\",\n                match &r.tool_result {\n                    Ok(result) => format!(\"{} content item(s)\", result.content.len()),\n                    Err(e) => format!(\"Error: {e}\"),\n                }\n            ),\n            MessageContent::ToolConfirmationRequest(r) => {\n                write!(f, \"[ToolConfirmationRequest: {}]\", r.tool_name)\n            }\n            MessageContent::ActionRequired(a) => match &a.data {\n                ActionRequiredData::ToolConfirmation { tool_name, .. } => {\n                    write!(f, \"[ActionRequired: ToolConfirmation for {}]\", tool_name)\n                }\n                ActionRequiredData::Elicitation { message, .. } => {\n                    write!(f, \"[ActionRequired: Elicitation - {}]\", message)\n                }\n                ActionRequiredData::ElicitationResponse { id, .. } => {\n                    write!(f, \"[ActionRequired: ElicitationResponse for {}]\", id)\n                }\n            },\n            MessageContent::FrontendToolRequest(r) => match &r.tool_call {\n                Ok(tool_call) => write!(f, \"[FrontendToolRequest: {}]\", tool_call.name),\n                Err(e) => write!(f, \"[FrontendToolRequest: Error: {}]\", e),\n            },\n            MessageContent::Thinking(t) => write!(f, \"[Thinking: {}]\", t.thinking),\n            MessageContent::RedactedThinking(_r) => write!(f, \"[RedactedThinking]\"),\n            MessageContent::SystemNotification(r) => {\n                write!(f, \"[SystemNotification: {}]\", r.msg)\n            }\n        }\n    }\n}\n\nimpl MessageContent {\n    pub fn text<S: Into<String>>(text: S) -> Self {\n        MessageContent::Text(\n            RawTextContent {\n                text: text.into(),\n                meta: None,\n            }\n            .no_annotation(),\n        )\n    }\n\n    pub fn image<S: Into<String>, T: Into<String>>(data: S, mime_type: T) -> Self {\n        MessageContent::Image(\n            RawImageContent {\n                data: data.into(),\n                mime_type: mime_type.into(),\n                meta: None,\n            }\n            .no_annotation(),\n        )\n    }\n\n    pub fn tool_request<S: Into<String>>(\n        id: S,\n        tool_call: ToolResult<CallToolRequestParam>,\n    ) -> Self {\n        MessageContent::ToolRequest(ToolRequest {\n            id: id.into(),\n            tool_call,\n            metadata: None,\n        })\n    }\n\n    pub fn tool_request_with_metadata<S: Into<String>>(\n        id: S,\n        tool_call: ToolResult<CallToolRequestParam>,\n        metadata: Option<&ProviderMetadata>,\n    ) -> Self {\n        MessageContent::ToolRequest(ToolRequest {\n            id: id.into(),\n            tool_call,\n            metadata: metadata.cloned(),\n        })\n    }\n\n    pub fn tool_response<S: Into<String>>(id: S, tool_result: ToolResult<CallToolResult>) -> Self {\n        MessageContent::ToolResponse(ToolResponse {\n            id: id.into(),\n            tool_result,\n            metadata: None,\n        })\n    }\n\n    pub fn tool_response_with_metadata<S: Into<String>>(\n        id: S,\n        tool_result: ToolResult<CallToolResult>,\n        metadata: Option<&ProviderMetadata>,\n    ) -> Self {\n        MessageContent::ToolResponse(ToolResponse {\n            id: id.into(),\n            tool_result,\n            metadata: metadata.cloned(),\n        })\n    }\n\n    pub fn action_required<S: Into<String>>(\n        id: S,\n        tool_name: String,\n        arguments: JsonObject,\n        prompt: Option<String>,\n    ) -> Self {\n        MessageContent::ActionRequired(ActionRequired {\n            data: ActionRequiredData::ToolConfirmation {\n                id: id.into(),\n                tool_name,\n                arguments,\n                prompt,\n            },\n        })\n    }\n\n    pub fn action_required_elicitation<S: Into<String>>(\n        id: S,\n        message: String,\n        requested_schema: serde_json::Value,\n    ) -> Self {\n        MessageContent::ActionRequired(ActionRequired {\n            data: ActionRequiredData::Elicitation {\n                id: id.into(),\n                message,\n                requested_schema,\n            },\n        })\n    }\n\n    pub fn action_required_elicitation_response<S: Into<String>>(\n        id: S,\n        user_data: serde_json::Value,\n    ) -> Self {\n        MessageContent::ActionRequired(ActionRequired {\n            data: ActionRequiredData::ElicitationResponse {\n                id: id.into(),\n                user_data,\n            },\n        })\n    }\n\n    pub fn thinking<S1: Into<String>, S2: Into<String>>(thinking: S1, signature: S2) -> Self {\n        MessageContent::Thinking(ThinkingContent {\n            thinking: thinking.into(),\n            signature: signature.into(),\n        })\n    }\n\n    pub fn redacted_thinking<S: Into<String>>(data: S) -> Self {\n        MessageContent::RedactedThinking(RedactedThinkingContent { data: data.into() })\n    }\n\n    pub fn frontend_tool_request<S: Into<String>>(\n        id: S,\n        tool_call: ToolResult<CallToolRequestParam>,\n    ) -> Self {\n        MessageContent::FrontendToolRequest(FrontendToolRequest {\n            id: id.into(),\n            tool_call,\n        })\n    }\n\n    pub fn system_notification<S: Into<String>>(\n        notification_type: SystemNotificationType,\n        msg: S,\n    ) -> Self {\n        MessageContent::SystemNotification(SystemNotificationContent {\n            notification_type,\n            msg: msg.into(),\n        })\n    }\n\n    pub fn as_system_notification(&self) -> Option<&SystemNotificationContent> {\n        if let MessageContent::SystemNotification(ref notification) = self {\n            Some(notification)\n        } else {\n            None\n        }\n    }\n\n    pub fn as_tool_request(&self) -> Option<&ToolRequest> {\n        if let MessageContent::ToolRequest(ref tool_request) = self {\n            Some(tool_request)\n        } else {\n            None\n        }\n    }\n\n    pub fn as_tool_response(&self) -> Option<&ToolResponse> {\n        if let MessageContent::ToolResponse(ref tool_response) = self {\n            Some(tool_response)\n        } else {\n            None\n        }\n    }\n\n    pub fn as_action_required(&self) -> Option<&ActionRequired> {\n        if let MessageContent::ActionRequired(ref action_required) = self {\n            Some(action_required)\n        } else {\n            None\n        }\n    }\n\n    pub fn as_tool_response_text(&self) -> Option<String> {\n        if let Some(tool_response) = self.as_tool_response() {\n            if let Ok(result) = &tool_response.tool_result {\n                let texts: Vec<String> = result\n                    .content\n                    .iter()\n                    .filter_map(|content| content.as_text().map(|t| t.text.to_string()))\n                    .collect();\n                if !texts.is_empty() {\n                    return Some(texts.join(\"\\n\"));\n                }\n            }\n        }\n        None\n    }\n\n    /// Get the text content if this is a TextContent variant\n    pub fn as_text(&self) -> Option<&str> {\n        match self {\n            MessageContent::Text(text) => Some(&text.text),\n            _ => None,\n        }\n    }\n\n    /// Get the thinking content if this is a ThinkingContent variant\n    pub fn as_thinking(&self) -> Option<&ThinkingContent> {\n        match self {\n            MessageContent::Thinking(thinking) => Some(thinking),\n            _ => None,\n        }\n    }\n\n    /// Get the redacted thinking content if this is a RedactedThinkingContent variant\n    pub fn as_redacted_thinking(&self) -> Option<&RedactedThinkingContent> {\n        match self {\n            MessageContent::RedactedThinking(redacted) => Some(redacted),\n            _ => None,\n        }\n    }\n}\n\nimpl From<Content> for MessageContent {\n    fn from(content: Content) -> Self {\n        match content.raw {\n            RawContent::Text(text) => {\n                MessageContent::Text(text.optional_annotate(content.annotations))\n            }\n            RawContent::Image(image) => {\n                MessageContent::Image(image.optional_annotate(content.annotations))\n            }\n            RawContent::ResourceLink(_link) => MessageContent::text(\"[Resource link]\"),\n            RawContent::Resource(resource) => {\n                let text = match &resource.resource {\n                    ResourceContents::TextResourceContents { text, .. } => text.clone(),\n                    ResourceContents::BlobResourceContents { blob, .. } => {\n                        format!(\"[Binary content: {}]\", blob.clone())\n                    }\n                };\n                MessageContent::text(text)\n            }\n            RawContent::Audio(_) => {\n                MessageContent::text(\"[Audio content: not supported]\".to_string())\n            }\n        }\n    }\n}\n\nimpl From<PromptMessage> for Message {\n    fn from(prompt_message: PromptMessage) -> Self {\n        // Create a new message with the appropriate role\n        let message = match prompt_message.role {\n            PromptMessageRole::User => Message::user(),\n            PromptMessageRole::Assistant => Message::assistant(),\n        };\n\n        // Convert and add the content\n        let content = match prompt_message.content {\n            PromptMessageContent::Text { text } => MessageContent::text(text),\n            PromptMessageContent::Image { image } => {\n                MessageContent::image(image.data.clone(), image.mime_type.clone())\n            }\n            PromptMessageContent::ResourceLink { .. } => MessageContent::text(\"[Resource link]\"),\n            PromptMessageContent::Resource { resource } => {\n                // For resources, convert to text content with the resource text\n                match &resource.resource {\n                    ResourceContents::TextResourceContents { text, .. } => {\n                        MessageContent::text(text.clone())\n                    }\n                    ResourceContents::BlobResourceContents { blob, .. } => {\n                        MessageContent::text(format!(\"[Binary content: {}]\", blob.clone()))\n                    }\n                }\n            }\n        };\n\n        message.with_content(content)\n    }\n}\n\n#[derive(ToSchema, Clone, Copy, PartialEq, Serialize, Deserialize, Debug)]\n/// Metadata for message visibility\n#[serde(rename_all = \"camelCase\")]\npub struct MessageMetadata {\n    /// Whether the message should be visible to the user in the UI\n    pub user_visible: bool,\n    /// Whether the message should be included in the agent's context window\n    pub agent_visible: bool,\n}\n\nimpl Default for MessageMetadata {\n    fn default() -> Self {\n        MessageMetadata {\n            user_visible: true,\n            agent_visible: true,\n        }\n    }\n}\n\nimpl MessageMetadata {\n    /// Create metadata for messages visible only to the agent\n    pub fn agent_only() -> Self {\n        MessageMetadata {\n            user_visible: false,\n            agent_visible: true,\n        }\n    }\n\n    /// Create metadata for messages visible only to the user\n    pub fn user_only() -> Self {\n        MessageMetadata {\n            user_visible: true,\n            agent_visible: false,\n        }\n    }\n\n    /// Create metadata for messages visible to neither user nor agent (archived)\n    pub fn invisible() -> Self {\n        MessageMetadata {\n            user_visible: false,\n            agent_visible: false,\n        }\n    }\n\n    /// Return a copy with agent_visible set to false\n    pub fn with_agent_invisible(self) -> Self {\n        Self {\n            agent_visible: false,\n            ..self\n        }\n    }\n\n    /// Return a copy with user_visible set to false\n    pub fn with_user_invisible(self) -> Self {\n        Self {\n            user_visible: false,\n            ..self\n        }\n    }\n\n    /// Return a copy with agent_visible set to true\n    pub fn with_agent_visible(self) -> Self {\n        Self {\n            agent_visible: true,\n            ..self\n        }\n    }\n\n    /// Return a copy with user_visible set to true\n    pub fn with_user_visible(self) -> Self {\n        Self {\n            user_visible: true,\n            ..self\n        }\n    }\n}\n\n#[derive(ToSchema, Clone, PartialEq, Serialize, Deserialize, Debug)]\n/// A message to or from an LLM\n#[serde(rename_all = \"camelCase\")]\npub struct Message {\n    pub id: Option<String>,\n    pub role: Role,\n    pub created: i64,\n    #[serde(deserialize_with = \"deserialize_sanitized_content\")]\n    pub content: Vec<MessageContent>,\n    pub metadata: MessageMetadata,\n}\n\nimpl Message {\n    pub fn new(role: Role, created: i64, content: Vec<MessageContent>) -> Self {\n        Message {\n            id: None,\n            role,\n            created,\n            content,\n            metadata: MessageMetadata::default(),\n        }\n    }\n    pub fn debug(&self) -> String {\n        format!(\"{:?}\", self)\n    }\n\n    /// Create a new user message with the current timestamp\n    pub fn user() -> Self {\n        Message {\n            id: None,\n            role: Role::User,\n            created: Utc::now().timestamp(),\n            content: Vec::new(),\n            metadata: MessageMetadata::default(),\n        }\n    }\n\n    /// Create a new assistant message with the current timestamp\n    pub fn assistant() -> Self {\n        Message {\n            id: None,\n            role: Role::Assistant,\n            created: Utc::now().timestamp(),\n            content: Vec::new(),\n            metadata: MessageMetadata::default(),\n        }\n    }\n\n    pub fn with_id<S: Into<String>>(mut self, id: S) -> Self {\n        self.id = Some(id.into());\n        self\n    }\n\n    /// Add any MessageContent to the message\n    pub fn with_content(mut self, content: MessageContent) -> Self {\n        self.content.push(content);\n        self\n    }\n\n    /// Add text content to the message\n    pub fn with_text<S: Into<String>>(self, text: S) -> Self {\n        let raw_text = text.into();\n        let sanitized_text = sanitize_unicode_tags(&raw_text);\n\n        self.with_content(MessageContent::Text(\n            RawTextContent {\n                text: sanitized_text,\n                meta: None,\n            }\n            .no_annotation(),\n        ))\n    }\n\n    /// Add image content to the message\n    pub fn with_image<S: Into<String>, T: Into<String>>(self, data: S, mime_type: T) -> Self {\n        self.with_content(MessageContent::image(data, mime_type))\n    }\n\n    /// Add a tool request to the message\n    pub fn with_tool_request<S: Into<String>>(\n        self,\n        id: S,\n        tool_call: ToolResult<CallToolRequestParam>,\n    ) -> Self {\n        self.with_content(MessageContent::tool_request(id, tool_call))\n    }\n\n    pub fn with_tool_request_with_metadata<S: Into<String>>(\n        self,\n        id: S,\n        tool_call: ToolResult<CallToolRequestParam>,\n        metadata: Option<&ProviderMetadata>,\n    ) -> Self {\n        self.with_content(MessageContent::tool_request_with_metadata(\n            id, tool_call, metadata,\n        ))\n    }\n\n    /// Add a tool response to the message\n    pub fn with_tool_response<S: Into<String>>(\n        self,\n        id: S,\n        result: ToolResult<CallToolResult>,\n    ) -> Self {\n        self.with_content(MessageContent::tool_response(id, result))\n    }\n\n    pub fn with_tool_response_with_metadata<S: Into<String>>(\n        self,\n        id: S,\n        result: ToolResult<CallToolResult>,\n        metadata: Option<&ProviderMetadata>,\n    ) -> Self {\n        self.with_content(MessageContent::tool_response_with_metadata(\n            id, result, metadata,\n        ))\n    }\n\n    /// Add an action required message for tool confirmation\n    pub fn with_action_required<S: Into<String>>(\n        self,\n        id: S,\n        tool_name: String,\n        arguments: JsonObject,\n        prompt: Option<String>,\n    ) -> Self {\n        self.with_content(MessageContent::action_required(\n            id, tool_name, arguments, prompt,\n        ))\n    }\n\n    pub fn with_frontend_tool_request<S: Into<String>>(\n        self,\n        id: S,\n        tool_call: ToolResult<CallToolRequestParam>,\n    ) -> Self {\n        self.with_content(MessageContent::frontend_tool_request(id, tool_call))\n    }\n\n    /// Add thinking content to the message\n    pub fn with_thinking<S1: Into<String>, S2: Into<String>>(\n        self,\n        thinking: S1,\n        signature: S2,\n    ) -> Self {\n        self.with_content(MessageContent::thinking(thinking, signature))\n    }\n\n    /// Add redacted thinking content to the message\n    pub fn with_redacted_thinking<S: Into<String>>(self, data: S) -> Self {\n        self.with_content(MessageContent::redacted_thinking(data))\n    }\n\n    /// Get the concatenated text content of the message, separated by newlines\n    pub fn as_concat_text(&self) -> String {\n        self.content\n            .iter()\n            .filter_map(|c| c.as_text())\n            .collect::<Vec<_>>()\n            .join(\"\\n\")\n    }\n\n    /// Check if the message is a tool call\n    pub fn is_tool_call(&self) -> bool {\n        self.content\n            .iter()\n            .any(|c| matches!(c, MessageContent::ToolRequest(_)))\n    }\n\n    /// Check if the message is a tool response\n    pub fn is_tool_response(&self) -> bool {\n        self.content\n            .iter()\n            .any(|c| matches!(c, MessageContent::ToolResponse(_)))\n    }\n\n    /// Retrieves all tool `id` from the message\n    pub fn get_tool_ids(&self) -> HashSet<&str> {\n        self.content\n            .iter()\n            .filter_map(|content| match content {\n                MessageContent::ToolRequest(req) => Some(req.id.as_str()),\n                MessageContent::ToolResponse(res) => Some(res.id.as_str()),\n                _ => None,\n            })\n            .collect()\n    }\n\n    /// Retrieves all tool `id` from ToolRequest messages\n    pub fn get_tool_request_ids(&self) -> HashSet<&str> {\n        self.content\n            .iter()\n            .filter_map(|content| {\n                if let MessageContent::ToolRequest(req) = content {\n                    Some(req.id.as_str())\n                } else {\n                    None\n                }\n            })\n            .collect()\n    }\n\n    /// Retrieves all tool `id` from ToolResponse messages\n    pub fn get_tool_response_ids(&self) -> HashSet<&str> {\n        self.content\n            .iter()\n            .filter_map(|content| {\n                if let MessageContent::ToolResponse(res) = content {\n                    Some(res.id.as_str())\n                } else {\n                    None\n                }\n            })\n            .collect()\n    }\n\n    /// Check if the message has only TextContent\n    pub fn has_only_text_content(&self) -> bool {\n        self.content\n            .iter()\n            .all(|c| matches!(c, MessageContent::Text(_)))\n    }\n\n    pub fn with_system_notification<S: Into<String>>(\n        self,\n        notification_type: SystemNotificationType,\n        msg: S,\n    ) -> Self {\n        self.with_content(MessageContent::system_notification(notification_type, msg))\n            .with_metadata(MessageMetadata::user_only())\n    }\n\n    /// Set the visibility metadata for the message\n    pub fn with_visibility(mut self, user_visible: bool, agent_visible: bool) -> Self {\n        self.metadata.user_visible = user_visible;\n        self.metadata.agent_visible = agent_visible;\n        self\n    }\n\n    /// Set the entire metadata for the message\n    pub fn with_metadata(mut self, metadata: MessageMetadata) -> Self {\n        self.metadata = metadata;\n        self\n    }\n\n    /// Mark the message as only visible to the user (not the agent)\n    pub fn user_only(mut self) -> Self {\n        self.metadata.user_visible = true;\n        self.metadata.agent_visible = false;\n        self\n    }\n\n    /// Mark the message as only visible to the agent (not the user)\n    pub fn agent_only(mut self) -> Self {\n        self.metadata.user_visible = false;\n        self.metadata.agent_visible = true;\n        self\n    }\n\n    /// Check if the message is visible to the user\n    pub fn is_user_visible(&self) -> bool {\n        self.metadata.user_visible\n    }\n\n    /// Check if the message is visible to the agent\n    pub fn is_agent_visible(&self) -> bool {\n        self.metadata.agent_visible\n    }\n}\n\n#[derive(Debug, Clone, Default, Serialize, Deserialize, ToSchema)]\n#[serde(rename_all = \"camelCase\")]\npub struct TokenState {\n    pub input_tokens: i32,\n    pub output_tokens: i32,\n    pub total_tokens: i32,\n    pub accumulated_input_tokens: i32,\n    pub accumulated_output_tokens: i32,\n    pub accumulated_total_tokens: i32,\n}\n\n#[cfg(test)]\nmod tests {\n    use crate::conversation::message::{Message, MessageContent, MessageMetadata};\n    use crate::conversation::*;\n    use rmcp::model::{\n        AnnotateAble, CallToolRequestParam, PromptMessage, PromptMessageContent, PromptMessageRole,\n        RawEmbeddedResource, RawImageContent, ResourceContents,\n    };\n    use rmcp::model::{ErrorCode, ErrorData};\n    use rmcp::object;\n    use serde_json::Value;\n\n    #[test]\n    fn test_sanitize_with_text() {\n        let malicious = \"Hello\\u{E0041}\\u{E0042}\\u{E0043}world\"; // Invisible \"ABC\"\n        let message = Message::user().with_text(malicious);\n        assert_eq!(message.as_concat_text(), \"Helloworld\");\n    }\n\n    #[test]\n    fn test_no_sanitize_with_text() {\n        let clean_text = \"Hello world 世界 🌍\";\n        let message = Message::user().with_text(clean_text);\n        assert_eq!(message.as_concat_text(), clean_text);\n    }\n\n    #[test]\n    fn test_message_serialization() {\n        let message = Message::assistant()\n            .with_text(\"Hello, I'll help you with that.\")\n            .with_tool_request(\n                \"tool123\",\n                Ok(CallToolRequestParam {\n                    name: \"test_tool\".into(),\n                    arguments: Some(object!({\"param\": \"value\"})),\n                }),\n            );\n\n        let json_str = serde_json::to_string_pretty(&message).unwrap();\n        println!(\"Serialized message: {}\", json_str);\n\n        // Parse back to Value to check structure\n        let value: Value = serde_json::from_str(&json_str).unwrap();\n\n        // Check top-level fields\n        assert_eq!(value[\"role\"], \"assistant\");\n        assert!(value[\"created\"].is_i64());\n        assert!(value[\"content\"].is_array());\n\n        // Check content items\n        let content = &value[\"content\"];\n\n        // First item should be text\n        assert_eq!(content[0][\"type\"], \"text\");\n        assert_eq!(content[0][\"text\"], \"Hello, I'll help you with that.\");\n\n        // Second item should be toolRequest\n        assert_eq!(content[1][\"type\"], \"toolRequest\");\n        assert_eq!(content[1][\"id\"], \"tool123\");\n\n        // Check tool_call serialization\n        assert_eq!(content[1][\"toolCall\"][\"status\"], \"success\");\n        assert_eq!(content[1][\"toolCall\"][\"value\"][\"name\"], \"test_tool\");\n        assert_eq!(\n            content[1][\"toolCall\"][\"value\"][\"arguments\"][\"param\"],\n            \"value\"\n        );\n    }\n\n    #[test]\n    fn test_error_serialization() {\n        let message = Message::assistant().with_tool_request(\n            \"tool123\",\n            Err(ErrorData {\n                code: ErrorCode::INTERNAL_ERROR,\n                message: std::borrow::Cow::from(\"Something went wrong\".to_string()),\n                data: None,\n            }),\n        );\n\n        let json_str = serde_json::to_string_pretty(&message).unwrap();\n        println!(\"Serialized error: {}\", json_str);\n\n        // Parse back to Value to check structure\n        let value: Value = serde_json::from_str(&json_str).unwrap();\n\n        // Check tool_call serialization with error\n        let tool_call = &value[\"content\"][0][\"toolCall\"];\n        assert_eq!(tool_call[\"status\"], \"error\");\n        assert_eq!(tool_call[\"error\"], \"-32603: Something went wrong\");\n    }\n\n    #[test]\n    fn test_deserialization() {\n        // Create a JSON string with our new format\n        let json_str = r#\"{\n            \"role\": \"assistant\",\n            \"created\": 1740171566,\n            \"content\": [\n                {\n                    \"type\": \"text\",\n                    \"text\": \"I'll help you with that.\"\n                },\n                {\n                    \"type\": \"toolRequest\",\n                    \"id\": \"tool123\",\n                    \"toolCall\": {\n                        \"status\": \"success\",\n                        \"value\": {\n                            \"name\": \"test_tool\",\n                            \"arguments\": {\"param\": \"value\"}\n                        }\n                    }\n                }\n            ],\n            \"metadata\": { \"agentVisible\": true, \"userVisible\": true }\n        }\"#;\n\n        let message: Message = serde_json::from_str(json_str).unwrap();\n\n        assert_eq!(message.role, Role::Assistant);\n        assert_eq!(message.created, 1740171566);\n        assert_eq!(message.content.len(), 2);\n\n        // Check first content item\n        if let MessageContent::Text(text) = &message.content[0] {\n            assert_eq!(text.text, \"I'll help you with that.\");\n        } else {\n            panic!(\"Expected Text content\");\n        }\n\n        // Check second content item\n        if let MessageContent::ToolRequest(req) = &message.content[1] {\n            assert_eq!(req.id, \"tool123\");\n            if let Ok(tool_call) = &req.tool_call {\n                assert_eq!(tool_call.name, \"test_tool\");\n                assert_eq!(tool_call.arguments, Some(object!({\"param\": \"value\"})))\n            } else {\n                panic!(\"Expected successful tool call\");\n            }\n        } else {\n            panic!(\"Expected ToolRequest content\");\n        }\n    }\n\n    #[test]\n    fn test_from_prompt_message_text() {\n        let prompt_content = PromptMessageContent::Text {\n            text: \"Hello, world!\".to_string(),\n        };\n\n        let prompt_message = PromptMessage {\n            role: PromptMessageRole::User,\n            content: prompt_content,\n        };\n\n        let message = Message::from(prompt_message);\n\n        if let MessageContent::Text(text_content) = &message.content[0] {\n            assert_eq!(text_content.text, \"Hello, world!\");\n        } else {\n            panic!(\"Expected MessageContent::Text\");\n        }\n    }\n\n    #[test]\n    fn test_from_prompt_message_image() {\n        let prompt_content = PromptMessageContent::Image {\n            image: RawImageContent {\n                data: \"base64data\".to_string(),\n                mime_type: \"image/jpeg\".to_string(),\n                meta: None,\n            }\n            .no_annotation(),\n        };\n\n        let prompt_message = PromptMessage {\n            role: PromptMessageRole::User,\n            content: prompt_content,\n        };\n\n        let message = Message::from(prompt_message);\n\n        if let MessageContent::Image(image_content) = &message.content[0] {\n            assert_eq!(image_content.data, \"base64data\");\n            assert_eq!(image_content.mime_type, \"image/jpeg\");\n        } else {\n            panic!(\"Expected MessageContent::Image\");\n        }\n    }\n\n    #[test]\n    fn test_from_prompt_message_text_resource() {\n        let resource = ResourceContents::TextResourceContents {\n            uri: \"file:///test.txt\".to_string(),\n            mime_type: Some(\"text/plain\".to_string()),\n            text: \"Resource content\".to_string(),\n            meta: None,\n        };\n\n        let prompt_content = PromptMessageContent::Resource {\n            resource: RawEmbeddedResource {\n                resource,\n                meta: None,\n            }\n            .no_annotation(),\n        };\n\n        let prompt_message = PromptMessage {\n            role: PromptMessageRole::User,\n            content: prompt_content,\n        };\n\n        let message = Message::from(prompt_message);\n\n        if let MessageContent::Text(text_content) = &message.content[0] {\n            assert_eq!(text_content.text, \"Resource content\");\n        } else {\n            panic!(\"Expected MessageContent::Text\");\n        }\n    }\n\n    #[test]\n    fn test_from_prompt_message_blob_resource() {\n        let resource = ResourceContents::BlobResourceContents {\n            uri: \"file:///test.bin\".to_string(),\n            mime_type: Some(\"application/octet-stream\".to_string()),\n            blob: \"binary_data\".to_string(),\n            meta: None,\n        };\n\n        let prompt_content = PromptMessageContent::Resource {\n            resource: RawEmbeddedResource {\n                resource,\n                meta: None,\n            }\n            .no_annotation(),\n        };\n\n        let prompt_message = PromptMessage {\n            role: PromptMessageRole::User,\n            content: prompt_content,\n        };\n\n        let message = Message::from(prompt_message);\n\n        if let MessageContent::Text(text_content) = &message.content[0] {\n            assert_eq!(text_content.text, \"[Binary content: binary_data]\");\n        } else {\n            panic!(\"Expected MessageContent::Text\");\n        }\n    }\n\n    #[test]\n    fn test_from_prompt_message() {\n        // Test user message conversion\n        let prompt_message = PromptMessage {\n            role: PromptMessageRole::User,\n            content: PromptMessageContent::Text {\n                text: \"Hello, world!\".to_string(),\n            },\n        };\n\n        let message = Message::from(prompt_message);\n        assert_eq!(message.role, Role::User);\n        assert_eq!(message.content.len(), 1);\n        assert_eq!(message.as_concat_text(), \"Hello, world!\");\n\n        // Test assistant message conversion\n        let prompt_message = PromptMessage {\n            role: PromptMessageRole::Assistant,\n            content: PromptMessageContent::Text {\n                text: \"I can help with that.\".to_string(),\n            },\n        };\n\n        let message = Message::from(prompt_message);\n        assert_eq!(message.role, Role::Assistant);\n        assert_eq!(message.content.len(), 1);\n        assert_eq!(message.as_concat_text(), \"I can help with that.\");\n    }\n\n    #[test]\n    fn test_message_with_text() {\n        let message = Message::user().with_text(\"Hello\");\n        assert_eq!(message.as_concat_text(), \"Hello\");\n    }\n\n    #[test]\n    fn test_message_with_tool_request() {\n        let tool_call = Ok(CallToolRequestParam {\n            name: \"test_tool\".into(),\n            arguments: Some(object!({})),\n        });\n\n        let message = Message::assistant().with_tool_request(\"req1\", tool_call);\n        assert!(message.is_tool_call());\n        assert!(!message.is_tool_response());\n\n        let ids = message.get_tool_ids();\n        assert_eq!(ids.len(), 1);\n        assert!(ids.contains(\"req1\"));\n    }\n\n    #[test]\n    fn test_message_deserialization_sanitizes_text_content() {\n        // Create a test string with Unicode Tags characters\n        let malicious_text = \"Hello\\u{E0041}\\u{E0042}\\u{E0043}world\";\n        let malicious_json = format!(\n            r#\"{{\n            \"id\": \"test-id\",\n            \"role\": \"user\",\n            \"created\": 1640995200,\n            \"content\": [\n                {{\n                    \"type\": \"text\",\n                    \"text\": \"{}\"\n                }},\n                {{\n                    \"type\": \"image\",\n                    \"data\": \"base64data\",\n                    \"mimeType\": \"image/png\"\n                }}\n            ],\n            \"metadata\": {{ \"agentVisible\": true, \"userVisible\": true }}\n        }}\"#,\n            malicious_text\n        );\n\n        let message: Message = serde_json::from_str(&malicious_json).unwrap();\n\n        // Text content should be sanitized\n        assert_eq!(message.as_concat_text(), \"Helloworld\");\n\n        // Image content should be unchanged\n        if let MessageContent::Image(img) = &message.content[1] {\n            assert_eq!(img.data, \"base64data\");\n            assert_eq!(img.mime_type, \"image/png\");\n        } else {\n            panic!(\"Expected ImageContent\");\n        }\n    }\n\n    #[test]\n    fn test_legitimate_unicode_preserved_during_message_deserialization() {\n        let clean_json = r#\"{\n            \"id\": \"test-id\",\n            \"role\": \"user\",\n            \"created\": 1640995200,\n            \"content\": [{\n                \"type\": \"text\",\n                \"text\": \"Hello world 世界 🌍\"\n            }],\n            \"metadata\": { \"agentVisible\": true, \"userVisible\": true }\n        }\"#;\n\n        let message: Message = serde_json::from_str(clean_json).unwrap();\n\n        assert_eq!(message.as_concat_text(), \"Hello world 世界 🌍\");\n    }\n\n    #[test]\n    fn test_message_metadata_defaults() {\n        let message = Message::user().with_text(\"Test\");\n\n        // By default, messages should be both user and agent visible\n        assert!(message.is_user_visible());\n        assert!(message.is_agent_visible());\n    }\n\n    #[test]\n    fn test_message_visibility_methods() {\n        // Test user_only\n        let user_only_msg = Message::user().with_text(\"User only\").user_only();\n        assert!(user_only_msg.is_user_visible());\n        assert!(!user_only_msg.is_agent_visible());\n\n        // Test agent_only\n        let agent_only_msg = Message::assistant().with_text(\"Agent only\").agent_only();\n        assert!(!agent_only_msg.is_user_visible());\n        assert!(agent_only_msg.is_agent_visible());\n\n        // Test with_visibility\n        let custom_msg = Message::user()\n            .with_text(\"Custom visibility\")\n            .with_visibility(false, true);\n        assert!(!custom_msg.is_user_visible());\n        assert!(custom_msg.is_agent_visible());\n    }\n\n    #[test]\n    fn test_message_metadata_serialization() {\n        let message = Message::user()\n            .with_text(\"Test message\")\n            .with_visibility(false, true);\n\n        let json_str = serde_json::to_string(&message).unwrap();\n        let value: Value = serde_json::from_str(&json_str).unwrap();\n\n        assert_eq!(value[\"metadata\"][\"userVisible\"], false);\n        assert_eq!(value[\"metadata\"][\"agentVisible\"], true);\n    }\n\n    #[test]\n    fn test_message_metadata_deserialization() {\n        // Test with explicit metadata\n        let json_with_metadata = r#\"{\n            \"role\": \"user\",\n            \"created\": 1640995200,\n            \"content\": [{\n                \"type\": \"text\",\n                \"text\": \"Test\"\n            }],\n            \"metadata\": {\n                \"userVisible\": false,\n                \"agentVisible\": true\n            }\n        }\"#;\n\n        let message: Message = serde_json::from_str(json_with_metadata).unwrap();\n        assert!(!message.is_user_visible());\n        assert!(message.is_agent_visible());\n    }\n\n    #[test]\n    fn test_message_metadata_static_methods() {\n        // Test MessageMetadata::agent_only()\n        let agent_only_metadata = MessageMetadata::agent_only();\n        assert!(!agent_only_metadata.user_visible);\n        assert!(agent_only_metadata.agent_visible);\n\n        // Test MessageMetadata::user_only()\n        let user_only_metadata = MessageMetadata::user_only();\n        assert!(user_only_metadata.user_visible);\n        assert!(!user_only_metadata.agent_visible);\n\n        // Test MessageMetadata::invisible()\n        let invisible_metadata = MessageMetadata::invisible();\n        assert!(!invisible_metadata.user_visible);\n        assert!(!invisible_metadata.agent_visible);\n\n        // Test using them with messages\n        let agent_msg = Message::assistant()\n            .with_text(\"Agent only message\")\n            .with_metadata(MessageMetadata::agent_only());\n        assert!(!agent_msg.is_user_visible());\n        assert!(agent_msg.is_agent_visible());\n\n        let user_msg = Message::user()\n            .with_text(\"User only message\")\n            .with_metadata(MessageMetadata::user_only());\n        assert!(user_msg.is_user_visible());\n        assert!(!user_msg.is_agent_visible());\n\n        let invisible_msg = Message::user()\n            .with_text(\"Invisible message\")\n            .with_metadata(MessageMetadata::invisible());\n        assert!(!invisible_msg.is_user_visible());\n        assert!(!invisible_msg.is_agent_visible());\n    }\n\n    #[test]\n    fn test_message_metadata_builder_methods() {\n        // Test with_agent_invisible\n        let metadata = MessageMetadata::default().with_agent_invisible();\n        assert!(metadata.user_visible);\n        assert!(!metadata.agent_visible);\n\n        // Test with_user_invisible\n        let metadata = MessageMetadata::default().with_user_invisible();\n        assert!(!metadata.user_visible);\n        assert!(metadata.agent_visible);\n\n        // Test with_agent_visible\n        let metadata = MessageMetadata::invisible().with_agent_visible();\n        assert!(!metadata.user_visible);\n        assert!(metadata.agent_visible);\n\n        // Test with_user_visible\n        let metadata = MessageMetadata::invisible().with_user_visible();\n        assert!(metadata.user_visible);\n        assert!(!metadata.agent_visible);\n\n        // Test chaining\n        let metadata = MessageMetadata::invisible()\n            .with_user_visible()\n            .with_agent_visible();\n        assert!(metadata.user_visible);\n        assert!(metadata.agent_visible);\n    }\n\n    #[test]\n    fn test_legacy_tool_response_deserialization() {\n        let legacy_json = r#\"{\n            \"role\": \"user\",\n            \"created\": 1640995200,\n            \"content\": [{\n                \"type\": \"toolResponse\",\n                \"id\": \"tool123\",\n                \"toolResult\": {\n                    \"status\": \"success\",\n                    \"value\": [\n                        {\n                            \"type\": \"text\",\n                            \"text\": \"Tool output text\"\n                        }\n                    ]\n                }\n            }],\n            \"metadata\": { \"agentVisible\": true, \"userVisible\": true }\n        }\"#;\n\n        let message: Message = serde_json::from_str(legacy_json).unwrap();\n        assert_eq!(message.content.len(), 1);\n\n        if let MessageContent::ToolResponse(response) = &message.content[0] {\n            assert_eq!(response.id, \"tool123\");\n            if let Ok(result) = &response.tool_result {\n                assert_eq!(result.content.len(), 1);\n                assert_eq!(\n                    result.content[0].as_text().unwrap().text,\n                    \"Tool output text\"\n                );\n            } else {\n                panic!(\"Expected successful tool result\");\n            }\n        } else {\n            panic!(\"Expected ToolResponse content\");\n        }\n    }\n\n    #[test]\n    fn test_new_tool_response_deserialization() {\n        let new_json = r#\"{\n            \"role\": \"user\",\n            \"created\": 1640995200,\n            \"content\": [{\n                \"type\": \"toolResponse\",\n                \"id\": \"tool456\",\n                \"toolResult\": {\n                    \"status\": \"success\",\n                    \"value\": {\n                        \"content\": [\n                            {\n                                \"type\": \"text\",\n                                \"text\": \"New format output\"\n                            }\n                        ],\n                        \"isError\": false\n                    }\n                }\n            }],\n            \"metadata\": { \"agentVisible\": true, \"userVisible\": true }\n        }\"#;\n\n        let message: Message = serde_json::from_str(new_json).unwrap();\n        assert_eq!(message.content.len(), 1);\n\n        if let MessageContent::ToolResponse(response) = &message.content[0] {\n            assert_eq!(response.id, \"tool456\");\n            if let Ok(result) = &response.tool_result {\n                assert_eq!(result.content.len(), 1);\n                assert_eq!(\n                    result.content[0].as_text().unwrap().text,\n                    \"New format output\"\n                );\n            } else {\n                panic!(\"Expected successful tool result\");\n            }\n        } else {\n            panic!(\"Expected ToolResponse content\");\n        }\n    }\n}\n"
                  },
                  "annotations": {
                    "audience": [
                      "assistant"
                    ]
                  }
                },
                {
                  "type": "text",
                  "text": "### /Users/baxen/Development/goose/crates/goose/src/conversation/message.rs (lines 1-150)\n```rust\n1: use crate::mcp_utils::ToolResult;\n2: use chrono::Utc;\n3: use rmcp::model::{\n4:     AnnotateAble, CallToolRequestParam, CallToolResult, Content, ImageContent, JsonObject,\n5:     PromptMessage, PromptMessageContent, PromptMessageRole, RawContent, RawImageContent,\n6:     RawTextContent, ResourceContents, Role, TextContent,\n7: };\n8: use serde::{Deserialize, Deserializer, Serialize};\n9: use std::collections::HashSet;\n10: use std::fmt;\n11: use utoipa::ToSchema;\n12: \n13: use crate::conversation::tool_result_serde;\n14: use crate::utils::sanitize_unicode_tags;\n15: \n16: #[derive(ToSchema)]\n17: pub enum ToolCallResult<T> {\n18:     Success { value: T },\n19:     Error { error: String },\n20: }\n21: \n22: /// Custom deserializer for MessageContent that sanitizes Unicode Tags in text content\n23: fn deserialize_sanitized_content<'de, D>(deserializer: D) -> Result<Vec<MessageContent>, D::Error>\n24: where\n25:     D: Deserializer<'de>,\n26: {\n27:     use serde::de::Error;\n28: \n29:     let mut raw: Vec<serde_json::Value> = Vec::deserialize(deserializer)?;\n30: \n31:     // Filter out old \"conversationCompacted\" messages from pre-14.0\n32:     raw.retain(|item| item.get(\"type\").and_then(|v| v.as_str()) != Some(\"conversationCompacted\"));\n33: \n34:     let mut content: Vec<MessageContent> = serde_json::from_value(serde_json::Value::Array(raw))\n35:         .map_err(|e| Error::custom(format!(\"Failed to deserialize MessageContent: {}\", e)))?;\n36: \n37:     for message_content in &mut content {\n38:         if let MessageContent::Text(text_content) = message_content {\n39:             let original = &text_content.text;\n40:             let sanitized = sanitize_unicode_tags(original);\n41:             if *original != sanitized {\n42:                 tracing::info!(\n43:                     original = %original,\n44:                     sanitized = %sanitized,\n45:                     removed_count = original.len() - sanitized.len(),\n46:                     \"Unicode Tags sanitized during Message deserialization\"\n47:                 );\n48:                 text_content.text = sanitized;\n49:             }\n50:         }\n51:     }\n52: \n53:     Ok(content)\n54: }\n55: \n56: /// Provider-specific metadata for tool requests/responses.\n57: /// Allows providers to store custom data without polluting the core model.\n58: pub type ProviderMetadata = serde_json::Map<String, serde_json::Value>;\n59: \n60: #[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]\n61: #[serde(rename_all = \"camelCase\")]\n62: #[derive(ToSchema)]\n63: pub struct ToolRequest {\n64:     pub id: String,\n65:     #[serde(with = \"tool_result_serde\")]\n66:     #[schema(value_type = Object)]\n67:     pub tool_call: ToolResult<CallToolRequestParam>,\n68:     #[serde(skip_serializing_if = \"Option::is_none\")]\n69:     #[schema(value_type = Object)]\n70:     pub metadata: Option<ProviderMetadata>,\n71: }\n72: \n73: impl ToolRequest {\n74:     pub fn to_readable_string(&self) -> String {\n75:         match &self.tool_call {\n76:             Ok(tool_call) => {\n77:                 format!(\n78:                     \"Tool: {}, Args: {}\",\n79:                     tool_call.name,\n80:                     serde_json::to_string_pretty(&tool_call.arguments)\n81:                         .unwrap_or_else(|_| \"<<invalid json>>\".to_string())\n82:                 )\n83:             }\n84:             Err(e) => format!(\"Invalid tool call: {}\", e),\n85:         }\n86:     }\n87: }\n88: \n89: #[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]\n90: #[serde(rename_all = \"camelCase\")]\n91: #[derive(ToSchema)]\n92: pub struct ToolResponse {\n93:     pub id: String,\n94:     #[serde(with = \"tool_result_serde::call_tool_result\")]\n95:     #[schema(value_type = Object)]\n96:     pub tool_result: ToolResult<CallToolResult>,\n97:     #[serde(skip_serializing_if = \"Option::is_none\")]\n98:     #[schema(value_type = Object)]\n99:     pub metadata: Option<ProviderMetadata>,\n100: }\n101: \n102: #[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]\n103: #[serde(rename_all = \"camelCase\")]\n104: #[derive(ToSchema)]\n105: pub struct ToolConfirmationRequest {\n106:     pub id: String,\n107:     pub tool_name: String,\n108:     pub arguments: JsonObject,\n109:     pub prompt: Option<String>,\n110: }\n111: \n112: #[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema)]\n113: #[serde(tag = \"actionType\", rename_all = \"camelCase\")]\n114: pub enum ActionRequiredData {\n115:     #[serde(rename_all = \"camelCase\")]\n116:     ToolConfirmation {\n117:         id: String,\n118:         tool_name: String,\n119:         arguments: JsonObject,\n120:         prompt: Option<String>,\n121:     },\n122:     Elicitation {\n123:         id: String,\n124:         message: String,\n125:         requested_schema: serde_json::Value,\n126:     },\n127:     ElicitationResponse {\n128:         id: String,\n129:         user_data: serde_json::Value,\n130:     },\n131: }\n132: \n133: #[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema)]\n134: #[serde(rename_all = \"camelCase\")]\n135: pub struct ActionRequired {\n136:     pub data: ActionRequiredData,\n137: }\n138: \n139: #[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema)]\n140: pub struct ThinkingContent {\n141:     pub thinking: String,\n142:     pub signature: String,\n143: }\n144: \n145: #[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema)]\n146: pub struct RedactedThinkingContent {\n147:     pub data: String,\n148: }\n149: \n150: #[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema)]\n```\n",
                  "annotations": {
                    "audience": [
                      "user"
                    ],
                    "priority": 0.0
                  }
                }
              ],
              "isError": false
            }
          }
        }
      ],
      "metadata": {
        "userVisible": true,
        "agentVisible": true
      }
    },
    {
      "id": "msg_01AEdDMbCrCDj93tRtiRX7BN",
      "role": "assistant",
      "created": 1766962654,
      "content": [
        {
          "type": "text",
          "text": "Now I have a comprehensive understanding of the message flow. Let me create a clear summary:\n\n# Message Flow from CLI Input to LLM Response\n\n## Overview\n\nThe message flow in Goose follows a well-structured pipeline from user input in the CLI through to the LLM response. Here's a detailed breakdown:\n\n---\n\n## 1. CLI Entry Point (`goose-cli`)\n\n### `main.rs` → `cli.rs`\n```\nUser Input → Clap Parser → Command Handler\n```\n\n- **Entry**: `crates/goose-cli/src/main.rs` calls `cli()` from `cli.rs`\n- **Parsing**: Uses Clap to parse commands (e.g., `session`, `run`)\n- **Session Creation**: Creates or resumes a session via `SessionManager`\n\n---\n\n## 2. Session Building (`session/builder.rs`)\n\n```\nSessionBuilderConfig → Provider Creation → Agent Setup → CliSession\n```\n\nKey steps in `build_session()`:\n1. **Load configuration** from `Config::global()`\n2. **Determine provider/model** (from CLI args, saved session, or config)\n3. **Create provider** via `goose::providers::create()`\n4. **Initialize Agent** with the provider\n5. **Load extensions** (MCP servers like `developer`, `memory`, etc.)\n6. **Create CliSession** with the agent\n\n---\n\n## 3. Interactive Session (`session/mod.rs`)\n\n### User Input Loop\n```rust\n// In CliSession::interactive()\nloop {\n    match input::get_input(&mut editor)? {\n        InputResult::Message(content) => {\n            self.push_message(Message::user().with_text(&content));\n            self.process_agent_response(true, cancel_token).await?;\n        }\n        // ... other input types\n    }\n}\n```\n\n### Message Processing\n```rust\n// In CliSession::process_message()\nself.push_message(message);  // Add to conversation\nself.process_agent_response(false, cancel_token).await?;  // Get LLM response\n```\n\n---\n\n## 4. Agent Reply (`agents/agent.rs`)\n\n### `Agent::reply()` - Main Entry Point\n```\nUser Message → Command Check → Session Storage → Conversation Retrieval → reply_internal()\n```\n\nKey flow:\n1. **Check for slash commands** (e.g., `/compact`, `/clear`)\n2. **Store message** in session via `SessionManager::add_message()`\n3. **Check for auto-compaction** if context is too large\n4. **Call `reply_internal()`** for actual LLM interaction\n\n### `Agent::reply_internal()` - Core Loop\n```rust\nloop {\n    // 1. Inject MOIM (Model-Oriented Instruction Memory)\n    let conversation_with_moim = super::moim::inject_moim(conversation.clone(), ...).await;\n    \n    // 2. Stream response from provider\n    let mut stream = Self::stream_response_from_provider(\n        provider, &system_prompt, messages, &tools, &toolshim_tools\n    ).await?;\n    \n    // 3. Process each response chunk\n    while let Some(next) = stream.next().await {\n        match next {\n            Ok((response, usage)) => {\n                // Categorize tool requests\n                let ToolCategorizeResult { frontend_requests, remaining_requests, filtered_response } \n                    = self.categorize_tools(&response, &tools).await;\n                \n                // Yield message to caller\n                yield AgentEvent::Message(filtered_response);\n                \n                // Execute tool calls if any\n                if num_tool_requests > 0 {\n                    // Dispatch tools, collect results\n                    // Add tool responses to conversation\n                }\n            }\n            Err(ProviderError::ContextLengthExceeded(_)) => {\n                // Compact conversation and retry\n            }\n            Err(e) => { /* Handle error */ }\n        }\n    }\n    \n    // 4. Continue loop if tools were called, exit if just text response\n    if no_tools_called { break; }\n}\n```\n\n---\n\n## 5. Provider Interaction (`providers/base.rs`)\n\n### `Provider::complete()` / `Provider::stream()`\n```\nSystem Prompt + Messages + Tools → LLM API → Response Message + Usage\n```\n\nThe `Provider` trait defines the interface:\n```rust\nasync fn complete(\n    &self,\n    system: &str,           // System prompt\n    messages: &[Message],   // Conversation history\n    tools: &[Tool],         // Available tools\n) -> Result<(Message, ProviderUsage), ProviderError>\n```\n\n### Streaming in `reply_parts.rs`\n```rust\n// Agent::stream_response_from_provider()\nif provider.supports_streaming() {\n    provider.stream(system_prompt, messages, &tools).await\n} else {\n    // Wrap single response as stream\n    stream_from_single_message(message, usage)\n}\n```\n\n---\n\n## 6. Response Rendering (`session/output.rs`)\n\nBack in `CliSession::process_agent_response()`:\n```rust\nwhile let Some(event) = stream.next().await {\n    match event {\n        AgentEvent::Message(message) => {\n            self.messages.push(message.clone());\n            output::render_message(&message, self.debug);\n        }\n        AgentEvent::McpNotification((extension_id, notification)) => {\n            // Show progress, logs from extensions\n        }\n        // ...\n    }\n}\n```\n\n---\n\n## Data Structures\n\n### `Message` (`conversation/message.rs`)\n```rust\npub struct Message {\n    pub id: Option<String>,\n    pub role: Role,              // User or Assistant\n    pub created: i64,\n    pub content: Vec<MessageContent>,  // Text, Image, ToolRequest, ToolResponse, etc.\n    pub metadata: MessageMetadata,     // Visibility flags\n}\n```\n\n### `Conversation` (`conversation/mod.rs`)\n- A validated collection of `Message` objects\n- Ensures proper alternation of User/Assistant messages\n- Handles tool request/response pairing\n\n### `AgentEvent` (`agents/agent.rs`)\n```rust\npub enum AgentEvent {\n    Message(Message),                              // LLM response or tool result\n    McpNotification((String, ServerNotification)), // Extension notifications\n    ModelChange { model: String, mode: String },   // For lead-worker providers\n    HistoryReplaced(Conversation),                 // After compaction\n}\n```\n\n---\n\n## Complete Flow Diagram\n\n```\n┌─────────────────────────────────────────────────────────────────────────────┐\n│                              CLI INPUT                                       │\n│  goose session / goose run --text \"...\"                                     │\n└─────────────────────────────────────────────────────────────────────────────┘\n                                    │\n                                    ▼\n┌─────────────────────────────────────────────────────────────────────────────┐\n│                           cli.rs: cli()                                      │\n│  • Parse command with Clap                                                   │\n│  • Create/resume session via SessionManager                                  │\n│  • Call build_session() to create CliSession                                 │\n└─────────────────────────────────────────────────────────────────────────────┘\n                                    │\n                                    ▼\n┌─────────────────────────────────────────────────────────────────────────────┐\n│                      builder.rs: build_session()                             │\n│  • Load provider config (provider name, model)                               │\n│  • Create Provider via providers::create()                                   │\n│  • Initialize Agent with provider                                            │\n│  • Load extensions (MCP servers)                                             │\n│  • Return CliSession                                                         │\n└─────────────────────────────────────────────────────────────────────────────┘\n                                    │\n                                    ▼\n┌─────────────────────────────────────────────────────────────────────────────┐\n│                   session/mod.rs: CliSession::interactive()                  │\n│  • Display greeting                                                          │\n│  • Loop: get_input() → process user input                                    │\n│  • On message: push_message() + process_agent_response()                     │\n└─────────────────────────────────────────────────────────────────────────────┘\n                                    │\n                                    ▼\n┌─────────────────────────────────────────────────────────────────────────────┐\n│                      agent.rs: Agent::reply()                                │\n│  • Check for slash commands                                                  │\n│  • Store message in SessionManager                                           │\n│  • Check if compaction needed                                                │\n│  • Call reply_internal()                                                     │\n└─────────────────────────────────────────────────────────────────────────────┘\n                                    │\n                                    ▼\n┌─────────────────────────────────────────────────────────────────────────────┐\n│                    agent.rs: Agent::reply_internal()                         │\n│  • Prepare tools and system prompt                                           │\n│  • Loop until no tools called:                                               │\n│    1. Inject MOIM into conversation                                          │\n│    2. stream_response_from_provider()                                        │\n│    3. Categorize tool requests                                               │\n│    4. Execute tools via dispatch_tool_call()                                 │\n│    5. Yield AgentEvent::Message for each response                            │\n└─────────────────────────────────────────────────────────────────────────────┘\n                                    │\n                                    ▼\n┌─────────────────────────────────────────────────────────────────────────────┐\n│              reply_parts.rs: stream_response_from_provider()                 │\n│  • Convert messages if toolshim enabled                                      │\n│  • Call provider.stream() or provider.complete()                             │\n│  • Post-process with toolshim if needed                                      │\n│  • Return MessageStream                                                      │\n└─────────────────────────────────────────────────────────────────────────────┘\n                                    │\n                                    ▼\n┌─────────────────────────────────────────────────────────────────────────────┐\n│                    providers/base.rs: Provider::complete()                   │\n│  • Format request for specific LLM API (OpenAI, Anthropic, etc.)            │\n│  • Send HTTP request to LLM endpoint                                         │\n│  • Parse response into Message + ProviderUsage                               │\n└─────────────────────────────────────────────────────────────────────────────┘\n                                    │\n                                    ▼\n┌─────────────────────────────────────────────────────────────────────────────┐\n│              session/mod.rs: process_agent_response()                        │\n│  • Receive AgentEvent stream                                                 │\n│  • For each Message: add to conversation, render to terminal                 │\n│  • Handle tool confirmations, notifications                                  │\n│  • Update session metrics                                                    │\n└─────────────────────────────────────────────────────────────────────────────┘\n                                    │\n                                    ▼\n┌─────────────────────────────────────────────────────────────────────────────┐\n│                         TERMINAL OUTPUT                                      │\n│  • Rendered markdown text                                                    │\n│  • Tool call/response display                                                │\n│  • Progress indicators                                                       │\n└─────────────────────────────────────────────────────────────────────────────┘\n```\n\n---\n\n## Tool Summary\n\n| Tool | Times Called |\n|------|-------------|\n| `developer__text_editor` (view) | 14 |"
        }
      ],
      "metadata": {
        "userVisible": true,
        "agentVisible": true
      }
    }
  ],
  "metadata": {
    "total_tokens": 93057,
    "input_tokens": 90092,
    "output_tokens": 2965,
    "accumulated_total_tokens": 623724,
    "accumulated_input_tokens": 620759,
    "accumulated_output_tokens": 2965,
    "status": "completed"
  }
}
